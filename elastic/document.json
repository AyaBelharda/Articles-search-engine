[
  {
    "titre": "AI Model for Computer games based on Case Based Reasoning and AI Planning",
    "resume": "Making efficient AI models for games with imperfect information can be a particular challenge. Considering the large number of possible moves and the incorporated uncertainties building game trees for these games becomes very difficult due to the exponential growth of the number of nodes at each level. This effort is focused on presenting a method of combined Case Based Reasoning (CBR) with AI Planning which drastically reduces the size of game trees. Instead of looking at all possible combinations we can focus only on the moves that lead us to specific strategies in effect discarding meaningless moves. These strategies are selected by finding similarities to cases in the CBR database. The strategies are formed by a set of desired goals. The AI planning is responsible for creating a plan to reach these goals. The plan is basically a set of moves that brings the player to this goal. By following these steps and not regarding the vast number of other possible moves the model develops Game Trees which grows slower so they can be built with more feature moves restricted by the same amount of memory.",
    "auteurs": [
      "Case Based \nReasoning",
      "Vlado Menkovski",
      "Case Based \nReasoning",
      "Game Trees",
      "Game Trees and Minimax",
      "Game Trees"
    ],
    "institutions": [
      "Dimitrios Metafas Athens Information Technology ",
      "Vlado Menkovski Athens Information Technology "
    ],
    "mots_cles": [
      "Game AI",
      " Case Based Reasoning",
      " AI Planning",
      " Game Trees "
    ],
    "texte_integral": "AI Model for Computer games based on Case Based \nReasoning and AI Planning  \nVlado Menkovski \nAthens Information Technology \n0.8km Markopoulou Ave. \nPeania, 19002, Greece \nvmen@ait.edu.gr \nDimitrios Metafas \nAthens Information Technology \n0.8km Markopoulou Ave. \nPeania, 19002, Greece \ndmeta@ait.edu.gr \nAbstract\nMaking efficient AI models for games with imperfect \ninformation can be a particular challenge. Considering the large \nnumber of possible moves and the incorporated uncertainties \nbuilding game trees for these games becomes very difficult due to \nthe exponential growth of the number of nodes at each level. This \neffort is focused on presenting a method of combined Case Based \nReasoning (CBR) with AI Planning which drastically reduces the \nsize of game trees. Instead of looking at all possible combinations \nwe can focus only on the moves that lead us to specific strategies \nin effect discarding meaningless moves. These strategies are \nselected by finding similarities to cases in the CBR database. The \nstrategies are formed by a set of desired goals. The AI planning is \nresponsible for creating a plan to reach these goals. The plan is \nbasically a set of moves that brings the player to this goal. By \nfollowing these steps and not regarding the vast number of other \npossible moves the model develops Game Trees which grows \nslower so they can be built with more feature moves restricted by \nthe same amount of memory.  \nCategories and Subject Descriptors \nI.2.1 [Applications and Expert Systems]: Games\nGeneral Terms\nAlgorithms, Performance. \nKeywords\nGame AI, Case Based Reasoning, AI Planning, Game Trees \n1. Introduction \nThe goal of this effort is to explore a model for design and \nimplementation of an AI agent for turn based games. This model \nprovides for building more capable computer opponents that rely \non strategies that closely resemble human approach in solving \nproblems opposed to classical computational centric heuristics in \ngame AI. In this manner the computational resources can be \nfocused on more sensible strategies for the game play.  \nWith the advancement in computer hardware increasingly \nmore computing power is left for executing AI algorithms in \ngames. In the past AI in games was mainly a cheating set of \ninstructions that simulated the increasing difficulty in the game \nenvironment so that the player had the illusion of real counterpart. \nImprovement in available memory and processing power allows \nimplementation of more intelligent algorithms for building the \ngame environment as well as direct interaction with the human \nplayers.   \nIn this particular research the emphasis is put on the \ninteraction between the AI agent and a computer player in the \nrealm of the game rules. It is particularly focused on turn based \ngames that have the elements of uncertainty like dice or concealed \ninformation. At the beginning a description of Game AI \nalgorithms are given; such as Game Trees and Minimax. The \nfollowing section describes an approach of using AI Planning to \nimprove building Game Trees in games with imperfect \ninformation where Game Trees tend to be very large with high \ngrowth ratio. Section 4 discusses another approach that provides a \nsignificant reduction to the number of considered moves in order \nto find the favorable strategy of the AI player. This approach uses \nAI Planning techniques and Case Base Reasoning (CBR) to plan \nfor different scenarios in predetermined strategies which would be \nanalogous to human player experience in the particular game. The \nCBR database illustrates a set of past experiences for the AI \nproblem and the AI Planning illustrates the procedure to deal with \nthe given situation in the game. In the next two sections \nimplementations and evaluations of both approaches are given. \nThe AI Planning approach is implemented with the Tic-tac-toe \ngame and the combined AI Planning and CBR approach is \nimplemented with a model for the Monopoly game. The last part \ncontains conclusions and future work ideas.  \n2. Game Trees and Minimax \nGame Trees are common model for evaluating how different \ncombinations of moves from the player and his opponents will \naffect the future position of the player and eventually the end \nresult of the game. An algorithm that decides on the next move by \nevaluating the results from the built Game Tree is minimax [1]. \nMinimax assumes that the player at hand will always choose the \nbest possible move for him, in other words the player will try to \nselect the move that maximizes the result of the evaluation \nfunction over the game state. So basically the player at hand needs \nto choose the best move overall while taking into account that the \nnext player(s) will try to do the same thing. Minimax tries to \nmaximize the minimum gain. Minimax can be applied to multiple \nPermission to make digital or hard copies of all or part of this work for \npersonal or classroom use is granted without fee provided that copies are \nnot made or distributed for profit or commercial advantage and that \ncopies bear this notice and the full citation on the first page. To copy \notherwise, or republish, to post on servers or to redistribute to lists, \nrequires prior specific permission and/or a fee. \nDIMEA\u201908, September 10\u201312, 2008, Athens, Greece. \nCopyright 2008 ACM 978-1-60558-248-1/08/09... $5.00 \nInteractive and Adaptable Media\n295\n3rd International Conference on Digital Interactive Media in Entertainment and Arts\nlevels of nodes on the game tree, where the leaves bring the final \nknown (or considered) game state.  \nThe minimax theorem states: \nFor every two-person, zero-sum game there is a mixed strategy \nfor each player, such that the expected payoff for both is the same \nvalue V when the players use these strategies. Furthermore, V is \nthe best payoff each can expect to receive from a play of the \ngame; that is, these mixed strategies are the optimal strategies for \nthe two players. \nThis theorem was established by John von Neumann, who is \nquoted as saying \"As far as I can see, there could be no theory of \ngames \u2026 without that theorem \u2026 I thought there was nothing \nworth publishing until the Minimax Theorem was proved\" [2]. \nA simple example of minimax can be observed by building a \ngame tree of the tic-tac-toe game. The tic-tac-toe game is a simple \ngame which can end by the first player wining, the second player \nwining or a tie. There are nine positions for each of the players in \nwhich at each turn the player puts X or O sign. If the player has \nthree adjacent signs in a row, column or the two diagonals he or \nshe wins. This game has limited number of position and it is well \nsuited for building the whole game tree. The leaves of this tree \nwill be final positions in the game. A heuristics evaluation \nfunction will also need to be written to evaluate the value of each \nnode along the way. \n3. AI Planning for building Game Trees \n3.1.1 AI Planning \nAI Planning also referred as Automated Planning and \nScheduling is a branch of Artificial Intelligence that focuses on \nfinding strategies or sequences of actions that reach a predefined \ngoal [3]. Typical execution of AI Planning algorithms is by \nintelligent agents, autonomous robots and unmanned vehicles. \nOpposed to classical control or classification AI Planning results \nwith complex solutions that are derived from multidimensional \nspace. \n AI Planning algorithms are also common in the video game \ndevelopment. They solve broad range of problems from path \nfinding to action planning. A typical planner takes three inputs: a \ndescription of the initial state of the world, a description of the \ndesired goal, and a set of possible actions. Some efforts for \nincorporating planning techniques for building game trees have \nalso shown up, similar to the approach explored in this effort. In \naddition Cased Based Reasoning [4] techniques are also gathering \npopularity in developing strategies based in prior knowledge \nabout the problems in the games. One of the benefits from \nHierarchical Task Network (HTN) [5] planning is the possibility \nto build Game Trees based on HTN plans; this method is \ndescribed in the following section. \n3.2 Game Trees with AI Planning \nAn adaptation of the HTN planning can be used to build \nmuch smaller and more efficient game trees. This idea has already \nbeen implemented in the Bridge Baron a computer program for \nthe game of Contact Bridge [6]. \nComputer programs based on Game Tree search techniques \nare now as good as or better than humans in many games like \nChess [7] and checkers [8], but there are some difficulties in \nbuilding a game tree for games that have imperfect information \nand added uncertainty like card or games with dice. The main \nproblem is the enormous number of possibilities that the player \ncan choose from in making his move. In addition some of the \nmoves are accompanied with probabilities based on the random \nelements in the games. The number of possible moves \nexponentially grows with each move so the depth of the search \nhas to be very limited to accommodate for the memory \nlimitations.  \nThe basic idea behind using HTN for building game trees is \nthat the HTN provides the means of expressing high level goals \nand describing strategies how to reach those goals. These goals \nmay be decomposed in goals at lower level called sub-goals. This \napproach closely resembles the way a human player usually \naddresses a complex problem. It is also good for domains where \nclassical search for solution is not feasible due to the vastness of \nthe problem domain or uncertainties. \n3.2.1 Hierarchical Task Networks \nThe Hierarchical Task Network, or HTN, is an approach to \nautomated planning in which the dependency among actions can \nbe given in the form of networks [9] [Figure 1]. \nA simple task network (or just a task network for short) is an \nacyclic digraph \ufffd \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd in which U is the node set, E is the \nedge set, and each node \ufffd \ufffd \ufffd contains a task \ufffd\ufffd. The edges of \ufffd\ndefine a partial ordering of U. If the partial ordering is total, then \nwe say that \ufffd is totally ordered, in which case \ufffd can be written as \na sequence of tasks \ufffd \ufffd \ufffd\ufffd\ufffd\ufffd \ufffd\ufffd\ufffd \ufffd \ufffd \ufffd\ufffd\ufffd.\nFigure 1: Simple Hierarchical Task Network \nA Simple Task Network (STN) method is a 4-tuple of its name, \ntask, precondition and a task network. The name of the method \nlets us refer unambiguously to substitution instances of the \nmethod, without having to write the preconditions and effects \nexplicitly. The task tells what kind of task can be applied if the \npreconditions are met. The preconditions specify the conditions \nthat the current state needs to satisfy in order for the method to be \napplied. And the network defines the specific subtasks to \naccomplish in order to accomplish the task. \nA method is relevant for a task if the current state satisfies the \npreconditions of a method that implements that task. This task can \nbe then substituted with the instance of the method. The \nsubstitution is basically giving the method network as a solution \nfor the task. \nIf there is a task \u201cGo home\u201d and the distance to home is 3km \n[Figure 2] and there exists a method walk-to and this method has a \nprecondition that the distance is less than 5km, then a substation \nto the task \u201cGo home\u201d can be made with this method instance.  \nFigure 2: HTN Method \nBuy milk\nGo to (shop)\nPurchase \nGo to (home)\nGo-to (from, to)\nWalk (to)\nIf (to \u2013 from) < 5km \n296\nDIMEA 2008\n3rd International Conference on Digital Interactive Media in Entertainment and Arts\nIf the distance is larger than 5km another meth\nto be substituted [Figure 3]. \nFigure 3: HTN Method 2 \nAn STN planning domain is a set of operatio\nmethods M. A STN planning problem is a 4-tu\nstate S0, the task network w called initial task\nSTN domain. A plan \ufffd \ufffd \ufffd\ufffd\ufffd\ufffd \ufffd \ufffd \ufffd\ufffd\ufffd is a soluti\nproblem if there is a way to decompose w into \u03c0\nand each decomposition is applicable in the ap\nthe world. The algorithm that is capable to \nnetworks into plans is called Total-forward-deco\n[9] or Partial-forward-decomposition (PFD). H\ncases where one does not want to use a forwa\nprocedure. HTN planning is generalization of S\ngives the planning procedure more freedom\nconstruct the task networks.  \nIn order to provide this freedom, a bookke\nis needed to represent constraints that the plann\nnot yet enforced. The bookkeeping is done by\nunenforced constraints explicitly in the task netw\nThe HTN generalizes the definition of a\nSTN. A task network is the pair \ufffd \ufffd \ufffd\ufffd\ufffd \ufffd\ufffd w\ntask nodes and C is a set of constraints. Eac\nspecifies a requirement that must be satisfied by\na solution to a planning problem.  \nThe definition of a method in HTN also\ndefinition used in STN planning. A HTN pla\nname, task, subtasks, and constraints. The s\nconstraints form the task network. The HTN plan\nidentical to STN planning domains except they u\ninstead of STN methods. \nCompared to classical planners the prim\nHTN planners is their sophisticated knowledge r\nreasoning capabilities. They can represent and \nnon-classical planning problems; with a good\nguide them, they can solve classical planning p\nmagnitude more quickly than classical or neoc\nThe primary disadvantage of HTN is the nee\nauthor to write not only a set of planning opera\nof methods. \n3.2.2 HTN Planning in building Game \nFor a HTN planning algorithm to be adap\ntrees we need to define the domain (set of H\noperators) which is the domain of the game. Thi\na knowledge representation of the rules of the\nenvironments and possible strategies of game pla\nIn this domain the game rules as well as kn\ntackle specific task are defined.   The implem\nTree building with HTN is called Tign\nimplementation \nuses \na \nprocedure \nsimila\ndecomposition, but adapted to build up a game \nDrive(to\nIf(t\nGo-to (from, to) \nIf(to \u2013 from) < 5km \nWalk (to) \nhod instance needs \nons O and a set of \nuple of the initial \nk network and the \nion for a planning \n\u03c0 if \u03c0 is executable \nppropriate state of \ndecompose these \nomposition (TFD) \nHowever there are \nard-decomposition \nSTN planning that \nm about how to \neeping mechanism \nning algorithm has \ny representing the \nwork. \na task network in \nwhere \ufffd is a set of \nh constraint in C \ny every plan that is \no generalizes the \nan is a 4-tuple of \nsubtasks and the \nnning domains are \nuse HTN methods \nmary advantage of \nrepresentation and \nsolve a variety of \nd set of HTNs to \nproblems orders of \nclassical planners. \ned of the domain \nators but also a set \nTrees\nted to build game \nHTN methods and \nis is in some sense \ne game, the game \nay.\nnown strategies to \nmentation of Game \nnum2 [9]. This \nar \nto \nforward-\ntree rather than a \nplan. The branches of the game tree rep\nthe methods. Tignum2 applies all met\nstate of the world to produce new\ncontinues recursively until there are n\nhave not already been applied to th\nworld.  \nIn the task network generated by Tignu\nactions will occur is determined by th\nBy listing the actions in the order \nnetwork can be \u201cserialized\u201d into a gam\n4. Case Based Reasoning in\n4.1 Case Based Reasoning\nCase-based reasoning (CBR) is a \nArtificial Intelligence (AI), both as \nproblems and as a basis for standalone \nCase-based reasoning is a paradigm\nsolving and learning that has became \napplied subfield of AI of recent yea\nintuition that problems tend to recur. I\nare often similar to previously en\ntherefore, that past solutions may be of\n[10].  \nCBR is particularly applicable to probl\navailable, even when the domain is n\nfor a deep domain model. Helpdesks,\nsystems have been the most successfu\nto determine a fault or diagnostic \nattributes, or to determine whether or\nrepair is necessary given a set of past s\nFigure 5: Game Tree built fr\nFigure 4: HTN to Game Tr\n)\nto \u2013 from) < 200km \npresent moves generated by \nthods applicable to a given \nw states of the world and \nno applicable methods that \nhe appropriate state of the \num2, the order in which the \ne total-ordering constraints. \nthey will occur, the task \nme tree [Figure 4] [Figure 5]. \nn Game Strategies\nwell established subfield of \na mean for addressing AI \nAI technology.\nm for combining problem-\none of the most successful \nars. CBR is based on the \nIt means that new problems \nncountered problems and, \nf use in the current situation \nlems where earlier cases are \nnot understood well enough \n, diagnosis or classification \nul areas of application, e.g., \nan illness from observed \nr not a certain treatment or \nolved cases [11]. \nrom HTN\nree Algorithm\nInteractive and Adaptable Media\n297\n3rd International Conference on Digital Interactive Media in Entertainment and Arts\nCentral tasks that all CBR methods have to deal with are [12]: \"to \nidentify the current problem situation, find a past case similar to \nthe new one, use that case to suggest a solution to the current \nproblem, evaluate the proposed solution, and update the system by \nlearning from this experience. How this is done, what part of the \nprocess that is focused, what type of problems that drives the \nmethods, etc. varies considerably, however\".  \nWhile the underlying ideas of CBR can be applied \nconsistently \nacross \napplication \ndomains, \nthe \nspecific \nimplementation of the CBR methods \u2013in particular retrieval and \nsimilarity functions\u2013 is highly customized to the application at \nhand. \n4.2 CBR and Games \nMany different implementations of CBR exist in games. \nCBR technology is nicely suited for recognizing complex \nsituations much easier and more elegant than traditional parameter \ncomparison or function evaluation. There are especially evident \ncases in real time strategies where different attack and defense of \nglobal strategies are nicely defined by CBR datasets and later used \nin the running games. Also intelligent bots behavior is also \nanother typical example. Depending on the number of enemy bots \nthe layout of the terrain and position of human players the CBR \nsystem finds the closest CBR case and employs that strategy \nagainst the human players which in prior evaluation was proved to \nbe highly efficient. \n5. Game Trees with AI Planning \u2013 Tic-tac-toe \nIn order to show the expressive power of AI Planning in \ndefining strategies for games, and the use of these plans to build \nGame Trees I implemented an algorithm that builds Game Trees \nfor the Tic-Tac-Toe game. \nThe game tree of Tic-Tac-Toe shows 255,168 possible \ngames of which 131,184 are won by X (the first player), 77904 \nare won by O and the rest 46,080 are draw [13]. All these games \ncan be derived from building a complete Game Tree.  \nEven though it is possible to build a complete game tree of \nTic-tac-toe it is definitely not an optimal solution. Many of the \nmoves in this tree would be symmetrical and also there are a many \nmoves that would be illogical or at least a bad strategy to even \nconsider.  \nSo what strategy should X (the first player) choose in order \nto win the game? \nThere are few positions that lead to certain victory. These \npositions involve simultaneous attack on two positions so the \nother player could not defend, basically the only trick in Tic-Tac-\nToe. \nFigure 6: Tic-tac-toe winning strategy positions \nPosition 1 leads to victory if the two of the three fields: top \nmiddle, bottom left corner and bottom right corner are free \n[Figure 6]. \nPosition 2 lead to victory if two of the three fields: top right \ncorner, bottom right corner and bottom middle are free [Figure ]. \nAnd in the third position if the two of center, middle top and \nmiddle left are available the position is a certain victory. \nThere are many different arrangements of the player\u2019s tokens \nthat give equivalent positions as these three positions. By using \nplanning we do not need to consider all possible layouts but just \nconsider these three similar to what a human would consider. \n The game starts from an empty table. \nThe two relevant strategies that would lead to these positions \nare to take one corner or to take the center [Figure 7]. \nFigure 7: Tic-tac-toe Two starting moves \nThe center position as we can see in the simulation results \nlead to a bigger number of victorious endings but it is also a \nstraight forward strategy with obvious defense strategy. \nAt this point we need to consider the moves of the opponent. \nIf we take the left branch the opponent moves can be a center, a \ncorner or a middle field. We also need to differentiate with a \nmove to a corner adjacent with our like top left or bottom right or \nacross the center to bottom right [Figure 8]. \nFigure 8: Tic-tac-toe opponent response to corner move \nIn cases one and two, we have a clear path to executing \nstrategy 3 so we need to capture the diagonally opposite field. \nAnd as for the third case the best way to go is to capture the center \nand go for strategy 1 or 2 depending of the opponent\u2019s next move.  \nFigure 9: Tic-tac-toe move 2 after corner opening \nThe first move leads to certain victory, O will have to go to \nthe center and X will achieve strategy 3 [Figure 9]. The second \nmove is a possible way to strategy 3 if O makes a mistake in the \nnext loop, so X goes to the opposite corner. For the third case \nsince O is playing a valid strategy the only move that leaves a \npossible mistake from O would be to take the center and wait for \nO to go to the middle and then achieve strategy 1 or 3 which will \nbe a symmetric situation to the one that we will find if we \nbranched with the center. \nFigure 10: Tic-tac-toe opponent response to center move \nIf we go back to the second branch [Figure 10], a possible \nway for the second player to engage is corner or middle. The first \n298\nDIMEA 2008\n3rd International Conference on Digital Interactive Media in Entertainment and Arts\nmove is a valid strategy for O and can be mee\ncorner move from X to try a mistake from O in \nthe same as in the third case above from the pre\nanother move would be go to the middle wh\nachieves strategy 1 or 2.  \nFigure 11: Tic-tac-toe Move 2 after cent\nThe fist move will lead to win if O moves \ndraw if it goes for the corners [Figure 11]. In t\nhas to block the lower left corner which leave\nmiddle left or corner left which are strategy 1 and\nTo sum the strategies for the planning, first \ncorner strategy for the beginning. Then for the ce\nthe corners with the particularly the one oppo\nholds. If the center is empty for the second strate\nwe go for the opposite corner. After this point w\nopponent or try to implement strategies 1, 2 or\nvictory.  \nPlan 1: Take center  \nPreconditions: Center empty \nPlan 2: Take corner  \nPreconditions: All corners empty \nPlan 3: Take corner after center \nPreconditions: We have center take corner oppos\nopponent has \nPlan 4: Take diagonal corner \nPreconditions: We have a corner, the opponent ha\n the corner opposite to the one we have is free. \nPlan 5: Block \nPrecondition: The opponent has tree tokens in a r\nagonal \nPlan 6: Win \nPreconditions: We have two tokens in a row, colu\nnd the third place is free \nPlan 7: Tie \nPreconditions: If all places are taken, it\u2019s a tie. \n5.1 Hierarchical Task Network \nTop level task is Play [Figure 12]. This is a \ncan be derived into: Win, Block, Tie or Sear\nSearch for plan is derived to both Plan 1 and Pla\nPlan 4, which later leads to a call for the oppon\nrecursive call to Play. \nFigure 12: Tic-tac-toe HT\net with a opposite \nthe future exactly \nevious branch, and \nhere X eventually \nter opening\nto the middle or a \nthe second case O \nes X to go for the \nd 2.\nwe have center or \nenter we try to get \nosite to the one O \negy we go for it or \nwe either block the \nr 3 which lead to \nsite to the  one the \nas the ce\u2212nter and\nrow, colu\u2212mn or di\nmn or dia\u2212gonal a\na complex task and \nrch for Plan. The \nan 2 or Plan 3 and \nnent\u2019s move and a \nTN\nThis HTN when executed will re\ngame scenarios. By creating nodes from\nthem with branches with the move of t\ntree for the Tic-tac-toe game over whi\nalgorithm. \nThis set up with 7 plans with 3 ta\nfor Tic-tac-toe which considers all pos\nplayer with only 457 games, 281 of w\nand 0 where the second opponent w\nreduction over the 255, 168 possible g\ntree. These reductions can be very use\ncomputing capabilities but also we pr\nthat planning can be very efficient if d\ntrees by applying reasoning very \nreasoning. \nFurther improvements to the gam\nthe opponents moves are also planned\nall the meaningless and symmetrical m\n6. Game AI in Monopoly \n6.1 Overview of the AI Imp\nThe AI agent is responsible for \nplayers in the game. The core principle\na Game Tree with all the sensible move\nmake from the current point of time\nminimax algorithm the agent selects t\nwould bring the computer player mo\nwith the highest probability. Building \nthat would be big enough to consider \nis obstructed by the vastness of poss\nwith all the possible random landings \nnodes of the game tree exponentially\ntackle this problem the AI agents \ndiscussed technologies: Case Based Re\nThe technologies are employed \nFirst the agent searches the CBR datab\nlargest similarity with the current state\nassociated with a playing strategy. Th\nthat the planner needs to build plans f\nconsecutive player moves that bring th\nway only moves that are part of that str\nbeing a small fraction of the overall po\nedges of the game tree at each level dec\nAt each level of the game tree the\nof a single player. After the strateg\nconsidered the response to those strate\nby the opponent(s). The move of the \nprobability distribution of the dice as \nplayer. A more general strategy needs\nopponent\u2019s (human player) moves sin\nthe expertise of the opponent. This ge\nmore plausible moves than the focused\nAfter covering all opponents t\ndeducting a feature move of the com\nCBR selected plan strategy. After \nstrategies and reaching a reasonable s\ninto account the memory limits an\nprobabilities that the move is possible\nthe dice the building of the Game Tre\nalgorithm searches the Game Tree \nfavorable move for the AI player usi\nThe process is repeated each time the A\nesult with plans for possible \nm each position and linking \nthe player we create a game \nich we can run the minimax \narget strategies creates a tree \nssible moves for the second \nwhich X wins 176 are draw \nwins. This is a significant \names with a complete game \neful for devices with limited \nrove a very important point \ndesigning meaningful game \nsimilar to human player \nme tree are also possible if \nd, in other words if we drop \nmoves of the opponent. \nplementation\nthe moves of the artificial \ne of the AI agent is building \nes that all the players would \ne forward. Then using the \nthe move that in the future \nost favorable game position \na Game Tree in this game \nsufficient number of moves \nsible moves in combination \nof the dice. The number of \ny grows at each level. To \nincorporates two already \neasoning and AI Planning. \nin the following manner. \nbase to find the case with the \ne of the board. This case is \nhe strategy consists of goal \nfor, and the plans consist of \nhe player to that goal. This \nrategy are considered, those \nossible moves the number of \ncreases immensely. \ne model considers the moves \ngies of the AI player are \negies needs to be considered \nopponent(s) depends of the \nwell as the strategy of the \ns to be implemented for the \nnce we cannot be aware of \neneral strategy would bring \nd strategy of the AI player.  \nthe agent comes back to \nmputer player by using the \ncreating several loops of \nsize of a Game Tree taking \nnd the rapidly decreasing \ne due to the distribution of \nee stops. Then the minimax \nand decides on the most \ning the minimax algorithm. \nAI player is up. \nInteractive and Adaptable Media\n299\n3rd International Conference on Digital Interactive Media in Entertainment and Arts\nBuying, auctioning and trading game moves are always \naccompanied by return of investment calculations in making the \nplans. These calculations represent adaptation of the more general \nplanning associated with the cases in the CBR database. These \nadaptations are necessary due to the fact that the cases do not \nidentically correspond to the situation on the table. In addition \ncalculating the game position value of each node of the game tree \nis done by heuristic functions that incorporate economic \ncalculations of net present value, cash, and strategic layout and so \non. For example railroads in monopoly are known to be \nstrategically effective because they bring constant income even \nthough the income can be smaller than building on other \nproperties.  \n6.2 Details on the CBR Implementation \nThe implementation of the CBR is by using the JColibri2 \nplatform.  JColibri2 is an object-oriented framework in Java for \nbuilding CBR systems that is an evolution of previous work on \nknowledge intensive CBR [14].  \nFor this implementation we need to look into three particular \nclasses of the JColibri2 platform. The StandardCBRApplication, \nConnector, CBRQuery. For a JColibri2 implementation the \nStandardCBRApplication interface needs to be implemented.  \nThe CBR cycle executed accepts an instance of CBRQuery. \nThis class represents a CBR query to the CBR database. The \ndescription component (instance of CaseComponent) represents \nthe description of the case that will be looked up in the database. \nAll \ncases \nand \ncase \nsolutions \nare \nimplementing \nthe \nCaseComponent interface. \nThe JColibri2 platform connects to the CBR database via a \nConnector class. Each connector implements all the necessary \nmethods for accessing the database, retrieval of cases, storing and \ndeletion of cases. This implementation uses a custom XML \nstructure for holding the CBR cases. Since the game will not \nupdate the CBR database only read it, a XML solution satisfies \nthe needs. The XML file to a certain extent is similar to the XML \nrepresentation of the board. We are interested in finding one \nCBRCase that is the most similar case to the situation in the game \nat the time of the search. This procedure is done in the cycle \nmethod of the CBRApplication. The JColibri2 CBR comparison is \ndone by Nearest Neighbor (NN) search method.  \nJColibri2 offers implementations for NN search algorithms \nof simple attributes. These implementations are called local \nsimilarities. For complex attributes like in our case global \ncustomized similarity mechanisms need to be implemented. \nThe MonopolyDescription class [Figure 13] is basically a \nserialization of the GameState. It holds all the information about \nthe state of the board, the players, their amount of cash etc.  \nFigure 13: Class diagram of the Monopoly Case component \nmodels \nOn the other hand the MonopolySolution class holds the \nthree particular attributes that are needed for the planning, the \nplanning Domain, State and TaskList. \nThe game is implemented by using the Model-View-\nController software development pattern. The controller is \nresponsible for implementing the game rules and handling all of \nthe events in the game like roll of dice, input commands for \ntrading, auctioning and etc from the players. The View layer is \nresponsible for displaying the board and all of the input widgets \non to the game screen, and the models are data structures \nrepresenting the game state [Figure 14]. \nFigure 14: Class diagram of the Monopoly models \n6.2.1 Complex Similarity representation in CBR \nThe similarity measurement part of the Nearest Neighbor \nalgorithm JColibri2 is implemented by implementing the \nLocalSimiralrityFunction \nand \nthe \nGlobalSimiralityFunction \ninterface. A local similarity function is applied to simple attributes \nby the NN algorithm, and a global similarity function is applied to \ncompound attributes. In the case of our implementation the \nattributes of the MonopolyDescription are compound attributes \ndescribing the state of the board, number of players, amount of \ncash for every player and etc. Since MonopolyDescription is a \ncustom CaseComponent a global similarity function needs to be \nimplemented to accurately find the distance between different \nCBR cases. \nThe similarity mechanism is inseparable core element of the \nCBR system. This mechanism represents how the CBR decides \nwhich strategy is best suited for the particular situation by \n300\nDIMEA 2008\n3rd International Conference on Digital Interactive Media in Entertainment and Arts\ncalculating the distance or similarity to other cases in the \ndatabase.  \nFor the monopoly implementation we need to consider \nseveral basic strategies. Monopoly is based on investing in \nproperties and receiving revenues from those investments. One of \nthe basic strategies of the game is to build a set of properties that \nwill bring constant income larger than the one of the opponents. \nSo in time the opponents will have to declare bankruptcy. But on \nthe other hand over investment can lead to too stretched resources \nwith low income that will eventually drove the player to \nbankruptcy. To decide on these two we need a clear separation \ninto two groups of cases in the CBR database. The first group of \ncases will represent a situation on the board where the player has \nsignificant income per loop formed of one or more color group \nproperties, maybe railroads, some buildings on them and so on. It \nis important to note that in this case the player is better situated \nthan his opponents so he only needs to survive long enough to win \nthe game. In the other group of cases either the opponent is not \nwell positioned on the board or its opponents are better situated. \nIn this case further investments are necessary to improve the \nsituation so the player can have a chance of winning in the long \nrun.  \nThese metrics can be owning color groups, valuing groups of \nrailroads, evaluating the other opponents as well, and considering \nthe amount of cash. As it is obvious in monopoly the number of \nstreets is not as nearly as important as the combination of streets \nthe player owns. It is also important to note that one CBR case \ndoes not hold only a single strategy in place, but its solution can \nhave multiple different strategic goals. For example one CBR case \nmight simultaneously say buy this land to form a color group but \nalso trade some other unimportant property to increase cash \namount.  \nThe cases do not represent all possible combinations of board \npositions. They are only representation of typical game scenarios. \nThe CBR Case solutions do not give exact instructions in general \nbut rather strategic goals. For example one CBR Solution might \nsay trade the streets that you only have one of each for the ones \nthat you have two of that color already. Then the planner based on \nthe situation on the board needs to decompose this high level task \nto a low level operations. Like offer \"Mediterranean Avenue\" for \n\"Reading Railroad\" and offer $50. The exact amounts and actual \nstreets are left to the planer to evaluate.  \nThe monopoly CBR database is currently in development on \na monopoly clone game called Spaceopoly. The cases are \narchitected based on human player experience and knowledge. \nThere is a plan of making a number of slightly different strategies \nthat differ on the style of playing and then running simulation \ntests that would determine the particular validity of each database \nas well as validity of certain segments of the strategy or even \nparticular cases in the database.  \nThe actual execution of the strategies will not differ from \nstrategy to strategy since the plan execution is more related to the \nstructure and rules of the game than to the actual playing strategy. \n6.3 Details on the Planning Implementation \nFor the purpose of planning this implementation uses a \nmodification of the JSHOP2 planner. The Java Simple \nHierarchical Ordered Planner 2 is a domain independent HTN \nplanning system [15].  \nJSHOP2 uses ordered task decomposition in reducing the \nHTN to list of primitive tasks which form the plans. An ordered \ntask decomposition planner is an HTN planner that plans for tasks \nin the same order that they will be executed. This reduces the \ncomplexity of reasoning by removing a great deal of uncertainty \nabout the world, which makes it easy to incorporate substantial \nexpressive power into the planning algorithm. In addition to the \nusual HTN methods and operators, the planners can make use of \naxioms, can do mixed symbolic/numeric conditions, and can do \nexternal function calls. \n In order for the JSHOP2 planer to generate plans it needs \ntree crucial components: Domain, State and Tasks. The Domain \ndefines all the functionalities that the particular domain offers. \nThese are simple and complex tasks. The complex tasks also \ncalled methods create the hierarchy with the fact that they can be \nevaluated by simple tasks of other complex tasks. This is how a \nhierarchical structure of tasks is formed. The problem reduction is \ndone by reducing the high level complex tasks to simpler until all \nthe tasks are primitive. The list of primitive tasks forms the plan. \nThe State represents the state of the system. It is a simple \ndatabase of facts that represent the state of the system. The State \nis necessary to determine the way the problems or tasks are \nreduced to their primitive level. The reduction is done by \nsatisfying different prerequisites set in the methods; these \nprerequisites are defined in the state. The Tasks are high level \ntasks or methods defined in the Domain. The planner based on the \nState and the goals selects one or more high level tasks that need \nto be reduced to plans [Figure  15]. \nFigure 15: Diagram of a Planner \nThe plans then generate the game moves. The number of \nmoves generated by the plans is just a fraction of the possible \nmoves at that point. This reduces the game tree providing the \nopportunity to generate smaller and deeper game trees and making \nmore efficient decisions in general.  \n7. Conclusion \nEven though the results from the CBR database are not \ncomplete at this time partial strategies are implemented as cases \nand recognized during game play by the CBR system. These \nsmaller local strategies coupled with more global higher level \nstrategies that are particularly important at the beginning of the \ngame would form a complete CBR database and represent a \nknowledge engineered style of playing of the AI player.  \nThe AI Planning approach is a proven method by the tic-tac-\ntoe experiment and is suitable for implementing the strategies \nassociated with the CBR cases. \nThis approach in general benefits from both technologies, \nCBR as well as AI Planning and comprises an elegant solution. \nEven though AI Planning can be enough as a single technology \nfor some simpler problems like tic-tac-toe the complexity of \nMonopoly would mean that the Planner would have to incorporate \nCore Planner \nTasks\nPlan\nState\nInteractive and Adaptable Media\n301\n3rd International Conference on Digital Interactive Media in Entertainment and Arts\nlarge and complex domain and a very big state model. The CBR \napplication helps reduce this complexity by focusing the planning \non smaller domain of the game. Basically the CBR reduces the \noverall goal of the play (wining the game) to smaller more \nconcrete goals suitable to the particular state of the game, thus \nreducing the need for global planning strategies and complex \nplanning domain.  \nFurthermore this symbiosis of technologies gives way for \nmore precise and finely tuned strategies which can be difficult to \ninclude into global plan for the whole game. One simple example \nfor the Monopoly game would be this: Sometimes it\u2019s better to \nstay in jail because rolling double increases the probability of \nlanding on some field (two, four, six, eight, ten or twelve steps \nfrom the jail) that can be of great importance to the rest of the \ngame. These and similar small local strategies can be easily \nrecognized by similar cases in the CBR database.  \nIn other words the system is flexible enough so that new \nstrategies can be incorporated easily missing strategies can be also \nrecognized by the distance metrics as well as wrong assumptions \nin the strategies can be easily recognized. \nOne other important property of the system is that is highly \nconfigurable. The game its self can be diversely different \ndepending on the configuration of the board. Even though the \nplatform is restricted to Monopoly type of games, changing the \nlayout and values of the fields effectively brings completely \ndifferent properties of the game. In addition the CBR database \nrepresents the entire experience of the AI Player. It can be filled \nwith rich set of strategies or even configured with different flavors \nof difficulties of play, this of course coupled with the domain of \nthe planner which can differ from a case to a case as well.  \n8. Future Work \nFurther exploration of this technology would go towards \ncomplete implementation of an AI aware agent for monopoly. \nInitial results from the local cases with more specific strategies \nshow CBR as a capable tool for representing expertise in playing \nthe game. Completing the more general strategies and coupling \nthem with the planning domain will give precise results on the \nbenefits from this architecture. \nThere is also need for exploring the planning of strategies of \nopponents. This task is to some extent different because we \ncannot always expect the opponent to select the best move we \nthink. In the Tic-tac-toe example all possible moves of the \nopponent were taken into consideration, if we used the same \nplanner for the opponent only tie games would result from the \ngame tree. In other words mistakes of the players also need to be \nconsidered.  \nThe CBR Platform brings other functionalities well worth of \nexploring as well. The revision stage of the JColibri2 platform is \nbasically capable of fine tuning strategies or even developing new \nstrategies for the games. A well written underlying AI planning \nmodel with a capable feedback of the game tree evaluation back \nto the CBR revision capability can be an interesting concept in \nautomatic experience acquisition for the AI model. \nThere are also many other fields were combined CBR and \nplanning approach can be incorporated into a problem solution. \nThis combination is analogous in a big extent to a human way of \nreasoning. People in addition to logic of reasoning in situations \nwith lack of information rely to planning strategies and prior \nexperience, exactly the intuition behind CBR \u2013 AI Planning \narchitecture.  \n9. ACKNOWLEDGMENTS \nWe would like to thank Prof. Sofia Tsekeridou for her \ninvolvement in the valuable discussions we had on the topic of \nCBR. \n10. REFERENCES \n[1]\nMinimax. Wikipedia. [Online] [Cited: April 23, 2008.] \nhttp://en.wikipedia.org/wiki/Minimax. \n[2]\nVon Neumann, J: Zur theorie der gesellschaftsspiele Math. \nAnnalen. 100 (1928) 295-320 \n[3]\nAutomated Planning. Wikipedia. [Online] [Cited: April 23, \n2008.] http://en.wikipedia.org/wiki/Automated_planning. \n[4]\nSanchez-Ruiz, Antonio, et al. Game AI for a Turn-based \nStrategy Game with Plan Adaptation and Ontology-based \nretrieval.\n[5]\nK. Erol, J. Hendler, and D. Nau (1994). Semantics for \nhierarchical task-network planning. Technical Report TR-94-\n31, UMIACS. \n[6]\nSmith, S. J. J. and Dana S. Nau, T. A. Throp. A Planning \napproach decrarer play in contract bridge. Computational \nIntelligence. 1996, Vol. 12, 1. \n[7]\nOne Jump Ahead: Challenging Human Supremacy in \nCheckers. J.Schaeffer. s.l. : Springer-Verlag, 1997. \n[8]\nIBM. How Deep Blue works. [Online] 1997. [Cited: April \n23, 2008.] \nhttp://www.research.ibm.com/deepblue/meet/html/d.3.2.html\n[9]\nGhallab, Malik, Nau, Dana and Traverso, Paolo.\nAutomated Planning theory and practice. s.l. : Morgan \nKaufmann Publishers, May 2004. ISBN 1-55860-856-7. \n[10] Case Based Reasoning. Experiences, Lessons and Future. \nLeake, David. s.l. : AAAI Press. MIT Press., 1997. \n[11] Applying case-based reasoning: techniques for enterprise \nsystems. Watson, I. San Francisco, CA, USA : Morgan \nKaufmann Publishers Inc., 1998. \n[12] Plaza, A. Aamodt and E. Case-based reasoning: \nFoundational issues, methodological. AI Communications. \n1994, 7(i). \n[13] Tic-tac-toe. Wikipedia. [Online] [Cited: April 23, 2008.] \nhttp://en.wikipedia.org/wiki/Tic-tac-toe. \n[14] D\u00edaz-Agudo, B. and Gonz\u00e1lez-Calero, P. A. An \narchitecture for knowledge intensive CBR systems. Advances \nin Case-Based Reasoning \u2013 (EWCBR\u201900). New York : \nSpringer-Verlag, Berlin Heidelberg, 2000. \n[15] Ilghami, Okhtay and Nau, Dana S. A General Approach to \nSynthesize Problem-Specific Planners. 2003. \n302\nDIMEA 2008\n3rd International Conference on Digital Interactive Media in Entertainment and Arts\n",
    "pdf_url": "",
    "references": [
      "[1]",
      "Minimax. Wikipedia. [Online] [Cited: April 23, 2008.] ",
      "http://en.wikipedia.org/wiki/Minimax. ",
      "[2]",
      "Von Neumann, J: Zur theorie der gesellschaftsspiele Math. ",
      "Annalen. 100 (1928) 295-320 ",
      "[3]"
    ],
    "publication_date": "05-11-2023"
  },
  {
    "titre": "Semantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model",
    "resume": "The emergence of novel types of communication, such as email, hasbeen brought on by the development of the internet, which radicallyconcentrated the way in that individuals communicate socially andwith one another. It is now establishing itself as a crucial aspect ofthe communication network which has been adopted by a varietyof commercial enterprises such as retail outlets. So in this researchpaper, we have built a unique spam-detection methodology basedon email-body sentiment analysis. The proposed hybrid model isput into practice and preprocessing the data, extracting the proper-ties, and categorizing data are all steps in the process. To examinethe emotive and sequential aspects of texts, we use word embed-ding and a bi-directional LSTM network. this model frequentlyshortens the training period, then utilizes the Convolution Layer toextract text features at a higher level for the Bi LSTM network. Ourmodel performs better than previous versions, with an accuracyrate of 9798%. In addition, we show that our model beats not justsome well-known machine learning classifiers but also cutting-edgemethods for identifying spam communications, demonstrating itssuperiority on its own. Suggested Ensemble models results areexamined in terms of recall, accuracy, and precision",
    "auteurs": [
      "Khushbu Doulani",
      "GRU",
      "Shivangi Sachan",
      "Khushbu Doulani",
      "Mainak Adhikari",
      "Noida",
      "Decision Trees",
      "Bi-LSTM",
      "GRU",
      "BiLSTM+GRU"
    ],
    "institutions": [
      "Mainak Adhikari Department of CSEIIIT LucknowUP, ",
      "Department of CSEIIIT Lucknow Lucknow, UP, "
    ],
    "mots_cles": [
      "Dataset",
      " KNN",
      " Gaussian Naive Bayes",
      " LSTM",
      " SVM",
      " Bidirectional"
    ],
    "texte_integral": "Semantic Analysis and Classification of Emails through\nInformative Selection of Features and Ensemble AI Model\nShivangi Sachan\u2217\nDepartment of CSE\nIIIT Lucknow\nLucknow, UP, India\nmcs21025@iiitl.ac.in\nKhushbu Doulani\nVardhaman College of Engineering\nHyderabad, India\nkhushidoulani@gmail.com\nMainak Adhikari\nDepartment of CSE\nIIIT Lucknow\nUP, India\nmainak.ism@gmail.com\nABSTRACT\nThe emergence of novel types of communication, such as email, has\nbeen brought on by the development of the internet, which radically\nconcentrated the way in that individuals communicate socially and\nwith one another. It is now establishing itself as a crucial aspect of\nthe communication network which has been adopted by a variety\nof commercial enterprises such as retail outlets. So in this research\npaper, we have built a unique spam-detection methodology based\non email-body sentiment analysis. The proposed hybrid model is\nput into practice and preprocessing the data, extracting the proper-\nties, and categorizing data are all steps in the process. To examine\nthe emotive and sequential aspects of texts, we use word embed-\nding and a bi-directional LSTM network. this model frequently\nshortens the training period, then utilizes the Convolution Layer to\nextract text features at a higher level for the BiLSTM network. Our\nmodel performs better than previous versions, with an accuracy\nrate of 97\u201398%. In addition, we show that our model beats not just\nsome well-known machine learning classifiers but also cutting-edge\nmethods for identifying spam communications, demonstrating its\nsuperiority on its own. Suggested Ensemble model\u2019s results are\nexamined in terms of recall, accuracy, and precision\nCCS CONCEPTS\n\u2022 Computer systems organization \u2192 Embedded systems; Re-\ndundancy; Robotics; \u2022 Networks \u2192 Network reliability.\nKEYWORDS\nDataset, KNN, Gaussian Naive Bayes, LSTM, SVM, Bidirectional\nLSTM, GRU, Word-Embeddings, CNN\nACM Reference Format:\nShivangi Sachan, Khushbu Doulani, and Mainak Adhikari. 2023. Semantic\nAnalysis and Classification of Emails through Informative Selection of\nFeatures and Ensemble AI Model. In 2023 Fifteenth International Conference\non Contemporary Computing (IC3-2023) (IC3 2023), August 03\u201305, 2023, Noida,\nIndia. ACM, New York, NY, USA, 7 pages. https://doi.org/10.1145/3607947.\n3607979\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nIC3 2023, August 03\u201305, 2023, Noida, India\n\u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0022-4/23/08...$15.00\nhttps://doi.org/10.1145/3607947.3607979\n1\nINTRODUCTION\nOver the past few years, a clear surge of both the amount of spam-\nmers as well as spam emails. This is likely due to a fact that the\ninvestment necessary for engaging in the spamming industry is\nrelatively low. As a result of this, we currently have a system that\nidentifies every email as suspicious, which has caused major expen-\nditures in the investment of defense systems [12]. Emails are used\nfor online crimes like fraud, hacking, phishing, E-mail bombing, bul-\nlying, and spamming. [16]. Algorithms that are based on machine\nlearning (ML) are now the most effective and often used approach to\nthe recognition of spam. Phishing, which is defined as a fraudulent\nattempt to acquire private information by masquerading as a trust-\nworthy party in electronic communication, has rapidly advanced\npast use of simple techniques and the tactic of casting a wide net;\ninstead, spear phishing uses a variety of sophisticated techniques\nto target a single high-value individual. Other researchers used NB,\nDecision Trees, and SVM to compare the performance of supervised\nML algorithms for spam identification [6]. Spam emails clog up re-\ncipients\u2019 inboxes with unsolicited communications, which frustrate\nthem and push them into the attacker\u2019s planned traps [7]. As a re-\nsult, spam messages unquestionably pose a risk to both email users\nand the Internet community. In addition, Users may occasionally\nread the entire text of an unsolicited message that is delivered to\nthe target users\u2019 inboxes without realizing that the message is junk\nand then choosing to avoid it. Building a framework for email spam\ndetection is the aim of this project. In this approach, we combine the\nWord-Embedding Network with the CNN layer, Bi-LSTM, and GRU\n(BiLSTM+GRU). CNN layers are used to speed up training time\nbefore the Bi-LSTM network, and more advanced textual character-\nistics are extracted with the use of this network in comparison to\nthe straight LSTM network, in less time. Gated recurrent neural net-\nworks (GRUs) are then added because they train more quickly and\nperform better for language modeling. To evaluate and investigate\nvarious machine learning algorithms for predicting email spam,\nand develop a hybrid classification algorithm to filter email spam\nbefore employing an ensemble classification algorithm to forecast\nit. To put an innovative technique into practice and compare it to\nthe current method in terms of various metrics. Ensemble learn-\ning, a successful machine learning paradigm, combines a group of\nlearners rather than a single learner to forecast unknown target\nattributes. Bagging, boosting, voting, and stacking are the four main\ntypes of ensemble learning techniques. To increase performance,\nan integrated method and the combining of two or three algorithms\nare also suggested. Extraction of text-based features takes a long\ntime. Furthermore, it can be challenging to extract all of the crucial\ninformation from a short text. Over the span associated with this\n181\nIC3 2023, August 03\u201305, 2023, Noida, India\nSachan et al.\nresearch, we utilize Bidirectional Large Short-Term Memories (Bi-\nLSTM) in conjunction with Convolutional Neural Networks (CNN)\nto come up with an innovative method to the detection of spam.\nBagging and boosting approaches were widely preferred in this\nstudy. Contribution and paper organization is as follows: section 1.1\ndescribes literature study, section 1.2 describe motivation for this\nresearch work, section 2 sketches procedure of details implemen-\ntation, Section 3 present experimental setup, dataset description\nand evaluation metrics, and section 4 summarizing outcomes of the\nexperiment.\n1.1\nRelated Work\nEmail is indeed the second most frequently utilized Internet appli-\ncation as well as the third most common method of cyberbullying,\nclaims one study. Cybercriminals exploit it in a number of ways,\nincluding as sending obscene or abusive messages, adding viruses\nto emails, snatching the private information of victims, and ex-\nposing it to a broad audience. Spam letters made up 53.95% of all\nemail traffic in March 2020. We examine three main types of un-\nlawful emails in our study. First are fake emails, which are sent\nto manipulate recipients to submit sensitive information. The sec-\nond as being cyberbullying\u2019s use of harassing emails to threaten\nindividuals. Suspicious emails that describe illegal activities belong\nto the third category. Many researchers have earlier contributed\nmassively to this subject. The researcher claims there is some proof\nthat suspicious emails were sent before to the events of 9/11. [14].\nWhen it comes to data labeling, there are also convinced rule-based\napproaches and technologies ( like VADER) that are used, even\nthough their efficiency of the are together is adversely affected. A\nhidden layer, which itself is essential for vectorization, is the top\nlayer of the model. We use oversampling methods for this minority\nclass because of the absence of data. Sampling techniques can help\nwith multicollinearity, but they have an impact on simulation re-\nsults. Oversampling causes data to be randomly repeated, which\naffects test data because dividing data may result in duplicates. Un-\ndersampling may result in the loss of some strong information. In\norder to advance email research, it is crucial to provide datasets on\ncriminal activity. P. Garg et al. (2021) [5], which revealed that spam\nin an email was detected in 70 percent of business emails, spam was\nestablished as an obstacle for email administrators. Recognizing\nspam and getting rid of it were the primary concerns, as spam can\nbe offensive, may lead to other internet sites being tricked, which\ncan offer harmful data, and can feature those who are not particu-\nlar with their content using NLP. To select the best-trained model,\neach mail transmission protocol requires precise and effective email\nclassification, a machine learning comparison is done. Our study\nhas suggested that innovative deep learning outperforms learning\nalgorithms like SVM and RF. Current studies on the classification\nof emails use a variety of machine learning (ML) techniques, with\na few of them focusing on the study of the sentiments consisted of\nwithin email databases. The lack of datasets is a significant obstacle\nto email classification. There are few publicly accessible E-mail\ndatasets, thus researchers must use these datasets to test their hy-\npotheses or gather data on their own. Authors[15] describe supplied\ntwo-phased outlier detection models to enhance the IIOT network\u2019s\ndependability. Artificial Neural Network, SVM, Gaussian NB, and\nRF (random forest) ensemble techniques were performed to forecast\nclass labels, and the outputs were input into a classifying unit to\nincrease accuracy. A method for content-based phishing detection\nwas presented by the authors in [2], to classify phishing emails,\nthey employed RF. They categorize spam and phishing emails. They\nenhanced phishing email classifiers with more accurate predictions\nby extracting features. They showed some effective Machine learn-\ning spam filtering techniques. When the PCA method is used, it will\nlower the number of features in the dataset. The collected features\ngo through the PCA algorithm to reduce the number of features.\nThe PCA method is used to make a straightforward representation\nof the information which illustrates the amount of variability there\nis in the data. The authors of [20] presented the Fuzzy C-means\nmethod for classifying spam email. To stop spam, they implemented\na membership threshold value. A methodology to identify unla-\nbeled data was put forth by the authors of [1] and applied motive\nanalysis to the Enron data collection. They divided the data into\ncategories that were favorable, negative, and neutral. They grouped\nthe data using k-means clustering, an unsupervised ML technique\nand then classified it using the supervised ML techniques SVM and\nNB. Hina, Maryam, and colleagues (2021) implemented Sefaced:\nDeep learning-based semantic analysis and categorization of e-mail\ndata using a forensic technique. For multiclass email classification,\nSeFACED employs a Gated Recurrent Neural Network (GRU) based\non Long Short-Term Memory (LSTM). Different random weight ini-\ntializations affect LSTMs [9]. Zhang, Yan, et al.(2019) Experiments\non three-way game-theoretic rough set (GTRS) email spam filter-\ning show that it is feasible to significantly boost coverage without\ndecreasing accuracy [23]. According to Xia et al. [22], SMS spam\nhas been identified using machine learning model such as naive\nbayes , vector-space modeling, support vector machines (SVM),\nlong selective memory machines (LSTM), and convolutional neural\nnetworks including every instance of a method for categorizing\ndata. Elshoush, Huwaida, et al. (2019) Using adaboost and stochastic\ngradient descent (sgd) algorithms for e-mail filtering with R and\norange software spam [3]. Orange software was used to create the\nclassifications, which included Adaboost and SGD. The majority of\nresearchers focused on text-based email spam classification meth-\nods because image-based spam can be filtered in the early stages\nof pre-processing. There are widely used word bag (BoW) model,\nwhich believes that documents are merely unordered collections\nof words, is the foundation for these techniques. Kumaresan [11]\nexplains SVM with a cuckoo search algorithm was used to extract\ntextual features for spam detection. Renuka and Visalakshi made\nuse of svm [17] spam email identification, followed by selecting\nfeatures using Latent Semantic Indexing (LSI). Here we have used\nlabeled dataset to train the hybrid classifier. We used TF-IDF for\nfeature extraction [20] and Textual features for spam detection\nwere extracted using SVM and a cuckoo search algorithm. [4] for\nfiltering out the spam email. Combining the integrated strategy to\nthe pure SVM and NB methods, overall accuracy is really improved.\nMoreover, accurate detection for spam email has been proposed\nusing the Negative Selection Algorithm (NSA) and Particle Swarm\nOptimization\u2019s (PSO) algorithm. PSO is used in this instance to\nimprove the effectiveness of the classifier.\n182\nSemantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model\nIC3 2023, August 03\u201305, 2023, Noida, India\n1.2\nMotivation and Novelty\nEmail is most common form of communication between people\nin this digital age. Many users have been victims of spam emails,\nand their personal information has been compromised. The email\nClassification technique is employed to identify and filter junk\nmail, junk, and virus-infected emails prior to reach a user\u2019s inbox.\nExisting email classification methods result in irrelevant emails\nand/or the loss of valuable information. Keeping these constraints\nin mind, the following contributions are made in this paper:\n\u2022 Text-based feature extraction is a lengthy process. Further-\nmore, extracting every important feature from text is difficult.\nIn this paper, we show how to employ GRU with Convo-\nlutional Neural Networks and Bidirectional-LSTM to find\nspam.\n\u2022 Used Word-Embeddings, BiLSTM, and Gated Recurrent Neu-\nral Networks to examine the relationships, sentimental con-\ntent, and sequential way of email contents.\n\u2022 Applied CNN before the Bi-LSTM network, training time can\nbe sped up. This network can also extract more advanced\ntextual features faster than the Bi-LSTM network alone when\ncombined with the GRU network.\n\u2022 We use Enorn Corpora datasets and compute precision, re-\ncall, and f-score to assess how well the suggested technique\nperforms. Our model outperforms several well-known ma-\nchine learning techniques as well as more contemporary\nmethods for spam message detection.\n2\nPROPOSED SYSTEM ARCHITECTURE AND\nMODEL\nE-mail is a valuable tool for communicating with other users. Email\nallows the sender to efficiently forward millions of advertisements\nat no cost. Unfortunately, this scheme is now being used in a variety\nof organizations. As a result, a massive amount of redundant emails\nis known as spam or junk mail, many people are confused about the\nemails in their E- Mailboxes. Each learning sequence is given for-\nward as well as backward to two different LSTM networks that are\nattached to the same outputs layer in order for bidirectional Lstms\nto function. This indicates that the Bi-LSTM has detailed sequential\ninformation about all points before and following each point in a\nspecific sequence. In other words, we concatenate the outputs from\nboth the forward and the backward LSTM at each time step rather\nthan just encoding the sequence in the forward direction. Each\nword\u2019s encoded form now comprehends the words that come before\nand after it. This is a problem for the Internet community. The di-\nagram depicts various stages that aid in the prediction of email spam:\nBecause real-world data is messy and contains unnecessary infor-\nmation and duplication, data preprocessing is critical in natural\nlanguage processing (NLP). The major preprocessing steps are de-\npicted below.\n2.1\nNLP Tokenization\nTokenization of documents into words follows predefined rules.\nThe tokenization step is carried out in Python with spacy library.\n2.2\nStop Words Removal\nStop words appear infrequently or frequently in the document, but\nthey are less significant in terms of importance. As a result, these\nare removed to improve data processing.\n2.3\nText Normalization\nA word\u2019s lexicon form or order may differ. Thus, they must all be\nchanged to their root word to be correctly analyzed. Lemmatization\nand stemming are the two methods that can be used for normal-\nization. When a word\u2019s final few characters are removed to create\na shorter form, even if that form has no meaning, the procedure\nis known as stemming. lemmatization [21] is a mixture of corpus-\nbased an rule-based methods, and it retains the context of a term\nwhile changing it back to its root.\n2.4\nFeature Extraction\nfeature extraction which transforms the initial text into its features\nso that it may be used for modeling after being cleaned up and\nnormalized. Before predicting them, we use a specific way to give\nweights to specific terms in our document. While it is simple for a\ncomputer to process numbers, we choose to represent individual\nwords numerically. In such cases, we choose word embeddings. IDF\nis the count of documents containing the term divided by the total\nnumber of documents, and occurrence is the amount of instances a\nword appears in a document. We derive characteristics based on\nequations. 1,2,3,4,5, and 6. We use equations to derive properties.\n\ud835\udc47 \ud835\udc53 \ud835\udc3c\ud835\udc51\ud835\udc53 = \ud835\udc61\ud835\udc53 \u2217\n\ufffd 1\n\ud835\udc51\ud835\udc53\n\ufffd\n(1)\n\ud835\udc47 \ud835\udc53 \ud835\udc3c\ud835\udc51\ud835\udc53 = \ud835\udc61\ud835\udc53 \u2217 Inverse(\ud835\udc51\ud835\udc53 )\n(2)\n\ud835\udc47 \ud835\udc53 \ud835\udc3c\ud835\udc51\ud835\udc53 (\ud835\udc61,\ud835\udc51, \ud835\udc37) = \ud835\udc47 \ud835\udc53 (\ud835\udc61,\ud835\udc51).\ud835\udc3c\ud835\udc51\ud835\udc53 (\ud835\udc61, \ud835\udc37)\n(3)\n\ud835\udc47\ud835\udc3c\ud835\udc51\ud835\udc53 (\ud835\udc61,\ud835\udc51) = log\n\ud835\udc41\n|\ud835\udc51\ud835\udf16\ud835\udc37\ud835\udc61\ud835\udf16\ud835\udc37|\n(4)\nA word2vec neural network-based approach is the method that is\nutilized for this goal as the tool. The following equation, referred\nto as 5, shows how word2vec handles word context through the\nuse of probability-accurate measurements. Here letter D stands for\nthe paired-wise display of a set of words, while the letters w and c0\nor c1 represent paired word context that originated from a larger\ncollection of set D.\n\ud835\udc43 (\ud835\udc37 = 1 | \ud835\udc64,\ud835\udc5011:\ud835\udc58) =\n1\n1 + \ud835\udc52\u2212(\ud835\udc64\u00b7\ud835\udc5011+\ud835\udc64\u00b7\ud835\udc5012+...+\ud835\udc64\u00b7\ud835\udc501\ud835\udc58)\n(5)\n\ud835\udc43 (\ud835\udc37 = 1 | \ud835\udc64,\ud835\udc501:\ud835\udc58) =\n1\n1 + \ud835\udc52\u2212(\ud835\udc64\u00b7\ud835\udc500)\n(6)\n183\nIC3 2023, August 03\u201305, 2023, Noida, India\nSachan et al.\n2.5\nWord-Embeddings\nWord-Embedding helps to improve on the typical \"bag-of-words\"\nworldview, which requires a massive sparse feature vector to score\nevery word individually to represent this same entire vocabulary.\nThis perception is sparse because the vocabulary is large, and each\nword or document is defined by a massive vector. Using a word\nmap-based dictionary, word embedding needs to be converted terms\n(words) into real value feature vectors. There are two basic issues\nwith standard feature engineering techniques for deep learning.\nData is represented using sparse vectors, and the second is that\nsome of the meanings of words are not taken into consideration.\nSimilar phrases will have values in embedding vectors that are\nalmost real-valued. The Input length in our proposed study is set\nto 700 for our suggested model. If the texts seemed to be integer\nencoded with value systems between 10 and 20, the vocabulary\ndistance would be 11. Our data is encoded as integers, and the input\nand output dimensions are both set to 50,000. The embedding layer\noutcome will be used in successive layers and for BiLSTM and GRU\nlayers.\n2.6\nMachine Learning Model\nWithin the scope of the research, we are using the subsequent ma-\nchine learning techniques, to examine and compare the overall\nefficacy of our suggested Bi-LSTM strategy: Support Vector Ma-\nchine, Gaussian NB, Logistic Regression, K - nearest neighbors, and\nRandom Forest (RF).\n2.7\nConvolution Network\nThe popular RNN model generally performs well but takes too\nlong to train the model incorporating the textual sequential data.\nWhen a layer is added after the RNN layer, the model\u2019s learning\nduration is considerably decreased. Higher-level feature extraction\nis another benefit. [19] additionally possible using the convolutional\nlayer. In essence, the convolution layer looks for combinations of\nthe various words or paragraphs in the document that involve the\nfilters. We use features with 128 dimensions and a size 10 for each.\nFor this task, the Relu activation function is utilized. After that, the\none-dimensional largest pooling layers with a pooling size of 4 are\nput on the data in order to obtain higher-level features.\n2.8\nBiLSTM Network with GRU\nRecurrent Neural Network (RNN) technique of text sentiment anal-\nysis is particularly well-liked and frequently applied. Recurrent\nneural networks (RNN) surpass conventional neural networks. be-\ncause it can remember the information from earlier time steps\nthanks to its memory. A state vector is combined with an RNN\u2019s\ndata to create a new state vector. The resulting state vector uses the\npresent to recollect past knowledge. The RNN is straightforward\nand is based on the following equations:\n\u210e\ud835\udc61 = tanh (\ud835\udc4a\u210e\u210e\u210e\ud835\udc61\u22121 +\ud835\udc4a\ud835\udf0b\u210e\ud835\udc65\ud835\udc61)\n(7)\n\ud835\udc66\ud835\udc61 = \ud835\udc4a\u210e\ud835\udc66\u210e\ud835\udc61\n(8)\nThe vanilla RNN[18]is not very good at remembering previous\nsequences. In addition to that, RNN struggles with diminishing\ngradient descent. A kind of RNN is a long short-term recall network\n(LSTM), solves a vanishing gradient descent problem and learns\nlong-term dependencies[10]. LSTM was actually created to address\nthe problem of long-term reliance. LSTM has the unique ability to\nrecall. The cell state is the LSTM model\u2019s central concept. With\nonly a small amount of linear interaction, the cell state follows the\nsequence essentially unmodified from beginning to end. gate of\nan LSTM is also significant. Under the command of these gates,\ninformation is safely inserted to or eliminated from the cell stated.\nThe following equations are used by the LSTM model to update\neach cell:\n\ud835\udc53\ud835\udc61 = \ud835\udf0e\n\ufffd\n\ud835\udc4a\ud835\udc53 \u00b7 [\u210e\ud835\udc61\u22121,\ud835\udc65\ud835\udc61] + \ud835\udc4f\ud835\udc53\n\ufffd\n(9)\nIn this case, Xt denotes input, and ht is the hidden state at the t\ntime step. The following is the revised cell state Ct:\n\ud835\udc56t = \ud835\udf0e (\ud835\udc4a\ud835\udc56 [\u210e\ud835\udc61\u22121,\ud835\udc65\ud835\udc61] + \ud835\udc4f\ud835\udc56)\n(10)\n\ud835\udc36\ud835\udc47 = tanh (\ud835\udc4a\ud835\udc50 [\u210e\ud835\udc61\u22121,\ud835\udc65\ud835\udc61] + \ud835\udc4f\ud835\udc50\ud835\udc61)\n(11)\n\ud835\udc36\ud835\udc61 = \ud835\udc53\ud835\udc61 \u2217 \ud835\udc36\ud835\udc61\u22121 + \ud835\udc56\ud835\udc61 \u2217 \ud835\udc36\ud835\udc47\n(12)\nHere, we may compute the output and hidden state at t time steps\nusing the point-wise multiplication operator *.\n\ud835\udc5c\ud835\udc61 = \ud835\udf0e (\ud835\udc4a\ud835\udc5c \u00b7 [\u210e\ud835\udc61\u22121,\ud835\udc65\ud835\udc61] + \ud835\udc4f\ud835\udc5c)\n(13)\n\u210e\ud835\udc61 = \ud835\udc5c\ud835\udc61 \u2217 tanh (\ud835\udc36\ud835\udc61)\n(14)\nDue to the reality it only considers all prior contexts from the\npresent one, LSTM does have a few drawbacks. As a result of this,\nit may accept data from preceding time steps through LSTM as well\nas RNN. Therefore, in order to avoid this issue, further improve-\nments are carried out with the help of a bidirectional recurrent\nneural network(Bi-RNN). BiRNN [13] can handle two pieces of in-\nformation from both the front and the back. Bi-LSTM is created\nby combining the Bi-RNN and LSTM. As a result, operating LSTM\nhas advantages such as cell state storage so that BiRNN have way\nto acknowledge from the context before and after. As a conse-\nquence of this, it provides the Bi-LSTM with the advantages of an\nLSTM with feedback for the next layer. Remembering long-term\ndependencies is a significant new benefit of Bi-LSTM. The output,\nwhich is a feature vector, will be based on the call state. Finally,\nwe forecast the probability of email content as Normal, Fraudu-\nlent, Harassment, and Suspicious Emails using as an input to the\nsoftmax activation function, which is a weighted sum of the dense\nlayer\u2019s outputs. To regulate the information flow, GRU employs\nthe point-wise multiplying function and logistic sigmoid activation.\nThe GRU has hidden states of storage memory and does not have\ndistinct memory cells or units for state control. The W, U, and b\nvectors, which stand for weights, gates, and biases, respectively, are\ncrucial variables that must be calculated during the creation of the\nGRU model. For training reasons, the pre-trained word embedding\nknown as the Glove vector is used. They made it clear that GRU\nis the superior model when there is a large amount of training\ndata for textual groups and word embedding is available. BiLSTM,\nCNN, and GRU is required so as to compensate for the deletion\nof the document\u2019s long-term and short-term connections. In our\ncase, the embedding dimension, maximum sequence length, and\nlexicon size were used to start the LSTM embedding layer in three\nseparate LSTM models. The input vector was modified to make it\nappropriate for such a Conv1D layer, prior situations\u2019 sequences are\nreturned by LSTM layer. The \"return sequences\" of the LSTM layer\nmust be set to False when the subsequent state is free of the gated\n184\nSemantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model\nIC3 2023, August 03\u201305, 2023, Noida, India\narchitecture. Quantity of learning parameters must be taken into\nconsideration. A 350-unit LSTM layer was set - up, and different\nLSTM unit combinations were tested. More importantly, because\nit has more parts, the model made with BiLSTM will take longer\nto train. Bidirectional LSTM is the name of a particular kind of\nrecurrent neural network that is primarily used for the processing\nof natural languages. (BiLSTM). It is able to use data from both\nsides, and, in contrast to regular LSTM, it enables input flow in\nboth directions. It is an effective instrument for demonstrating the\nlogical relationships between words and phrases, and this involves\nboth the forward and backward directions of the sequence. In con-\nclusion, BiLSTM works by adding one extra layer of LSTM, causing\nthe information flow to travel in the other direction. It only denotes\nthat the input sequence runs in reverse at the next LSTM layer. Mul-\ntiple operations, including averaging, summation, multiplication,\nand concatenation, are then applied to the results of the two LSTM\nlayers. The gated design of Bi-LSTM and GRU networks solves\nthe disappearing gradient and exploding problems. A good way to\nhandle more long sequences is to use Bi-LSMT and GRU together.\nGRU works well with datasets that don\u2019t have text. In two to three\nrounds, the complicated CNN+BiLSTM+GRU model learns the long\nsequence of email text well. We have used word embedding, cnn,\nbidirectional lstm and gru networks as our three building blocks\nto separate email messages based on their sentiment and text\u2019s\nsequential features. Also, we succinctly demonstrate below why\nthese blocks help identify email spam:\n\u2022 First, We have used the Sequence - to - sequence Lstm as the\ncurrent block in the networks since it can retrieve both the\nprevious and next sequences from the current. More so than\na straightforward LSTM network, it can also recognize and\nextract text sentiment and sequential properties.\n\u2022 Second, we extract the more complex and advanced charac-\nteristics for Bi-LSTM network using Convolutional Network\nblock, which is the network\u2019s second block after the Bi-LSTM\nblock. Bi-LSTM takes a long time to extract text-based fea-\ntures, hence one of the reasons for using this block is to\nreduce the network\u2019s overall training time.\n3\nEXPERIMENTAL EVALUATION\n3.1\nExperimental Setup\nWe divided the information into training and testing groups of\n80/20. We divided the remaining 20% of the 80 percent training\ndata into test data for the model. Construct, compute, and evaluate\nthe efficacy of the suggested method using the Pythonic packages\nKeras, as TensorFlow and Scikit learn.\n3.2\nDataset Description\nEmail spam detection is the foundation of this research project. The\ndataset includes normal emails from the Enron corpora, deceptive\nemails from phished email corpora, harassment emails chosen from\nhate speech, and the offensive dataset. Only the content of the email\nbody is used for analysis; all header information, including sender,\ntopic, CC, and BCC, are eliminated. Word2vector, TF-IDF, and Word\nEmbedding are used to extract characteristics from the email mes-\nsage and classify them. This dataset[8] is publicly available. The\npresented model is implemented using Python, and several metrics,\nincluding accuracy, precision, and recall, are used to examine the\noutcomes.\n3.3\nEvaluation Metrics and Results\nClassifier performance is assessed Using metrics such as accuracy,\nprecision, and recall. Four terms make up a confusion matrix that\nis used to calculate these metrics.\n\u2022 True positives (TP) are positive values that have been accu-\nrately assigned the positive label.\n\u2022 The negative values that are accurately identified as negative\nare known as True Negatives (TN).\n\u2022 True Negative values are those that can be accurately identi-\nfied as being negative (TN).\n\u2022 Positive readings that have been mistakenly labeled as nega-\ntive are known as False Negatives (FN).\nAssess the efficacy of the suggested model is listed below:\n3.3.1\nAccuracy. Accuracy reveals how frequently the ML model\nwas overall correct.\nAccuracy =\n\ud835\udc47\ud835\udc43 +\ud835\udc47\ud835\udc41\n\ud835\udc47\ud835\udc43 +\ud835\udc47\ud835\udc41 + \ud835\udc39\ud835\udc43 + \ud835\udc39\ud835\udc41\n(15)\n3.3.2\nPrecision. The accuracy of the model gauges how effectively\nit can predict a specific category.\nPrecision =\n\ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc43\n(16)\n3.3.3\nRecall. Recall tells us how often the model was able to rec-\nognize a specific category.\nRecall =\n\ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc41\n(17)\nModel\nAccuracy\nPrecision\nRecall\nGaussian NB\n91.3\n90.1\n91.8\nRandom Forest\n88.41\n90\n88\nKNN\n86.6\n89\n87\nSVM\n92.4\n91\n92\nLSTM\n95.2\n95\n95.7\nProposed\nEnsemble\n(CNN,BiLSTM+GRU)\n97.32\n95.6\n95.3\nTable 1: Differet Model\u2019s Score on Test Data\nAccuracy, Precision, and Recall metrics are computed. In the\ngiven Table 1 where six different classifiers are Gaussian NB, Ran-\ndom Forest, KNN, SVM, LSTM, and Propose Ensemble Hybrid\nModel (CNN+BiLSTM+GRU) have been used in this work. In the\nCNN, Bi-LSTM, and GRU architectures which enable sequence pre-\ndiction, CNN strands for feature extraction on data input which are\ncombined with LSTM. It requires less time training and a higher\nexpandable model. Any bottlenecks are created by predictions and\nthe increasing number of distinct units of information. This model\nis useful for dealing with issue-related classifications that consist\nof two or more than two classes. So suggested Ensemble model, out\nof these six classifiers, produces more accurate findings.\n185\nIC3 2023, August 03\u201305, 2023, Noida, India\nSachan et al.\nFigure 1: Performance Analysis\n3.4\nComparative Analysis\nA model\u2019s ability to fit new data is measured by the validation\nloss, whereas its ability to fit training data is determined by the\ntraining loss. The two main variables that decide whether in which\nlearning is efficient or not are validation loss and training loss.\nLSTM and Suggested Ensemble hybrid Models have equivalent loss\nand accuracy. In this context, we are contrasting the LSTM with the\nproposed model (CNN, Bilstm, and GRU) in terms of their respective\nvalidation accuracies and losses. The model\u2019s accuracy was at its\nhighest after 14 epochs of operation when it achieved an accuracy\nof roughly 97-98% while minimizing model loss.\nFigure 2: LSTM Model Training and Validation Accuracy\nFigure 3: LSTM Model Training and Validation Loss\nFigure 4: Ensemble Model (CNN,BiLSTM+GRU) Training\nand Validation Accuracy\nFigure 5: Ensemble Model (CNN,BiLSTM+GRU)Training\nand Validation Loss\n186\nSemantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model\nIC3 2023, August 03\u201305, 2023, Noida, India\nIn this Proposed ensemble hybrid model\u2019s train accuracy is 98.7%\nValidation accuracy is 97.32% and LSTM has train accuracy of 97.41%\nand validation accuracy is 95.2%. So based on figures 3 and 5 indicate\nthe validation loss for LSTM and the proposed ensemble hybrid\nmodel to be 0.93 and 0.84, respectively, and figures 2 and 4 show the\nvalidation accuracy to be 95.2% and 97.3%, respectively. LSTM and\nthe proposed hybrid model used ensemble artificial intelligence,\nwith the proposed hybrid model outperforming the LSTM. We\ndecide on dense architecture as the final model for identifying the\ntext messages as spam or nonspam based on loss, accuracy, and the\naforementioned charts. The loss and accuracy over epochs are more\nstable than LSTM, and the Proposed classifier has a straightforward\nstructure.\n4\nCONCLUSION\nThe model is composed of four networks Word-Embeddings, CNN,\nBi-LSTM, and GRU. We may train the model more quickly by using\nthe convolutional layer first, followed by the word-embedding layer,\nand then the BiLSTM network. The Bidirectional LSTM network\nalso has higher-level properties that we can extract. We have used\na bidirectional LSTM(BiLSTM)and GRU network to memorize a\nsentence\u2019s contextual meaning and sequential structure, which im-\nproves the model\u2019s performance accuracy to roughly 97.32 percent.\nREFERENCES\n[1] Rayan Salah Hag Ali and Neamat El Gayar. 2019. Sentiment analysis using unla-\nbeled email data. In 2019 International Conference on Computational Intelligence\nand Knowledge Economy (ICCIKE). IEEE, 328\u2013333.\n[2] Ali Shafigh Aski and Navid Khalilzadeh Sourati. 2016. Proposed efficient algo-\nrithm to filter spam using machine learning techniques. Pacific Science Review A:\nNatural Science and Engineering 18, 2 (2016), 145\u2013149.\n[3] Huwaida T Elshoush and Esraa A Dinar. 2019. Using adaboost and stochastic\ngradient descent (sgd) algorithms with R and orange software for filtering e-mail\nspam. In 2019 11th Computer Science and Electronic Engineering (CEEC). IEEE,\n41\u201346.\n[4] Weimiao Feng, Jianguo Sun, Liguo Zhang, Cuiling Cao, and Qing Yang. 2016. A\nsupport vector machine based naive Bayes algorithm for spam filtering. In 2016\nIEEE 35th International Performance Computing and Communications Conference\n(IPCCC). IEEE, 1\u20138.\n[5] Pranjul Garg and Nancy Girdhar. 2021. A Systematic Review on Spam Filtering\nTechniques based on Natural Language Processing Framework. In 2021 11th Inter-\nnational Conference on Cloud Computing, Data Science & Engineering (Confluence).\nIEEE, 30\u201335.\n[6] Adam Kavon Ghazi-Tehrani and Henry N Pontell. 2021. Phishing evolves: Ana-\nlyzing the enduring cybercrime. Victims & Offenders 16, 3 (2021), 316\u2013342.\n[7] Radicati Group et al. 2015. Email Statistics Report 2015\u20132019. Radicati Group.\nAccessed August 13 (2015), 2019.\n[8] Maryam Hina, Mohsin Ali, and Javed. 2021. Sefaced: Semantic-based forensic\nanalysis and classification of e-mail data using deep learning. IEEE Access 9\n(2021), 98398\u201398411.\n[9] Maryam Hina, Mohsin Ali, Abdul Rehman Javed, Fahad Ghabban, Liaqat Ali\nKhan, and Zunera Jalil. 2021. Sefaced: Semantic-based forensic analysis and\nclassification of e-mail data using deep learning. IEEE Access 9 (2021), 98398\u2013\n98411.\n[10] Weicong Kong, Zhao Yang Dong, Youwei Jia, David J Hill, Yan Xu, and Yuan\nZhang. 2017. Short-term residential load forecasting based on LSTM recurrent\nneural network. IEEE transactions on smart grid 10, 1 (2017), 841\u2013851.\n[11] T Kumaresan and C Palanisamy. 2017. E-mail spam classification using S-cuckoo\nsearch and support vector machine. International Journal of Bio-Inspired Compu-\ntation 9, 3 (2017), 142\u2013156.\n[12] Nuha H Marza, Mehdi E Manaa, and Hussein A Lafta. 2021. Classification of\nspam emails using deep learning. In 2021 1st Babylon International Conference on\nInformation Technology and Science (BICITS). IEEE, 63\u201368.\n[13] Tomas Mikolov and Geoffrey Zweig. 2012. Context dependent recurrent neural\nnetwork language model. In 2012 IEEE Spoken Language Technology Workshop\n(SLT). IEEE, 234\u2013239.\n[14] Sarwat Nizamani, Nasrullah Memon, Mathies Glasdam, and Dong Duong Nguyen.\n2014. Detection of fraudulent emails by employing advanced feature abundance.\nEgyptian Informatics Journal 15, 3 (2014), 169\u2013174.\n[15] V Priya, I Sumaiya Thaseen, Thippa Reddy Gadekallu, Mohamed K Aboudaif,\nand Emad Abouel Nasr. 2021. Robust attack detection approach for IIoT using\nensemble classifier. arXiv preprint arXiv:2102.01515 (2021).\n[16] Justinas Rastenis, Simona Ramanauskait\u02d9e, Justinas Janulevi\u010dius, Antanas \u010cenys,\nAsta Slotkien\u02d9e, and K\u0119stutis Pakrijauskas. 2020. E-mail-based phishing attack\ntaxonomy. Applied Sciences 10, 7 (2020), 2363.\n[17] Karthika D Renuka and P Visalakshi. 2014. Latent semantic indexing based SVM\nmodel for email spam classification. (2014).\n[18] Shuvendu Roy, Sk Imran Hossain, MAH Akhand, and N Siddique. 2018. Sequence\nmodeling for intelligent typing assistant with Bangla and English keyboard. In\n2018 International Conference on Innovation in Engineering and Technology (ICIET).\nIEEE, 1\u20136.\n[19] Tara N Sainath, Oriol Vinyals, Andrew Senior, and Ha\u015fim Sak. 2015. Convolu-\ntional, long short-term memory, fully connected deep neural networks. In 2015\nIEEE international conference on acoustics, speech and signal processing (ICASSP).\nIeee, 4580\u20134584.\n[20] Anuj Kumar Singh, Shashi Bhushan, and Sonakshi Vij. 2019. Filtering spam\nmessages and mails using fuzzy C means algorithm. In 2019 4th International\nConference on Internet of Things: Smart Innovation and Usages (IoT-SIU). IEEE,\n1\u20135.\n[21] Kristina Toutanova and Colin Cherry. 2009. A global model for joint lemmati-\nzation and part-of-speech prediction. In Proceedings of the Joint Conference of\nthe 47th Annual Meeting of the ACL and the 4th International Joint Conference on\nNatural Language Processing of the AFNLP. 486\u2013494.\n[22] Tian Xia. 2020. A constant time complexity spam detection algorithm for boosting\nthroughput on rule-based filtering systems. IEEE Access 8 (2020), 82653\u201382661.\n[23] Yan Zhang, PengFei Liu, and JingTao Yao. 2019. Three-way email spam filtering\nwith game-theoretic rough sets. In 2019 International conference on computing,\nnetworking and communications (ICNC). IEEE, 552\u2013556.\nReceived 15 April 2023\n187\n",
    "pdf_url": "",
    "references": [
      "[1] Rayan Salah Hag Ali and Neamat El Gayar. 2019. Sentiment analysis using unla-",
      "beled email data. In 2019 International Conference on Computational Intelligence",
      "and Knowledge Economy (ICCIKE). IEEE, 328\u2013333.",
      "[2] Ali Shafigh Aski and Navid Khalilzadeh Sourati. 2016. Proposed efficient algo-",
      "rithm to filter spam using machine learning techniques. Pacific Science Review A:",
      "Natural Science and Engineering 18, 2 (2016), 145\u2013149.",
      "[3] Huwaida T Elshoush and Esraa A Dinar. 2019. Using adaboost and stochastic"
    ],
    "publication_date": "06-11-2023"
  },
  {
    "titre": "S.R. Doty August 27, 2008",
    "resume": "S.R. Doty",
    "auteurs": [
      "Loading"
    ],
    "institutions": [],
    "mots_cles": [
      "python",
      "x",
      "list",
      "type",
      "function",
      "example",
      "print",
      "n",
      "lists",
      "use"
    ],
    "texte_integral": "Python Basics\nS.R. Doty\nAugust 27, 2008\nContents\n1\nPreliminaries\n4\n1.1\nWhat is Python? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.2\nInstallation and documentation\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n2\nGetting started\n4\n2.1\nRunning Python as a calculator . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n2.2\nQuitting the interpreter\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.3\nLoading commands from the library . . . . . . . . . . . . . . . . . . . . . . . . . . .\n6\n2.4\nDe\ufb01ning functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2.5\nFiles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.6\nTesting code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n2.7\nScripts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n8\n1\n3\nPython commands\n9\n3.1\nComments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n3.2\nNumbers and other data types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n3.2.1\nThe type function\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n3.2.2\nStrings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n3.2.3\nLists and tuples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n3.2.4\nThe range function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n3.2.5\nBoolean values\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n3.3\nExpressions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n3.4\nOperators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n3.5\nVariables and assignment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n3.6\nDecisions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n3.7\nLoops\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.7.1\nfor loop . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.7.2\nwhile loop . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.7.3\nelse in loops . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.7.4\nbreak, continue, and pass\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.8\nLists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.8.1\nLength of a list; empty list . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.8.2\nSublists (slicing)\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.8.3\nJoining two lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.8.4\nList methods\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.9\nStrings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n2\nhttp://www.xkcd.com/353/\n3\n1\nPreliminaries\n1.1\nWhat is Python?\nPython is a powerful modern computer programming language.\nIt bears some similarities to\nFortran, one of the earliest programming languages, but it is much more powerful than Fortran.\nPython allows you to use variables without declaring them (i.e., it determines types implicitly),\nand it relies on indentation as a control structure. You are not forced to de\ufb01ne classes in Python\n(unlike Java) but you are free to do so when convenient.\nPython was developed by Guido van Rossum, and it is free software. Free as in \u201cfree beer,\u201d in that\nyou can obtain Python without spending any money. But Python is also free in other important\nways, for example you are free to copy it as many times as you like, and free to study the source\ncode, and make changes to it. There is a worldwide movement behind the idea of free software,\ninitiated in 1983 by Richard Stallman.1\nThis document focuses on learning Python for the purpose of doing mathematical calculations.\nWe assume the reader has some knowledge of basic mathematics, but we try not to assume any\nprevious exposure to computer programming, although some such exposure would certainly be\nhelpful. Python is a good choice for mathematical calculations, since we can write code quickly, test\nit easily, and its syntax is similar to the way mathematical ideas are expressed in the mathematical\nliterature. By learning Python you will also be learning a major tool used by many web developers.\n1.2\nInstallation and documentation\nIf you use Mac OS X or Linux, then Python should already be installed on your computer by\ndefault. If not, you can download the latest version by visiting the Python home page, at\nhttp://www.python.org\nwhere you will also \ufb01nd loads of documentation and other useful information. Windows users can\nalso download Python at this website. Don\u2019t forget this website; it is your \ufb01rst point of reference\nfor all things Python. You will \ufb01nd there, for example, reference [1], the excellent Python Tutorial\nby Guido van Rossum. You may \ufb01nd it useful to read along in the Tutorial as a supplement to\nthis document.\n2\nGetting started\n2.1\nRunning Python as a calculator\nThe easiest way to get started is to run Python as an interpreter, which behaves similar to the\nway one would use a calculator. In the interpreter, you type a command, and Python produces\nthe answer. Then you type another command, which again produes an answer, and so on.\nIn OS X or Linux, to start the Python interpreter is as simple as typing the command python\non the command line in a terminal shell. In Windows, assuming that Python has already been\n1See http://www.fsf.org or http://www.opensource.org for more information.\n4\ninstalled, you need to \ufb01nd Python in the appropriate menu. Windows users may choose to run\nPython in a command shell (i.e., a DOS window) where it will behave very similarly to Linux or\nOS X.\nFor all three operating systems (Linux, OS X, Windows) there is also an integrated development\nenvironment for Python named IDLE. If interested, you may download and install this on your com-\nputer.2 For help on getting started with IDLE see http://hkn.eecs.berkeley.edu/~dyoo/python/idle_int\nOnce Python starts running in interpreter mode, using IDLE or a command shell, it produces a\nprompt, which waits for your input. For example, this is what I get when I start Python in a\ncommand shell on my Linux box:\ndoty@brauer:~% python\nPython\n2.5.2 (r252:60911 , Apr 21 2008, 11:12:42)\n[GCC 4.2.3 (Ubuntu 4.2.3 -2ubuntu7)] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more\ninformation.\n>>>\nwhere the three symbols >>> indicates the prompt awaiting my input.\nSo experiment, using the Python interpreter as a calculator. Be assured that you cannot harm\nanything, so play with Python as much as you like. For example:\n>>> 2*1024\n2048\n>>> 3+4+9\n16\n>>> 2**100\n1267650600228229401496703205376 L\nIn the above, we \ufb01rst asked for the product of 2 and 1024, then we asked for the sum of 3, 4, and 9\nand \ufb01nally we asked for the value of 2100. Note that multiplication in Python is represented by \u2217,\naddition by +, and exponents by **; you will need to remember this syntax. The L appended to\nthe last answer is there to indicate that this is a long integer; more on this later. It is also worth\nnoting that Python does arbitrary precision integer arithmetic, by default:\n>>> 2**1000\n1071508607186267320948425049060001810561404811705533607443750\n3883703510511249361224931983788156958581275946729175531468251\n8714528569231404359845775746985748039345677748242309854210746\n0506237114187795418215304647498358194126739876755916554394607\n7062914571196477686542167660429831652624386837205668069376L\nHere is another example, where we print a table of perfect squares:\n>>> for n in [1,2,3,4,5,6]:\n...\nprint n**2\n...\n1\n4\n9\n16\n25\n36\n2Both Python and IDLE should be already preinstalled on all Loyola Windows computers.\n5\nThis illustrates several points. First, the expression [1,2,3,4,5,6] is a list, and we print the values\nof n2 for n varying over the list. If we prefer, we can print horizontally instead of vertically:\n>>> for n in [1,2,3,4,5,6]:\n...\nprint n**2,\n...\n1 4 9 16 25 36\nsimply by adding a comma at the end of the print command, which tells Python not to move to\na new line before the next print.\nThese last two examples are examples of a compound command, where the command is divided\nover two lines (or more). That is why you see ... on the second line instead of the usual >>>,\nwhich is the interpreter\u2019s way of telling us it awaits the rest of the command. On the third line\nwe entered nothing, in order to tell the interpreter that the command was complete at the second\nline. Also notice the colon at the end of the \ufb01rst line, and the indentation in the second line. Both\nare required in compound Python commands.\n2.2\nQuitting the interpreter\nIn a terminal you can quit a Python session by CTRL-D. (Hold down the CTRL key while pressing\nthe D key.) In IDLE you can also quit from the menu.\nIf the interpreter gets stuck in an in\ufb01nite loop, you can quit the current execution by CTRL-C.\n2.3\nLoading commands from the library\nPython has a very extensive library of commands, documented in the Python Library Reference\nManual [2]. These commands are organized into modules. One of the available modules is especially\nuseful for us: the math module. Let\u2019s see how it may be used.\n>>> from math import sqrt , exp\n>>> exp(-1)\n0.36787944117144233\n>>> sqrt(2)\n1.4142135623730951\nWe \ufb01rst import the sqrt and exp functions from the math module, then use them to compute\ne\u22121 = 1/e and\n\u221a\n2.\nOnce we have loaded a function from a module, it is available for the rest of that session. When\nwe start a new session, we have to reload the function if we need it.\nNote that we could have loaded both functions sqrt and exp by using a wildcard *:\n>>> from math import *\nwhich tells Python to import all the functions in the math module.\nWhat would have happened if we forgot to import a needed function? After starting a new session,\nif we type\n>>> sqrt(2)\nTraceback (most recent call last):\nFile \"<stdin >\", line 1, in <module >\nNameError: name \u2019sqrt\u2019 is not defined\n6\nwe see an example of an error message, telling us that Python does not recognize sqrt.\n2.4\nDe\ufb01ning functions\nIt is possible, and very useful, to de\ufb01ne our own functions in Python. Generally speaking, if you\nneed to do a calculation only once, then use the interpreter. But when you or others have need to\nperform a certain type of calculation many times, then de\ufb01ne a function. For a simple example,\nthe compound command\n>>> def f(x):\n...\nreturn x*x\n...\nde\ufb01nes the squaring function f(x) = x2, a popular example used in elementary math courses. In\nthe de\ufb01nition, the \ufb01rst line is the function header where the name, f, of the function is speci\ufb01ed.\nSubsequent lines give the body of the function, where the output value is calculated. Note that\nthe \ufb01nal step is to return the answer; without it we would never see any results. Continuing the\nexample, we can use the function to calculate the square of any given input:\n>>> f(2)\n4\n>>> f(2.5)\n6.25\nThe name of a function is purely arbitrary. We could have de\ufb01ned the same function as above,\nbut with the name square instead of f; then to use it we use the new function name instead of\nthe old:\n>>> def square(x):\n...\nreturn x*x\n...\n>>> square (3)\n9\n>>> square (2.5)\n6.25\nActually, a function name is not completely arbitrary, since we are not allowed to use a reserved\nword as a function name. Python\u2019s reserved words are: and, def, del, for, is, raise, assert,\nelif, from, lambda, return, break, else, global, not, try, class, except, if, or, while,\ncontinue, exec, import, pass, yield.\nBy the way, Python also allows us to de\ufb01ne functions using a format similar to the Lambda\nCalculus in mathematical logic. For instance, the above function could alternatively be de\ufb01ned in\nthe following way:\n>>> square = lambda x: x*x\nHere lambda x:\nx*x is known as a lambda expression. Lambda expressions are useful when you\nneed to de\ufb01ne a function in just one line; they are also useful in situations where you need a\nfunction but don\u2019t want to name it.\nUsually function de\ufb01nitions will be stored in a module (\ufb01le) for later use. These are indistinguish-\nable from Python\u2019s Library modules from the user\u2019s perspective.\n7\n2.5\nFiles\nPython allows us to store our code in \ufb01les (also called modules). This is very useful for more\nserious programming, where we do not want to retype a long function de\ufb01nition from the very\nbeginning just to change one mistake. In doing this, we are essentially de\ufb01ning our own modules,\njust like the modules de\ufb01ned already in the Python library. For example, to store our squaring\nfunction example in a \ufb01le, we can use any text editor3 to type the code into a \ufb01le, such as\ndef square(x):\nreturn x*x\nNotice that we omit the prompt symbols >>>, ...\nwhen typing the code into a \ufb01le, but the\nindentation is still important. Let\u2019s save this \ufb01le under the name \u201cSquaringFunction.py\u201d and then\nopen a terminal in order to run it:\ndoty@brauer:~% python\nPython\n2.5.2 (r252:60911 , Apr 21 2008, 11:12:42)\n[GCC 4.2.3 (Ubuntu 4.2.3 -2ubuntu7)] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\"\nfor more information.\n>>> from SquaringFunction import\nsquare\n>>> square (1.5)\n2.25\nNotice that I had to import the function from the \ufb01le before I could use it. Importing a command\nfrom a \ufb01le works exactly the same as for library modules. (In fact, some people refer to Python\n\ufb01les as \u201cmodules\u201d because of this analogy.) Also notice that the \ufb01le\u2019s extension (.py) is omitted\nin the import command.\n2.6\nTesting code\nAs indicated above, code is usually developed in a \ufb01le using an editor. To test the code, import it\ninto a Python session and try to run it. Usually there is an error, so you go back to the \ufb01le, make\na correction, and test again. This process is repeated until you are satis\ufb01ed that the code works.\nThe entire process is known as the development cycle.\nThere are two types of errors that you will encounter.\nSyntax errors occur when the form of\nsome command is invalid. This happens when you make typing errors such as misspellings, or\ncall something by the wrong name, and for many other reasons. Python will always give an error\nmessage for a syntax error.\n2.7\nScripts\nIf you use Mac OS X or some other variant of Unix (such as Linux) then you may be interested\nin running Python commands as a script. Here\u2019s an example. Use an editor to create a \ufb01le name\nSayHi containing the following lines\n#! /usr/bin/python\nprint \"Hello World!\"\nprint \"- From your friendly Python\nprogram\"\n3Most developers rely on emacs for editing code. Other possible choices are Notepad for Windows, gedit for\nLinux/Gnome, and TextEdit for OS X. IDLE comes with its own editor, by the way.\n8\nThe \ufb01rst line tells Python that this is a script. After saving the \ufb01le, make it executable by typing\nchmod 755 SayHi in the terminal. To run the script, type ./SayHi in the terminal. Note that if\nyou move the script someplace in your search path, then you can run it simply by typing SayHi.\nType echo $PATH to see what folders are in your search path, and type which python to see where\nyour python program is \u2014 this should match the \ufb01rst line in your script.\nAs far as I know, it is impossible to run Python scripts in a similar way on a Windows machine.\n3\nPython commands\n3.1\nComments\nIn a Python command, anything after a # symbol is a comment. For example:\nprint \"Hello world\" #this is silly\nComments are not part of the command, but rather intended as documentation for anyone reading\nthe code.\nMultiline comments are also possible, and are enclosed by triple double-quote symbols:\n\"\"\"This is an example of a long comment\nthat goes on\nand on\nand on.\"\"\"\n3.2\nNumbers and other data types\nPython recognizes several di\ufb00erent types of data. For instance, 23 and \u221275 are integers, while 5.0\nand \u221223.09 are \ufb02oats or \ufb02oating point numbers. The type \ufb02oat is (roughly) the same as a real\nnumber in mathematics. The number 12345678901 is a long integer; Python prints it with an \u201cL\u201d\nappended to the end.\nUsually the type of a piece of data is determined implicitly.\n3.2.1\nThe type function\nTo see the type of some data, use Python\u2019s builtin type function:\n>>> type(-75)\n<type \u2019int\u2019>\n>>> type(5.0)\n<type \u2019float\u2019>\n>>> type (12345678901)\n<type \u2019long\u2019>\nAnother useful data type is complex, used for complex numbers. For example:\n>>> 2j\n2j\n>>> 2j-1\n(-1+2j)\n>>> complex(2,3)\n9\n(2+3j)\n>>> type(-1+2j)\n<type \u2019complex\u2019>\nNotice that Python uses j for the complex unit (such that j2 = \u22121) just as physicists do, instead\nof the letter i preferred by mathematicians.\n3.2.2\nStrings\nOther useful data types are strings (short for \u201ccharacter strings\u201d); for example \"Hello World!\".\nStrings are sequences of characters enclosed in single or double quotes:\n>>> \"This is a string\"\n\u2019This is a string \u2019\n>>> \u2019This is a string, too\u2019\n\u2019This is a string , too\u2019\n>>> type(\"This is a string\")\n<type \u2019str\u2019>\nStrings are an example of a sequence type.\n3.2.3\nLists and tuples\nOther important sequence types used in Python include lists and tuples. A sequence type is formed\nby putting together some other types in a sequence. Here is how we form lists and tuples:\n>>> [1,3,4,1,6]\n[1, 3, 4, 1, 6]\n>>> type( [1,3,4,1,6] )\n<type \u2019list\u2019>\n>>> (1,3,2)\n(1, 3, 2)\n>>> type( (1,3,2) )\n<type \u2019tuple\u2019>\nNotice that lists are enclosed in square brackets while tuples are enclosed in parentheses. Also note\nthat lists and tuples do not need to be homogeneous; that is, the components can be of di\ufb00erent\ntypes:\n>>> [1,2,\"Hello\" ,(1,2)]\n[1, 2, \u2019Hello\u2019, (1, 2)]\nHere we created a list containing four components: two integers, a string, and a tuple. Note that\ncomponents of lists may be other lists, and so on:\n>>> [1, 2, [1,2], [1,[1,2]], 5]\n[1, 2, [1, 2], [1, [1, 2]], 5]\nBy nesting lists within lists in this way, we can build up complicated stuctures.\nSequence types such as lists, tuples, and strings are always ordered, as opposed to a set in mathe-\nmatics, which is always unordered. Also, repetition is allowed in a sequence, but not in a set.\n10\n3.2.4\nThe range function\nThe range function is often used to create lists of integers. It has three forms. In the simplest\nform, range(n) produces a list of all numbers 0, 1, 2, . . ., n \u2212 1 starting with 0 and ending with\nn \u2212 1. For instance,\n>>> range (17)\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\nYou can also specify an optional starting point and an increment, which may be negative. For\ninstance, we have\n>> range(1 ,10)\n[1, 2, 3, 4, 5, 6, 7, 8, 9]\n>>> range(-6,0)\n[-6, -5, -4, -3, -2, -1]\n>>> range (1 ,10 ,2)\n[1, 3, 5, 7, 9]\n>>> range(10,0,-2)\n[10, 8, 6, 4, 2]\nNote the use of a negative increment in the last example.\n3.2.5\nBoolean values\nFinally, we should mention the boolean type. This is a value which is either True or False.\n>>> True\nTrue\n>>> type(True)\n<type \u2019bool\u2019>\n>>> False\nFalse\n>>> type(False)\n<type \u2019bool\u2019>\nBoolean types are used in making decisions.\n3.3\nExpressions\nPython expressions are not commands, but rather form part of a command. An expression is\nanything which produces a value. Examples of expressions are: 2+2, 2**100, f((x-1)/(x+1)).\nNote that in order for Python to make sense of the last one, the variable x must have a value\nassigned and f should be a previously de\ufb01ned function.\nExpressions are formed from variables, constants, function evaluations, and operators. Parentheses\nare used to indicate order of operations and grouping, as usual.\n3.4\nOperators\nThe common binary operators for arithmetic are + for addition, - for subtraction, * for multi-\nplication, and / for division. As already mentioned, Python uses ** for exponentiation. Integer\ndivision is performed so that the result is always another integer (the integer quotient):\n11\n>>> 25/3\n8\n>>> 5/2\n2\nThis is a wrinkle that you will always have to keep in mind when working with Python. To get a\nmore accurate answer, use the \ufb02oat type:\n>>> 25.0/3\n8.3333333333333339\n>>> 5/2.0\n2.5\nIf just one of the operands is of type \ufb02oat, then the result will be of type \ufb02oat. Here is another\nexample of this pitfall:\n>>> 2**(1/2)\n1\nwhere we wanted to compute the square root of 2 as the 1\n2 power of 2, but the division in the\nexponent produced a result of 0 because of integer division. A correct way to do this computation\nis:\n>>> 2**0.5\n1.4142135623730951\nAnother useful operator is %, which is read as \u201dmod\u201d. This gives the remainder of an integer\ndivision, as in\n>>> 5 % 2\n1\n>>> 25 % 3\n1\nwhich shows that 5 mod 2 = 1, and 25 mod 3 = 1. This operator is useful in number theory and\ncryptography.\nBesides the arithmetic operators we need comparison operators: <, >, <=, >=, ==, !=, <>. In order\nthese are read as: is less than, is greater than, is less than or equal to, is greater than or equal to,\nis equal to, is not equal to, is not equal to. The result of a comparison is always a boolen value\nTrue or False.\n>>> 2 < 3\nTrue\n>>> 3<2\nFalse\n>>> 3 <= 2\nFalse\nNote that != and <> are synonomous; either one means not equal to. Also, the operator == means\nis equal to.\n>>> 2 <> 3\nTrue\n>>> 2 != 3\nTrue\n>>> 0 != 0\nFalse\n12\n>>> 0 == 0\nTrue\n3.5\nVariables and assignment\nAn assignment statement in Python has the form variable = expression. This has the following\ne\ufb00ect. First the expression on the right hand side is evaluated, then the result is assigned to the\nvariable. After the assignment, the variable becomes a name for the result. The variable retains\nthe same value until another value is assigned, in which case the previous value is lost. Executing\nthe assignment produces no output; its purpose it to make the association between the variable\nand its value.\n>>> x = 2+2\n>>> print x\n4\nIn the example above, the assignment statement sets x to 4, producing no output. If we want to\nsee the value of x, we must print it. If we execute another assignment to x, then the previous value\nis lost.\n>>> x = 380.5\n>>> print x\n380.5\n>>> y = 2*x\n>>> print y\n761.0\nRemember: A single = is used for assignment, the double == is used to test for equality.\nIn mathematics the equation x = x + 1 is nonsense; it has no solution. In computer science, the\nstatement x = x + 1 is useful. Its purpose is to add 1 to x, and reassign the result to x. In short,\nx is incremented by 1.\n>>> x = 10\n>>> x = x + 1\n>>> print x\n11\n>>> x = x + 1\n>>> print x\n12\nVariable names may be any contiguous sequence of letters, numbers, and the underscore (_) char-\nacter. The \ufb01rst character must not be a number, and you may not use a reserved word as a variable\nname. Case is important; for instance Sum is a di\ufb00erent name than sum. Other examples of legal\nvariable names are: a, v1, v_1, abc, Bucket, monthly_total, __pi__, TotalAssets.\n3.6\nDecisions\nThe if\u2013else is used to make choices in Python code. This is a compound statement. The simplest\nform is\nif\nc o n d i t i o n :\na c t i o n \u22121\n13\nelse:\na c t i o n \u22122\nThe indentation is required. Note that the else and its action are optional. The actions action-1\nand action-2 may consist of many statements; they must all be indented the same amount. The\ncondition is an expression which evaluates to True or False.\nOf course, if the condition evaluates to True then action-1 is executed, otherwise action-2 is exe-\ncuted. In either case execution continues with the statement after the if-else. For example, the\ncode\nx = 1\nif x > 0:\nprint \"Friday is wonderful\"\nelse:\nprint \"Monday\nsucks\"\nprint \"Have a good weekend\"\nresults in the output\nFriday is wonderful\nHave a good weekend\nNote that the last print statement is not part of the if-else statement (because it isn\u2019t indented),\nso if we change the \ufb01rst line to say x = 0 then the output would be\nMonday\nsucks\nHave a good weekend\nMore complex decisions may have several alternatives depending on several conditions. For these\nthe elif is used. It means \u201celse if\u201d and one can have any number of elif clauses between the if\nand the else. The usage of elif is best illustrated by an example:\nif x >= 0 and x < 10:\ndigits = 1\nelif x >= 10 and x < 100:\ndigits = 2\nelif x >= 100 and x < 1000:\ndigits = 3\nelif x >= 1000 and x < 10000:\ndigits = 4\nelse:\ndigits = 0\n# more than 4\nIn the above, the number of digits in x is computed, so long as the number is 4 or less. If x is\nnegative or greater than 10000, then digits will be set to zero.\n3.7\nLoops\nPython provides two looping commands: for and while. These are compound commands.\n3.7.1\nfor loop\nThe syntax of a for loop is\n14\nfor\nitem\nin\nl i s t :\na c t i o n\nAs usual, the action consists of one or more statements, all at the same indentation level. These\nstatements are also known as the body of the loop. The item is a variable name, and list is a list.\nExecution of the for loop works by setting the variable successively to each item in the list, and\nthen executing the body each time. Here is a simple example (the comma at the end of the print\nmakes all printing occur on the same line):\nfor i in [2, 4, 6, 0]:\nprint i,\nThis produces the output\n2 4 6 0\n3.7.2\nwhile loop\nThe syntax of the while loop is\nwhile\nc o n d i t i o n :\na c t i o n\nOf course, the action may consist of one or more statements all at the same indentation level. The\nstatements in the action are known as the body of the loop. Execution of the loop works as follows.\nFirst the condition is evaluated. If True, the body is executed and the condition evaluated again,\nand this repeats until the condition evaluates to False. Here is a simple example:\nn = 0\nwhile n < 10:\nprint n,\nn = n + 3\nThis produces the following output\n0 3 6 9\nNote that the body of a while loop is never executed if the condition evaluates to False the \ufb01rst\ntime. Also, if the body does not change the subsequent evaluations of the condition, an in\ufb01nite\nloop may occur. For example\nwhile True:\nprint \"Hello\",\nwill print Hellos endlessly. To interrupt the execution of an in\ufb01nite loop, use CTRL-C.\n3.7.3\nelse in loops\nA loop may have an optional else which is executed when the loop \ufb01nishes. For example, the\nloop\nfor n in [10,9,8,7,6,5,4,3,2,1]:\nprint n,\nelse:\nprint \"blastoff\"\n15\nresults in the output\n10 9 8 7 6 5 4 3 2 1 blastoff\nand the loop\nn=10\nwhile n > 0:\nprint n,\nn = n - 1\nelse:\nprint \"blastoff\"\nhas the same e\ufb00ect (it produces identical output).\n3.7.4\nbreak, continue, and pass\nThe break statement, like in C, breaks out of the smallest enclosing for or while loop.\nThe\ncontinue statement, also borrowed from C, continues with the next iteration of the loop. The\npass statement does nothing. It can be used when a statement is required syntactically but the\nprogram requires no action.\nHere is an example of the use of a break statement and an else clause in a loop.\nfor n in range(2, 10):\nfor x in range(2, n):\nif n % x == 0:\nprint n, \u2019equals \u2019, x, \u2019*\u2019, n/x\nbreak\nelse:\n# loop fell through without finding a factor\nprint n, \u2019is a prime number \u2019\nThe above code searches for prime numbers between 2 and 10, and produces the following output.\n2 is a prime number\n3 is a prime number\n4 equals 2 * 2\n5 is a prime number\n6 equals 2 * 3\n7 is a prime number\n8 equals 2 * 4\n9 equals 3 * 3\n3.8\nLists\nAs already mentioned, a list is a \ufb01nite sequence of items, and one could use the range function to\ncreate lists of integers.\nIn Python, lists are not required to be homogeneous, i.e., the items could be of di\ufb00erent types.\nFor example,\na = [2, \"Jack\", 45, \"23 Wentworth Ave\"]\nis a perfectly valid list consisting of two integers and two strings. One can refer to the entire list\nusing the identi\ufb01er a or to the i-th item in the list using a[i].\n16\n>>> a = [2, \"Jack\", 45, \"23 Wentworth Ave\"]\n>>> a\n[2, \u2019Jack\u2019, 45, \u201923 Wentworth Ave\u2019]\n>>> a[0]\n2\n>>> a[1]\n\u2019Jack\u2019\n>>> a[2]\n45\n>>> a[3]\n\u201923 Wentworth Ave\u2019\nNote that the numbering of list items always begins at 0 in Python. So the four items in the above\nlist are indexed by the numbers 0, 1, 2, 3.\nList items may be assigned a new value; this of course changes the list. For example, with a as\nabove:\n>>> a\n[2, \u2019Jack\u2019, 45, \u201923 Wentworth Ave\u2019]\n>>> a[0] = 2002\n>>> a\n[2002 , \u2019Jack\u2019, 45, \u201923 Wentworth Ave\u2019]\nOf course, the entire list may be assigned a new value, which does not have to be a list. When\nthis happens, the previous value is lost:\n>>> a\n[2002 , \u2019Jack\u2019, 45, \u201923 Wentworth Ave\u2019]\n>>> a = \u2019gobbletygook\u2019\n>>> a\n\u2019gobbletygook\u2019\n3.8.1\nLength of a list; empty list\nEvery list has a length, the number of items in the list, obtained using the len function:\n>>> x = [9, 4, 900,\n-45]\n>>> len(x)\n4\nOf special importance is the empty list of length 0. This is created as follows:\n>>> x = []\n>>> len(x)\n0\n3.8.2\nSublists (slicing)\nSublists are obtained by slicing, which works analogously to the range function discussed before.\nIf x is an existing list, then x[start:end] is the sublist consisting of all items in the original list\nat index positions i such that\nstart \u2264 i < end.\nOf course, we must remember that indexing items always starts at 0 in Python. For example,\n17\n>>> x=range(0 ,20 ,2)\n>>> x\n[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n>>> x[2:5]\n[4, 6, 8]\n>>> x[0:5]\n[0, 2, 4, 6, 8]\nWhen taking a slice, either parameter start or end may be omitted: if start is omitted then the\nslice consists of all items up to, but not including, the one at index position end, similarly, if end\nis omitted the slice consists of all items starting with the one at position start. For instance, with\nthe list x as de\ufb01ned above we have\n>>> x[:5]\n[0, 2, 4, 6, 8]\n>>> x[2:]\n[4, 6, 8, 10, 12, 14, 16, 18]\nIn this case, x[:5] is equivalent to x[0:5] and x[2:] is equivalent to x[2:len(x)].\nThere is an optional third parameter in a slice, which if present represents an increment, just as\nin the range function. For example,\n>>> list = range (20)\n>>> list\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n>>> list [0:16:2]\n[0, 2, 4, 6, 8, 10, 12, 14]\n>>> list [0:15:2]\n[0, 2, 4, 6, 8, 10, 12, 14]\nNotice that one may cleverly use a negative increment to e\ufb00ectively reverse a list, as in:\n>>> list[18::-1]\n[17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\nIn general, the slice x[len(x)::-1] reverses any existing list x.\n3.8.3\nJoining two lists\nTwo existing lists may be concatenated together to make a longer list, using the + operator:\n>>> [2,3,6,10] + [4,0,0,5,0]\n[2, 3, 6, 10, 4, 0, 0, 5, 0]\n3.8.4\nList methods\nIf x is the name of an existing list, we can append an item item to the end of the list using\nx.append(item)\nFor example,\n>>> x = [3, 6, 8, 9]\n>>> x.append (999)\n>>> x\n[3, 6, 8, 9, 999]\n18\nA similar method is called insert, which allows an element to be inserted in the list at a speci\ufb01ed\nposition:\n>>> x = [\u2019a\u2019, \u2019c\u2019, \u20193\u2019, \u2019d\u2019, \u20197\u2019]\n>>> x.insert (0 ,100)\n>>> x\n[100, \u2019a\u2019, \u2019c\u2019, \u20193\u2019, \u2019d\u2019, \u20197\u2019]\n>>> x.insert(3,\u2019junk\u2019)\n>>> x\n[100, \u2019a\u2019, \u2019c\u2019, \u2019junk\u2019, \u20193\u2019, \u2019d\u2019, \u20197\u2019]\nOne can also delete the \ufb01rst occurrence of some item in the list (if possible) using remove as\nfollows:\n>>> x.remove(\u2019a\u2019)\n>>> x\n[100, \u2019c\u2019, \u2019junk\u2019, \u20193\u2019, \u2019d\u2019, \u20197\u2019]\nTo delete the item at index position i use x.pop(i), as in:\n>>> x.pop(0)\n100\n>>> x\n[\u2019c\u2019, \u2019junk\u2019, \u20193\u2019, \u2019d\u2019, \u20197\u2019]\nNotice that pop not only changes the list, but it also returns the item that was deleted. Also, by\ndefault x.pop() pops o\ufb00 the last item:\n>>> x.pop()\n\u20197\u2019\n>>> x\n[\u2019c\u2019, \u2019junk\u2019, \u20193\u2019, \u2019d\u2019]\nMany more methods exist for manipulating lists; consult the Python Tutorial [1] or Python Library\nReference [2] for more details.\n3.9\nStrings\nA string in Python is a sequence of characters. In some sense strings are similar to lists, however,\nthere are important di\ufb00erences. One major di\ufb00erence is that Python strings are immutable, mean-\ning that we are not allowed to change individual parts of them as we could for a list. So if x is an\nexisting string, then x[i] gets the character at position i, but we are not allowed to reassign that\ncharacter, as in x[5] = \u2019s\u2019.\n>>> x = \u2019gobbletygook\u2019\n>>> x[2]\n\u2019b\u2019\n>>> x[5]\n\u2019e\u2019\n>>> x[5] = \u2019s\u2019\nTraceback (most recent call last):\nFile \"<stdin >\", line 1, in <module >\nTypeError: \u2019str\u2019 object\ndoes not support item assignment\nJust as for lists, string items are indexed starting at 0. Slicing for strings works exactly the same as\nfor lists. The length function len is the same as for lists, and concatenation is the same too. But\n19\nthe list methods append, insert, delete, and pop are not available for strings, because strings\nare immutable. If you need to change an existing string, you must make a new, changed, one.\nThere are many string methods for manipulating strings, documented in the Python Library\nReference Manual [2]. For example, you can capitalize an existing string x using x.capitalize();\nthis returns a new copy of the string in which the \ufb01rst character has been capitalized.\n>>> a = \u2019gobbletygook is refreshing\u2019\n>>> a.capitalize()\n\u2019Gobbletygook is refreshing\u2019\nOther useful methods are find and index, which are used to \ufb01nd the \ufb01rst occurence of a substring\nin a given string. See the manuals for details.\nReferences\n[1] Guido van Rossum, Python Tutorial, http://docs.python.org.\n[2] Guido van Rossum, Python Library Reference Manual, http://docs.python.org.\n20\n",
    "pdf_url": "",
    "references": [
      "[1] Guido van Rossum, Python Tutorial, http://docs.python.org.",
      "[2] Guido van Rossum, Python Library Reference Manual, http://docs.python.org."
    ],
    "publication_date": "27-08-2008"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "uage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).Addison-Wesley Professional.",
      "University of Kent"
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "uage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).Addison-Wesley Professional.",
      "University of Kent"
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Semantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model",
    "resume": "The emergence of novel types of communication, such as email, hasbeen brought on by the development of the internet, which radicallyconcentrated the way in that individuals communicate socially andwith one another. It is now establishing itself as a crucial aspect ofthe communication network which has been adopted by a varietyof commercial enterprises such as retail outlets. So in this researchpaper, we have built a unique spam-detection methodology basedon email-body sentiment analysis. The proposed hybrid model isput into practice and preprocessing the data, extracting the proper-ties, and categorizing data are all steps in the process. To examinethe emotive and sequential aspects of texts, we use word embed-ding and a bi-directional LSTM network. this model frequentlyshortens the training period, then utilizes the Convolution Layer toextract text features at a higher level for the Bi LSTM network. Ourmodel performs better than previous versions, with an accuracyrate of 9798%. In addition, we show that our model beats not justsome well-known machine learning classifiers but also cutting-edgemethods for identifying spam communications, demonstrating itssuperiority on its own. Suggested Ensemble models results areexamined in terms of recall, accuracy, and precision",
    "auteurs": [
      "Khushbu Doulani",
      "GRU",
      "Shivangi Sachan",
      "Khushbu Doulani",
      "Mainak Adhikari",
      "Noida",
      "Decision Trees",
      "Bi-LSTM",
      "GRU",
      "BiLSTM+GRU"
    ],
    "institutions": [
      "Department of CSEIIIT Lucknow Lucknow, UP, ",
      "Mainak Adhikari Department of CSEIIIT LucknowUP, "
    ],
    "mots_cles": [
      " Dataset",
      " KNN",
      " Gaussian Naive Bayes",
      " LSTM",
      " SVM",
      " Bidirectional "
    ],
    "texte_integral": "Semantic Analysis and Classification of Emails through\nInformative Selection of Features and Ensemble AI Model\nShivangi Sachan\u2217\nDepartment of CSE\nIIIT Lucknow\nLucknow, UP, India\nmcs21025@iiitl.ac.in\nKhushbu Doulani\nVardhaman College of Engineering\nHyderabad, India\nkhushidoulani@gmail.com\nMainak Adhikari\nDepartment of CSE\nIIIT Lucknow\nUP, India\nmainak.ism@gmail.com\nABSTRACT\nThe emergence of novel types of communication, such as email, has\nbeen brought on by the development of the internet, which radically\nconcentrated the way in that individuals communicate socially and\nwith one another. It is now establishing itself as a crucial aspect of\nthe communication network which has been adopted by a variety\nof commercial enterprises such as retail outlets. So in this research\npaper, we have built a unique spam-detection methodology based\non email-body sentiment analysis. The proposed hybrid model is\nput into practice and preprocessing the data, extracting the proper-\nties, and categorizing data are all steps in the process. To examine\nthe emotive and sequential aspects of texts, we use word embed-\nding and a bi-directional LSTM network. this model frequently\nshortens the training period, then utilizes the Convolution Layer to\nextract text features at a higher level for the BiLSTM network. Our\nmodel performs better than previous versions, with an accuracy\nrate of 97\u201398%. In addition, we show that our model beats not just\nsome well-known machine learning classifiers but also cutting-edge\nmethods for identifying spam communications, demonstrating its\nsuperiority on its own. Suggested Ensemble model\u2019s results are\nexamined in terms of recall, accuracy, and precision\nCCS CONCEPTS\n\u2022 Computer systems organization \u2192 Embedded systems; Re-\ndundancy; Robotics; \u2022 Networks \u2192 Network reliability.\nKEYWORDS\nDataset, KNN, Gaussian Naive Bayes, LSTM, SVM, Bidirectional\nLSTM, GRU, Word-Embeddings, CNN\nACM Reference Format:\nShivangi Sachan, Khushbu Doulani, and Mainak Adhikari. 2023. Semantic\nAnalysis and Classification of Emails through Informative Selection of\nFeatures and Ensemble AI Model. In 2023 Fifteenth International Conference\non Contemporary Computing (IC3-2023) (IC3 2023), August 03\u201305, 2023, Noida,\nIndia. ACM, New York, NY, USA, 7 pages. https://doi.org/10.1145/3607947.\n3607979\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nIC3 2023, August 03\u201305, 2023, Noida, India\n\u00a9 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 979-8-4007-0022-4/23/08...$15.00\nhttps://doi.org/10.1145/3607947.3607979\n1\nINTRODUCTION\nOver the past few years, a clear surge of both the amount of spam-\nmers as well as spam emails. This is likely due to a fact that the\ninvestment necessary for engaging in the spamming industry is\nrelatively low. As a result of this, we currently have a system that\nidentifies every email as suspicious, which has caused major expen-\nditures in the investment of defense systems [12]. Emails are used\nfor online crimes like fraud, hacking, phishing, E-mail bombing, bul-\nlying, and spamming. [16]. Algorithms that are based on machine\nlearning (ML) are now the most effective and often used approach to\nthe recognition of spam. Phishing, which is defined as a fraudulent\nattempt to acquire private information by masquerading as a trust-\nworthy party in electronic communication, has rapidly advanced\npast use of simple techniques and the tactic of casting a wide net;\ninstead, spear phishing uses a variety of sophisticated techniques\nto target a single high-value individual. Other researchers used NB,\nDecision Trees, and SVM to compare the performance of supervised\nML algorithms for spam identification [6]. Spam emails clog up re-\ncipients\u2019 inboxes with unsolicited communications, which frustrate\nthem and push them into the attacker\u2019s planned traps [7]. As a re-\nsult, spam messages unquestionably pose a risk to both email users\nand the Internet community. In addition, Users may occasionally\nread the entire text of an unsolicited message that is delivered to\nthe target users\u2019 inboxes without realizing that the message is junk\nand then choosing to avoid it. Building a framework for email spam\ndetection is the aim of this project. In this approach, we combine the\nWord-Embedding Network with the CNN layer, Bi-LSTM, and GRU\n(BiLSTM+GRU). CNN layers are used to speed up training time\nbefore the Bi-LSTM network, and more advanced textual character-\nistics are extracted with the use of this network in comparison to\nthe straight LSTM network, in less time. Gated recurrent neural net-\nworks (GRUs) are then added because they train more quickly and\nperform better for language modeling. To evaluate and investigate\nvarious machine learning algorithms for predicting email spam,\nand develop a hybrid classification algorithm to filter email spam\nbefore employing an ensemble classification algorithm to forecast\nit. To put an innovative technique into practice and compare it to\nthe current method in terms of various metrics. Ensemble learn-\ning, a successful machine learning paradigm, combines a group of\nlearners rather than a single learner to forecast unknown target\nattributes. Bagging, boosting, voting, and stacking are the four main\ntypes of ensemble learning techniques. To increase performance,\nan integrated method and the combining of two or three algorithms\nare also suggested. Extraction of text-based features takes a long\ntime. Furthermore, it can be challenging to extract all of the crucial\ninformation from a short text. Over the span associated with this\n181\nIC3 2023, August 03\u201305, 2023, Noida, India\nSachan et al.\nresearch, we utilize Bidirectional Large Short-Term Memories (Bi-\nLSTM) in conjunction with Convolutional Neural Networks (CNN)\nto come up with an innovative method to the detection of spam.\nBagging and boosting approaches were widely preferred in this\nstudy. Contribution and paper organization is as follows: section 1.1\ndescribes literature study, section 1.2 describe motivation for this\nresearch work, section 2 sketches procedure of details implemen-\ntation, Section 3 present experimental setup, dataset description\nand evaluation metrics, and section 4 summarizing outcomes of the\nexperiment.\n1.1\nRelated Work\nEmail is indeed the second most frequently utilized Internet appli-\ncation as well as the third most common method of cyberbullying,\nclaims one study. Cybercriminals exploit it in a number of ways,\nincluding as sending obscene or abusive messages, adding viruses\nto emails, snatching the private information of victims, and ex-\nposing it to a broad audience. Spam letters made up 53.95% of all\nemail traffic in March 2020. We examine three main types of un-\nlawful emails in our study. First are fake emails, which are sent\nto manipulate recipients to submit sensitive information. The sec-\nond as being cyberbullying\u2019s use of harassing emails to threaten\nindividuals. Suspicious emails that describe illegal activities belong\nto the third category. Many researchers have earlier contributed\nmassively to this subject. The researcher claims there is some proof\nthat suspicious emails were sent before to the events of 9/11. [14].\nWhen it comes to data labeling, there are also convinced rule-based\napproaches and technologies ( like VADER) that are used, even\nthough their efficiency of the are together is adversely affected. A\nhidden layer, which itself is essential for vectorization, is the top\nlayer of the model. We use oversampling methods for this minority\nclass because of the absence of data. Sampling techniques can help\nwith multicollinearity, but they have an impact on simulation re-\nsults. Oversampling causes data to be randomly repeated, which\naffects test data because dividing data may result in duplicates. Un-\ndersampling may result in the loss of some strong information. In\norder to advance email research, it is crucial to provide datasets on\ncriminal activity. P. Garg et al. (2021) [5], which revealed that spam\nin an email was detected in 70 percent of business emails, spam was\nestablished as an obstacle for email administrators. Recognizing\nspam and getting rid of it were the primary concerns, as spam can\nbe offensive, may lead to other internet sites being tricked, which\ncan offer harmful data, and can feature those who are not particu-\nlar with their content using NLP. To select the best-trained model,\neach mail transmission protocol requires precise and effective email\nclassification, a machine learning comparison is done. Our study\nhas suggested that innovative deep learning outperforms learning\nalgorithms like SVM and RF. Current studies on the classification\nof emails use a variety of machine learning (ML) techniques, with\na few of them focusing on the study of the sentiments consisted of\nwithin email databases. The lack of datasets is a significant obstacle\nto email classification. There are few publicly accessible E-mail\ndatasets, thus researchers must use these datasets to test their hy-\npotheses or gather data on their own. Authors[15] describe supplied\ntwo-phased outlier detection models to enhance the IIOT network\u2019s\ndependability. Artificial Neural Network, SVM, Gaussian NB, and\nRF (random forest) ensemble techniques were performed to forecast\nclass labels, and the outputs were input into a classifying unit to\nincrease accuracy. A method for content-based phishing detection\nwas presented by the authors in [2], to classify phishing emails,\nthey employed RF. They categorize spam and phishing emails. They\nenhanced phishing email classifiers with more accurate predictions\nby extracting features. They showed some effective Machine learn-\ning spam filtering techniques. When the PCA method is used, it will\nlower the number of features in the dataset. The collected features\ngo through the PCA algorithm to reduce the number of features.\nThe PCA method is used to make a straightforward representation\nof the information which illustrates the amount of variability there\nis in the data. The authors of [20] presented the Fuzzy C-means\nmethod for classifying spam email. To stop spam, they implemented\na membership threshold value. A methodology to identify unla-\nbeled data was put forth by the authors of [1] and applied motive\nanalysis to the Enron data collection. They divided the data into\ncategories that were favorable, negative, and neutral. They grouped\nthe data using k-means clustering, an unsupervised ML technique\nand then classified it using the supervised ML techniques SVM and\nNB. Hina, Maryam, and colleagues (2021) implemented Sefaced:\nDeep learning-based semantic analysis and categorization of e-mail\ndata using a forensic technique. For multiclass email classification,\nSeFACED employs a Gated Recurrent Neural Network (GRU) based\non Long Short-Term Memory (LSTM). Different random weight ini-\ntializations affect LSTMs [9]. Zhang, Yan, et al.(2019) Experiments\non three-way game-theoretic rough set (GTRS) email spam filter-\ning show that it is feasible to significantly boost coverage without\ndecreasing accuracy [23]. According to Xia et al. [22], SMS spam\nhas been identified using machine learning model such as naive\nbayes , vector-space modeling, support vector machines (SVM),\nlong selective memory machines (LSTM), and convolutional neural\nnetworks including every instance of a method for categorizing\ndata. Elshoush, Huwaida, et al. (2019) Using adaboost and stochastic\ngradient descent (sgd) algorithms for e-mail filtering with R and\norange software spam [3]. Orange software was used to create the\nclassifications, which included Adaboost and SGD. The majority of\nresearchers focused on text-based email spam classification meth-\nods because image-based spam can be filtered in the early stages\nof pre-processing. There are widely used word bag (BoW) model,\nwhich believes that documents are merely unordered collections\nof words, is the foundation for these techniques. Kumaresan [11]\nexplains SVM with a cuckoo search algorithm was used to extract\ntextual features for spam detection. Renuka and Visalakshi made\nuse of svm [17] spam email identification, followed by selecting\nfeatures using Latent Semantic Indexing (LSI). Here we have used\nlabeled dataset to train the hybrid classifier. We used TF-IDF for\nfeature extraction [20] and Textual features for spam detection\nwere extracted using SVM and a cuckoo search algorithm. [4] for\nfiltering out the spam email. Combining the integrated strategy to\nthe pure SVM and NB methods, overall accuracy is really improved.\nMoreover, accurate detection for spam email has been proposed\nusing the Negative Selection Algorithm (NSA) and Particle Swarm\nOptimization\u2019s (PSO) algorithm. PSO is used in this instance to\nimprove the effectiveness of the classifier.\n182\nSemantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model\nIC3 2023, August 03\u201305, 2023, Noida, India\n1.2\nMotivation and Novelty\nEmail is most common form of communication between people\nin this digital age. Many users have been victims of spam emails,\nand their personal information has been compromised. The email\nClassification technique is employed to identify and filter junk\nmail, junk, and virus-infected emails prior to reach a user\u2019s inbox.\nExisting email classification methods result in irrelevant emails\nand/or the loss of valuable information. Keeping these constraints\nin mind, the following contributions are made in this paper:\n\u2022 Text-based feature extraction is a lengthy process. Further-\nmore, extracting every important feature from text is difficult.\nIn this paper, we show how to employ GRU with Convo-\nlutional Neural Networks and Bidirectional-LSTM to find\nspam.\n\u2022 Used Word-Embeddings, BiLSTM, and Gated Recurrent Neu-\nral Networks to examine the relationships, sentimental con-\ntent, and sequential way of email contents.\n\u2022 Applied CNN before the Bi-LSTM network, training time can\nbe sped up. This network can also extract more advanced\ntextual features faster than the Bi-LSTM network alone when\ncombined with the GRU network.\n\u2022 We use Enorn Corpora datasets and compute precision, re-\ncall, and f-score to assess how well the suggested technique\nperforms. Our model outperforms several well-known ma-\nchine learning techniques as well as more contemporary\nmethods for spam message detection.\n2\nPROPOSED SYSTEM ARCHITECTURE AND\nMODEL\nE-mail is a valuable tool for communicating with other users. Email\nallows the sender to efficiently forward millions of advertisements\nat no cost. Unfortunately, this scheme is now being used in a variety\nof organizations. As a result, a massive amount of redundant emails\nis known as spam or junk mail, many people are confused about the\nemails in their E- Mailboxes. Each learning sequence is given for-\nward as well as backward to two different LSTM networks that are\nattached to the same outputs layer in order for bidirectional Lstms\nto function. This indicates that the Bi-LSTM has detailed sequential\ninformation about all points before and following each point in a\nspecific sequence. In other words, we concatenate the outputs from\nboth the forward and the backward LSTM at each time step rather\nthan just encoding the sequence in the forward direction. Each\nword\u2019s encoded form now comprehends the words that come before\nand after it. This is a problem for the Internet community. The di-\nagram depicts various stages that aid in the prediction of email spam:\nBecause real-world data is messy and contains unnecessary infor-\nmation and duplication, data preprocessing is critical in natural\nlanguage processing (NLP). The major preprocessing steps are de-\npicted below.\n2.1\nNLP Tokenization\nTokenization of documents into words follows predefined rules.\nThe tokenization step is carried out in Python with spacy library.\n2.2\nStop Words Removal\nStop words appear infrequently or frequently in the document, but\nthey are less significant in terms of importance. As a result, these\nare removed to improve data processing.\n2.3\nText Normalization\nA word\u2019s lexicon form or order may differ. Thus, they must all be\nchanged to their root word to be correctly analyzed. Lemmatization\nand stemming are the two methods that can be used for normal-\nization. When a word\u2019s final few characters are removed to create\na shorter form, even if that form has no meaning, the procedure\nis known as stemming. lemmatization [21] is a mixture of corpus-\nbased an rule-based methods, and it retains the context of a term\nwhile changing it back to its root.\n2.4\nFeature Extraction\nfeature extraction which transforms the initial text into its features\nso that it may be used for modeling after being cleaned up and\nnormalized. Before predicting them, we use a specific way to give\nweights to specific terms in our document. While it is simple for a\ncomputer to process numbers, we choose to represent individual\nwords numerically. In such cases, we choose word embeddings. IDF\nis the count of documents containing the term divided by the total\nnumber of documents, and occurrence is the amount of instances a\nword appears in a document. We derive characteristics based on\nequations. 1,2,3,4,5, and 6. We use equations to derive properties.\n\ud835\udc47 \ud835\udc53 \ud835\udc3c\ud835\udc51\ud835\udc53 = \ud835\udc61\ud835\udc53 \u2217\n\ufffd 1\n\ud835\udc51\ud835\udc53\n\ufffd\n(1)\n\ud835\udc47 \ud835\udc53 \ud835\udc3c\ud835\udc51\ud835\udc53 = \ud835\udc61\ud835\udc53 \u2217 Inverse(\ud835\udc51\ud835\udc53 )\n(2)\n\ud835\udc47 \ud835\udc53 \ud835\udc3c\ud835\udc51\ud835\udc53 (\ud835\udc61,\ud835\udc51, \ud835\udc37) = \ud835\udc47 \ud835\udc53 (\ud835\udc61,\ud835\udc51).\ud835\udc3c\ud835\udc51\ud835\udc53 (\ud835\udc61, \ud835\udc37)\n(3)\n\ud835\udc47\ud835\udc3c\ud835\udc51\ud835\udc53 (\ud835\udc61,\ud835\udc51) = log\n\ud835\udc41\n|\ud835\udc51\ud835\udf16\ud835\udc37\ud835\udc61\ud835\udf16\ud835\udc37|\n(4)\nA word2vec neural network-based approach is the method that is\nutilized for this goal as the tool. The following equation, referred\nto as 5, shows how word2vec handles word context through the\nuse of probability-accurate measurements. Here letter D stands for\nthe paired-wise display of a set of words, while the letters w and c0\nor c1 represent paired word context that originated from a larger\ncollection of set D.\n\ud835\udc43 (\ud835\udc37 = 1 | \ud835\udc64,\ud835\udc5011:\ud835\udc58) =\n1\n1 + \ud835\udc52\u2212(\ud835\udc64\u00b7\ud835\udc5011+\ud835\udc64\u00b7\ud835\udc5012+...+\ud835\udc64\u00b7\ud835\udc501\ud835\udc58)\n(5)\n\ud835\udc43 (\ud835\udc37 = 1 | \ud835\udc64,\ud835\udc501:\ud835\udc58) =\n1\n1 + \ud835\udc52\u2212(\ud835\udc64\u00b7\ud835\udc500)\n(6)\n183\nIC3 2023, August 03\u201305, 2023, Noida, India\nSachan et al.\n2.5\nWord-Embeddings\nWord-Embedding helps to improve on the typical \"bag-of-words\"\nworldview, which requires a massive sparse feature vector to score\nevery word individually to represent this same entire vocabulary.\nThis perception is sparse because the vocabulary is large, and each\nword or document is defined by a massive vector. Using a word\nmap-based dictionary, word embedding needs to be converted terms\n(words) into real value feature vectors. There are two basic issues\nwith standard feature engineering techniques for deep learning.\nData is represented using sparse vectors, and the second is that\nsome of the meanings of words are not taken into consideration.\nSimilar phrases will have values in embedding vectors that are\nalmost real-valued. The Input length in our proposed study is set\nto 700 for our suggested model. If the texts seemed to be integer\nencoded with value systems between 10 and 20, the vocabulary\ndistance would be 11. Our data is encoded as integers, and the input\nand output dimensions are both set to 50,000. The embedding layer\noutcome will be used in successive layers and for BiLSTM and GRU\nlayers.\n2.6\nMachine Learning Model\nWithin the scope of the research, we are using the subsequent ma-\nchine learning techniques, to examine and compare the overall\nefficacy of our suggested Bi-LSTM strategy: Support Vector Ma-\nchine, Gaussian NB, Logistic Regression, K - nearest neighbors, and\nRandom Forest (RF).\n2.7\nConvolution Network\nThe popular RNN model generally performs well but takes too\nlong to train the model incorporating the textual sequential data.\nWhen a layer is added after the RNN layer, the model\u2019s learning\nduration is considerably decreased. Higher-level feature extraction\nis another benefit. [19] additionally possible using the convolutional\nlayer. In essence, the convolution layer looks for combinations of\nthe various words or paragraphs in the document that involve the\nfilters. We use features with 128 dimensions and a size 10 for each.\nFor this task, the Relu activation function is utilized. After that, the\none-dimensional largest pooling layers with a pooling size of 4 are\nput on the data in order to obtain higher-level features.\n2.8\nBiLSTM Network with GRU\nRecurrent Neural Network (RNN) technique of text sentiment anal-\nysis is particularly well-liked and frequently applied. Recurrent\nneural networks (RNN) surpass conventional neural networks. be-\ncause it can remember the information from earlier time steps\nthanks to its memory. A state vector is combined with an RNN\u2019s\ndata to create a new state vector. The resulting state vector uses the\npresent to recollect past knowledge. The RNN is straightforward\nand is based on the following equations:\n\u210e\ud835\udc61 = tanh (\ud835\udc4a\u210e\u210e\u210e\ud835\udc61\u22121 +\ud835\udc4a\ud835\udf0b\u210e\ud835\udc65\ud835\udc61)\n(7)\n\ud835\udc66\ud835\udc61 = \ud835\udc4a\u210e\ud835\udc66\u210e\ud835\udc61\n(8)\nThe vanilla RNN[18]is not very good at remembering previous\nsequences. In addition to that, RNN struggles with diminishing\ngradient descent. A kind of RNN is a long short-term recall network\n(LSTM), solves a vanishing gradient descent problem and learns\nlong-term dependencies[10]. LSTM was actually created to address\nthe problem of long-term reliance. LSTM has the unique ability to\nrecall. The cell state is the LSTM model\u2019s central concept. With\nonly a small amount of linear interaction, the cell state follows the\nsequence essentially unmodified from beginning to end. gate of\nan LSTM is also significant. Under the command of these gates,\ninformation is safely inserted to or eliminated from the cell stated.\nThe following equations are used by the LSTM model to update\neach cell:\n\ud835\udc53\ud835\udc61 = \ud835\udf0e\n\ufffd\n\ud835\udc4a\ud835\udc53 \u00b7 [\u210e\ud835\udc61\u22121,\ud835\udc65\ud835\udc61] + \ud835\udc4f\ud835\udc53\n\ufffd\n(9)\nIn this case, Xt denotes input, and ht is the hidden state at the t\ntime step. The following is the revised cell state Ct:\n\ud835\udc56t = \ud835\udf0e (\ud835\udc4a\ud835\udc56 [\u210e\ud835\udc61\u22121,\ud835\udc65\ud835\udc61] + \ud835\udc4f\ud835\udc56)\n(10)\n\ud835\udc36\ud835\udc47 = tanh (\ud835\udc4a\ud835\udc50 [\u210e\ud835\udc61\u22121,\ud835\udc65\ud835\udc61] + \ud835\udc4f\ud835\udc50\ud835\udc61)\n(11)\n\ud835\udc36\ud835\udc61 = \ud835\udc53\ud835\udc61 \u2217 \ud835\udc36\ud835\udc61\u22121 + \ud835\udc56\ud835\udc61 \u2217 \ud835\udc36\ud835\udc47\n(12)\nHere, we may compute the output and hidden state at t time steps\nusing the point-wise multiplication operator *.\n\ud835\udc5c\ud835\udc61 = \ud835\udf0e (\ud835\udc4a\ud835\udc5c \u00b7 [\u210e\ud835\udc61\u22121,\ud835\udc65\ud835\udc61] + \ud835\udc4f\ud835\udc5c)\n(13)\n\u210e\ud835\udc61 = \ud835\udc5c\ud835\udc61 \u2217 tanh (\ud835\udc36\ud835\udc61)\n(14)\nDue to the reality it only considers all prior contexts from the\npresent one, LSTM does have a few drawbacks. As a result of this,\nit may accept data from preceding time steps through LSTM as well\nas RNN. Therefore, in order to avoid this issue, further improve-\nments are carried out with the help of a bidirectional recurrent\nneural network(Bi-RNN). BiRNN [13] can handle two pieces of in-\nformation from both the front and the back. Bi-LSTM is created\nby combining the Bi-RNN and LSTM. As a result, operating LSTM\nhas advantages such as cell state storage so that BiRNN have way\nto acknowledge from the context before and after. As a conse-\nquence of this, it provides the Bi-LSTM with the advantages of an\nLSTM with feedback for the next layer. Remembering long-term\ndependencies is a significant new benefit of Bi-LSTM. The output,\nwhich is a feature vector, will be based on the call state. Finally,\nwe forecast the probability of email content as Normal, Fraudu-\nlent, Harassment, and Suspicious Emails using as an input to the\nsoftmax activation function, which is a weighted sum of the dense\nlayer\u2019s outputs. To regulate the information flow, GRU employs\nthe point-wise multiplying function and logistic sigmoid activation.\nThe GRU has hidden states of storage memory and does not have\ndistinct memory cells or units for state control. The W, U, and b\nvectors, which stand for weights, gates, and biases, respectively, are\ncrucial variables that must be calculated during the creation of the\nGRU model. For training reasons, the pre-trained word embedding\nknown as the Glove vector is used. They made it clear that GRU\nis the superior model when there is a large amount of training\ndata for textual groups and word embedding is available. BiLSTM,\nCNN, and GRU is required so as to compensate for the deletion\nof the document\u2019s long-term and short-term connections. In our\ncase, the embedding dimension, maximum sequence length, and\nlexicon size were used to start the LSTM embedding layer in three\nseparate LSTM models. The input vector was modified to make it\nappropriate for such a Conv1D layer, prior situations\u2019 sequences are\nreturned by LSTM layer. The \"return sequences\" of the LSTM layer\nmust be set to False when the subsequent state is free of the gated\n184\nSemantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model\nIC3 2023, August 03\u201305, 2023, Noida, India\narchitecture. Quantity of learning parameters must be taken into\nconsideration. A 350-unit LSTM layer was set - up, and different\nLSTM unit combinations were tested. More importantly, because\nit has more parts, the model made with BiLSTM will take longer\nto train. Bidirectional LSTM is the name of a particular kind of\nrecurrent neural network that is primarily used for the processing\nof natural languages. (BiLSTM). It is able to use data from both\nsides, and, in contrast to regular LSTM, it enables input flow in\nboth directions. It is an effective instrument for demonstrating the\nlogical relationships between words and phrases, and this involves\nboth the forward and backward directions of the sequence. In con-\nclusion, BiLSTM works by adding one extra layer of LSTM, causing\nthe information flow to travel in the other direction. It only denotes\nthat the input sequence runs in reverse at the next LSTM layer. Mul-\ntiple operations, including averaging, summation, multiplication,\nand concatenation, are then applied to the results of the two LSTM\nlayers. The gated design of Bi-LSTM and GRU networks solves\nthe disappearing gradient and exploding problems. A good way to\nhandle more long sequences is to use Bi-LSMT and GRU together.\nGRU works well with datasets that don\u2019t have text. In two to three\nrounds, the complicated CNN+BiLSTM+GRU model learns the long\nsequence of email text well. We have used word embedding, cnn,\nbidirectional lstm and gru networks as our three building blocks\nto separate email messages based on their sentiment and text\u2019s\nsequential features. Also, we succinctly demonstrate below why\nthese blocks help identify email spam:\n\u2022 First, We have used the Sequence - to - sequence Lstm as the\ncurrent block in the networks since it can retrieve both the\nprevious and next sequences from the current. More so than\na straightforward LSTM network, it can also recognize and\nextract text sentiment and sequential properties.\n\u2022 Second, we extract the more complex and advanced charac-\nteristics for Bi-LSTM network using Convolutional Network\nblock, which is the network\u2019s second block after the Bi-LSTM\nblock. Bi-LSTM takes a long time to extract text-based fea-\ntures, hence one of the reasons for using this block is to\nreduce the network\u2019s overall training time.\n3\nEXPERIMENTAL EVALUATION\n3.1\nExperimental Setup\nWe divided the information into training and testing groups of\n80/20. We divided the remaining 20% of the 80 percent training\ndata into test data for the model. Construct, compute, and evaluate\nthe efficacy of the suggested method using the Pythonic packages\nKeras, as TensorFlow and Scikit learn.\n3.2\nDataset Description\nEmail spam detection is the foundation of this research project. The\ndataset includes normal emails from the Enron corpora, deceptive\nemails from phished email corpora, harassment emails chosen from\nhate speech, and the offensive dataset. Only the content of the email\nbody is used for analysis; all header information, including sender,\ntopic, CC, and BCC, are eliminated. Word2vector, TF-IDF, and Word\nEmbedding are used to extract characteristics from the email mes-\nsage and classify them. This dataset[8] is publicly available. The\npresented model is implemented using Python, and several metrics,\nincluding accuracy, precision, and recall, are used to examine the\noutcomes.\n3.3\nEvaluation Metrics and Results\nClassifier performance is assessed Using metrics such as accuracy,\nprecision, and recall. Four terms make up a confusion matrix that\nis used to calculate these metrics.\n\u2022 True positives (TP) are positive values that have been accu-\nrately assigned the positive label.\n\u2022 The negative values that are accurately identified as negative\nare known as True Negatives (TN).\n\u2022 True Negative values are those that can be accurately identi-\nfied as being negative (TN).\n\u2022 Positive readings that have been mistakenly labeled as nega-\ntive are known as False Negatives (FN).\nAssess the efficacy of the suggested model is listed below:\n3.3.1\nAccuracy. Accuracy reveals how frequently the ML model\nwas overall correct.\nAccuracy =\n\ud835\udc47\ud835\udc43 +\ud835\udc47\ud835\udc41\n\ud835\udc47\ud835\udc43 +\ud835\udc47\ud835\udc41 + \ud835\udc39\ud835\udc43 + \ud835\udc39\ud835\udc41\n(15)\n3.3.2\nPrecision. The accuracy of the model gauges how effectively\nit can predict a specific category.\nPrecision =\n\ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc43\n(16)\n3.3.3\nRecall. Recall tells us how often the model was able to rec-\nognize a specific category.\nRecall =\n\ud835\udc47\ud835\udc43\n\ud835\udc47\ud835\udc43 + \ud835\udc39\ud835\udc41\n(17)\nModel\nAccuracy\nPrecision\nRecall\nGaussian NB\n91.3\n90.1\n91.8\nRandom Forest\n88.41\n90\n88\nKNN\n86.6\n89\n87\nSVM\n92.4\n91\n92\nLSTM\n95.2\n95\n95.7\nProposed\nEnsemble\n(CNN,BiLSTM+GRU)\n97.32\n95.6\n95.3\nTable 1: Differet Model\u2019s Score on Test Data\nAccuracy, Precision, and Recall metrics are computed. In the\ngiven Table 1 where six different classifiers are Gaussian NB, Ran-\ndom Forest, KNN, SVM, LSTM, and Propose Ensemble Hybrid\nModel (CNN+BiLSTM+GRU) have been used in this work. In the\nCNN, Bi-LSTM, and GRU architectures which enable sequence pre-\ndiction, CNN strands for feature extraction on data input which are\ncombined with LSTM. It requires less time training and a higher\nexpandable model. Any bottlenecks are created by predictions and\nthe increasing number of distinct units of information. This model\nis useful for dealing with issue-related classifications that consist\nof two or more than two classes. So suggested Ensemble model, out\nof these six classifiers, produces more accurate findings.\n185\nIC3 2023, August 03\u201305, 2023, Noida, India\nSachan et al.\nFigure 1: Performance Analysis\n3.4\nComparative Analysis\nA model\u2019s ability to fit new data is measured by the validation\nloss, whereas its ability to fit training data is determined by the\ntraining loss. The two main variables that decide whether in which\nlearning is efficient or not are validation loss and training loss.\nLSTM and Suggested Ensemble hybrid Models have equivalent loss\nand accuracy. In this context, we are contrasting the LSTM with the\nproposed model (CNN, Bilstm, and GRU) in terms of their respective\nvalidation accuracies and losses. The model\u2019s accuracy was at its\nhighest after 14 epochs of operation when it achieved an accuracy\nof roughly 97-98% while minimizing model loss.\nFigure 2: LSTM Model Training and Validation Accuracy\nFigure 3: LSTM Model Training and Validation Loss\nFigure 4: Ensemble Model (CNN,BiLSTM+GRU) Training\nand Validation Accuracy\nFigure 5: Ensemble Model (CNN,BiLSTM+GRU)Training\nand Validation Loss\n186\nSemantic Analysis and Classification of Emails through Informative Selection of Features and Ensemble AI Model\nIC3 2023, August 03\u201305, 2023, Noida, India\nIn this Proposed ensemble hybrid model\u2019s train accuracy is 98.7%\nValidation accuracy is 97.32% and LSTM has train accuracy of 97.41%\nand validation accuracy is 95.2%. So based on figures 3 and 5 indicate\nthe validation loss for LSTM and the proposed ensemble hybrid\nmodel to be 0.93 and 0.84, respectively, and figures 2 and 4 show the\nvalidation accuracy to be 95.2% and 97.3%, respectively. LSTM and\nthe proposed hybrid model used ensemble artificial intelligence,\nwith the proposed hybrid model outperforming the LSTM. We\ndecide on dense architecture as the final model for identifying the\ntext messages as spam or nonspam based on loss, accuracy, and the\naforementioned charts. The loss and accuracy over epochs are more\nstable than LSTM, and the Proposed classifier has a straightforward\nstructure.\n4\nCONCLUSION\nThe model is composed of four networks Word-Embeddings, CNN,\nBi-LSTM, and GRU. We may train the model more quickly by using\nthe convolutional layer first, followed by the word-embedding layer,\nand then the BiLSTM network. The Bidirectional LSTM network\nalso has higher-level properties that we can extract. We have used\na bidirectional LSTM(BiLSTM)and GRU network to memorize a\nsentence\u2019s contextual meaning and sequential structure, which im-\nproves the model\u2019s performance accuracy to roughly 97.32 percent.\nREFERENCES\n[1] Rayan Salah Hag Ali and Neamat El Gayar. 2019. Sentiment analysis using unla-\nbeled email data. In 2019 International Conference on Computational Intelligence\nand Knowledge Economy (ICCIKE). IEEE, 328\u2013333.\n[2] Ali Shafigh Aski and Navid Khalilzadeh Sourati. 2016. Proposed efficient algo-\nrithm to filter spam using machine learning techniques. Pacific Science Review A:\nNatural Science and Engineering 18, 2 (2016), 145\u2013149.\n[3] Huwaida T Elshoush and Esraa A Dinar. 2019. Using adaboost and stochastic\ngradient descent (sgd) algorithms with R and orange software for filtering e-mail\nspam. In 2019 11th Computer Science and Electronic Engineering (CEEC). IEEE,\n41\u201346.\n[4] Weimiao Feng, Jianguo Sun, Liguo Zhang, Cuiling Cao, and Qing Yang. 2016. A\nsupport vector machine based naive Bayes algorithm for spam filtering. In 2016\nIEEE 35th International Performance Computing and Communications Conference\n(IPCCC). IEEE, 1\u20138.\n[5] Pranjul Garg and Nancy Girdhar. 2021. A Systematic Review on Spam Filtering\nTechniques based on Natural Language Processing Framework. In 2021 11th Inter-\nnational Conference on Cloud Computing, Data Science & Engineering (Confluence).\nIEEE, 30\u201335.\n[6] Adam Kavon Ghazi-Tehrani and Henry N Pontell. 2021. Phishing evolves: Ana-\nlyzing the enduring cybercrime. Victims & Offenders 16, 3 (2021), 316\u2013342.\n[7] Radicati Group et al. 2015. Email Statistics Report 2015\u20132019. Radicati Group.\nAccessed August 13 (2015), 2019.\n[8] Maryam Hina, Mohsin Ali, and Javed. 2021. Sefaced: Semantic-based forensic\nanalysis and classification of e-mail data using deep learning. IEEE Access 9\n(2021), 98398\u201398411.\n[9] Maryam Hina, Mohsin Ali, Abdul Rehman Javed, Fahad Ghabban, Liaqat Ali\nKhan, and Zunera Jalil. 2021. Sefaced: Semantic-based forensic analysis and\nclassification of e-mail data using deep learning. IEEE Access 9 (2021), 98398\u2013\n98411.\n[10] Weicong Kong, Zhao Yang Dong, Youwei Jia, David J Hill, Yan Xu, and Yuan\nZhang. 2017. Short-term residential load forecasting based on LSTM recurrent\nneural network. IEEE transactions on smart grid 10, 1 (2017), 841\u2013851.\n[11] T Kumaresan and C Palanisamy. 2017. E-mail spam classification using S-cuckoo\nsearch and support vector machine. International Journal of Bio-Inspired Compu-\ntation 9, 3 (2017), 142\u2013156.\n[12] Nuha H Marza, Mehdi E Manaa, and Hussein A Lafta. 2021. Classification of\nspam emails using deep learning. In 2021 1st Babylon International Conference on\nInformation Technology and Science (BICITS). IEEE, 63\u201368.\n[13] Tomas Mikolov and Geoffrey Zweig. 2012. Context dependent recurrent neural\nnetwork language model. In 2012 IEEE Spoken Language Technology Workshop\n(SLT). IEEE, 234\u2013239.\n[14] Sarwat Nizamani, Nasrullah Memon, Mathies Glasdam, and Dong Duong Nguyen.\n2014. Detection of fraudulent emails by employing advanced feature abundance.\nEgyptian Informatics Journal 15, 3 (2014), 169\u2013174.\n[15] V Priya, I Sumaiya Thaseen, Thippa Reddy Gadekallu, Mohamed K Aboudaif,\nand Emad Abouel Nasr. 2021. Robust attack detection approach for IIoT using\nensemble classifier. arXiv preprint arXiv:2102.01515 (2021).\n[16] Justinas Rastenis, Simona Ramanauskait\u02d9e, Justinas Janulevi\u010dius, Antanas \u010cenys,\nAsta Slotkien\u02d9e, and K\u0119stutis Pakrijauskas. 2020. E-mail-based phishing attack\ntaxonomy. Applied Sciences 10, 7 (2020), 2363.\n[17] Karthika D Renuka and P Visalakshi. 2014. Latent semantic indexing based SVM\nmodel for email spam classification. (2014).\n[18] Shuvendu Roy, Sk Imran Hossain, MAH Akhand, and N Siddique. 2018. Sequence\nmodeling for intelligent typing assistant with Bangla and English keyboard. In\n2018 International Conference on Innovation in Engineering and Technology (ICIET).\nIEEE, 1\u20136.\n[19] Tara N Sainath, Oriol Vinyals, Andrew Senior, and Ha\u015fim Sak. 2015. Convolu-\ntional, long short-term memory, fully connected deep neural networks. In 2015\nIEEE international conference on acoustics, speech and signal processing (ICASSP).\nIeee, 4580\u20134584.\n[20] Anuj Kumar Singh, Shashi Bhushan, and Sonakshi Vij. 2019. Filtering spam\nmessages and mails using fuzzy C means algorithm. In 2019 4th International\nConference on Internet of Things: Smart Innovation and Usages (IoT-SIU). IEEE,\n1\u20135.\n[21] Kristina Toutanova and Colin Cherry. 2009. A global model for joint lemmati-\nzation and part-of-speech prediction. In Proceedings of the Joint Conference of\nthe 47th Annual Meeting of the ACL and the 4th International Joint Conference on\nNatural Language Processing of the AFNLP. 486\u2013494.\n[22] Tian Xia. 2020. A constant time complexity spam detection algorithm for boosting\nthroughput on rule-based filtering systems. IEEE Access 8 (2020), 82653\u201382661.\n[23] Yan Zhang, PengFei Liu, and JingTao Yao. 2019. Three-way email spam filtering\nwith game-theoretic rough sets. In 2019 International conference on computing,\nnetworking and communications (ICNC). IEEE, 552\u2013556.\nReceived 15 April 2023\n187\n",
    "pdf_url": "",
    "references": [
      "[1] Rayan Salah Hag Ali and Neamat El Gayar. 2019. Sentiment analysis using unla-",
      "beled email data. In 2019 International Conference on Computational Intelligence",
      "and Knowledge Economy (ICCIKE). IEEE, 328\u2013333.",
      "[2] Ali Shafigh Aski and Navid Khalilzadeh Sourati. 2016. Proposed efficient algo-",
      "rithm to filter spam using machine learning techniques. Pacific Science Review A:",
      "Natural Science and Engineering 18, 2 (2016), 145\u2013149.",
      "[3] Huwaida T Elshoush and Esraa A Dinar. 2019. Using adaboost and stochastic"
    ],
    "publication_date": "06-11-2023"
  },
  {
    "titre": "A Prototype Implementation of an Orthographic Software Modeling Environment",
    "resume": "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
    "auteurs": [
      "Colin Atkinson",
      "Dietmar Stoll",
      "Jacques Robin",
      "Recife",
      "Brasil",
      "D.2.2"
    ],
    "institutions": [
      "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
      "Dietmar Stoll University of Mannheim, TunjicUniversity of Mannheim,",
      "Colin Atkinson University of Mannheim,"
    ],
    "mots_cles": [
      " Orthographic Software Modeling",
      " View-based Modeling "
    ],
    "texte_integral": "A Prototype Implementation of an Orthographic Software\nModeling Environment\nColin Atkinson\nUniversity of Mannheim,\nGermany\natkinson@informatik.uni-\nmannheim.de\nDietmar Stoll\nUniversity of Mannheim,\nGermany\nstoll@informatik.uni-\nmannheim.de\nChristian Tunjic\nUniversity of Mannheim,\nGermany\ntunjic@informatik.uni-\nmannheim.de\nJacques Robin\nUniversidade Federal de\nPernambuco, Recife, Brasil\njr@cin.ufpe.br\nABSTRACT\nOrthographic Software Modeling (OSM) is a view-centric\nsoftware engineering approach that aims to leverage the or-\nthographic projection metaphor used in the visualization of\nphysical objects to visualize software systems. Although the\ngeneral concept of OSM does not prescribe speci\ufb01c sets of\nviews, a concrete OSM environment has to be speci\ufb01c about\nthe particular views to be used in a particular project. At\nthe University of Mannheim we are developing a prototype\nOSM environment, nAOMi, that supports the views de\ufb01ned\nby the KobrA 2.0 method, a version of KobrA adapted for\nOSM. In this paper we provide an overview of the KobrA 2.0\nmetamodel underpinning nAOMi and give a small example\nof its use to model a software system.\nCategories and Subject Descriptors\nD.1.7 [Programming Techniques]: Visual Programming;\nD.2.2 [Design Tools and Techniques]: Computer-aided\nsoftware engineering (CASE); D.2.6 [Software Engineer-\ning]: Programming Environments\u2014Graphical environments\nKeywords\nOrthographic Software Modeling, View-based Modeling\n1.\nINTRODUCTION\nOrthographic Software Modeling (OSM) is based on three\nfundamental hypotheses \u2014 (a) that it is feasible to inte-\ngrate the many di\ufb00erent kinds of artifacts used in contempo-\nrary software engineering methods within a single coherent\nmethodology in which they are treated as views, (b) that it\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for pro\ufb01t or commercial advantage and that copies\nbear this notice and the full citation on the \ufb01rst page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior speci\ufb01c\npermission and/or a fee.\nVAO \u201913, July 2, 2013, Montpellier, France\nCopyright 2013 ACM 978-1-4503-2041-2 ...$15.00.\nis feasible to create an e\ufb03cient and scalable way of support-\ning these views by generating them dynamically, on-the-\ufb02y,\nfrom a Single Underlying Model (SUM) using model-based\ntransformations and (c) that it is feasible to provide an in-\ntuitive metaphor for navigating around these many views\nby adapting the orthographic projection technique under-\npinning the CAD tools used in other engineering disciplines.\nFigure 1: Orthographic Projection.\nAs shown in Figure 1, the main advantages of using the\nidea of orthographic projection to de\ufb01ne the views used\nto visualize and described a system are that they (a) can\nbe organized according to a simple and easy-to-understand\nmetaphor and (b) collectively represent all the properties of\na system with minimal overlap and redundancy. In practice\nthis translates into a set of \u201cdimensions\u201d, each containing\nwell de\ufb01ned choices (or so called \u201cdimension elements\u201d) that\ncan be used to select individuals views.\nAs shown in Figure 2, the main advantage of making the\nartifacts used to describe a software system views of a SUM\nis that the number of pairwise coherence relationships that\nhave to be maintained is reduced and new views can be in-\ntroduced by simply de\ufb01ning their relationship to the SUM.\nMoreover, the importance of this advantage grows quickly\nas the size of the system and the complexity of the deployed\ndevelopment methodology increase. Another important ad-\nvantage is that the dominance of one particular kind of view\nover the development process (e.g. code) at the expense of\nother kinds of views (e.g. graphical models) is reduced so\nthat any appropriate type of views can be used to enrich\nthe underlying description of the system, depending on the\nneeds and skills of the stakeholder involved. This makes it\npossible to subsume all view types under the same, overarch-\nSUM\nSUM / View Centric Environment\nArtifact / Tools Centric Environment\nFigure 2: Consistency Dependencies in Artifact-oriented versus View-oriented Environments.\ning development process and methodology (e.g. agile-driven,\nfocusing on small development cycles, or model-driven de-\nvelopment, based on transformations between abstraction\nlevels). Although the details of how the views are created\nfrom the SUM and how the SUM is updated from the views\nare not central to the approach, a natural implementation\nis to use the visualization and transformation technologies\no\ufb00ered by model driven software engineering (MDSE).\nTo explore the validity of these hypotheses at the Uni-\nversity of Mannheim we have been developing a prototype\nOSM modeling environment based on an enhanced version\nof the KobrA method for model-driven, component-oriented\ndevelopment, KobrA 2.0 [1]. This was chosen as a basis for\nthe prototype, known as the Open, Adaptable, Orthographic\nModeling Environment (nAOMi) [13] because its views were\ndesigned with the precise goals of being (a) genuine pro-\njections of a subject containing carefully selected subsets\nof information about that subject, (b) minimalistic in the\nsense that they should overlap to the smallest extent possible\nand contain the minimum necessary models elements, and\n(c) selectable via a set of independent \u201cdimensions\u201d which\nre\ufb02ect di\ufb00erent fundamental concerns of development (i.e.\nabstraction levels, composition or variants). In other words,\nKobrA already provided one of the \u201cmost orthogonal\u201d sets\nof views for visualizing software systems of any contempo-\nrary method. More details about the actual views and di-\nmensions de\ufb01ned in KobrA are presented in the following\nsections. More information on OSM can be found in [2] and\n[3].\nnAOMi is implemented as an Eclipse plugin using the\nEclipse Modeling Framework (EMF) as the underlying mod-\neling platform and UML 2.0 tools [4] to generate and edit\nviews.\nThe KobrA 2.0 metamodel on which the current\nversion of nAOMi is based is a specialization of the UML\nmetamodel composed of three separate packages \u2014 one for\nthe SUM, one for the views and one for the transformations\n(Figure 3). The UML was chosen as the base language be-\ncause of its maturity and widespread acceptance, making the\nenvironment usable to the largest possible body of develop-\ners. UML elements not needed in KobrA 2.0 are excluded\nusing OCL constraints while new elements or properties are\nKobrA2\nTransformation\nSUM\nViews\nFigure 3: KobrA 2.0 Top Level Packages.\nintroduced by specializing existing elements.\nThe unique contribution of this paper is to elaborate on\nthe structure of the KobrA 2.0 metamodel and how it is used\nto drive nAOMi. The three following sections each focus on\none of the three main components of the metamodel \u2014 the\nSUM, the views and the transformations . This is followed\nby a brief overview of the OSM navigation paradigm in Sec-\ntion 5 before a small example of the approach is presented in\nSection 6. Section 7 then concludes the paper with related\nand future work.\n2.\nSUM PACKAGE\nFigure 4 depicts the internal structure of the SUM pack-\nage which is based on the UML metamodel. There are three\nmain subpackages, two containing the structural and behav-\nioral constructs respectively, and one containing the con-\nstraints that ensure that the metaclasses are used according\nto the KobrA conventions and rules.\nThe Classes subpackage of the Structure package contains\nsome of the most fundamental elements of the KobrA meta-\nmodel, such as Class and ComponentClass.\nThe internal\nstructure of this package is illustrated in Figure 5. Com-\nponentClass represents objects with complex and reusable\nbehaviors, while Class captures simple \u201cdata type\u201d objects\nthat have only very simple or non-reusable behaviors. The\nmodeler has to decide whether it is necessary to model a\nspeci\ufb01c part of the system as a ComponentClass and include\nstate charts and activity diagrams, or whether it is su\ufb03cient\nto use a Class (which is limited to using OCL constraints).\nComponentClass inherits (indirectly via Class) from Com-\nmunications so it also has the isActive attribute. This makes\nKobrA2::SUM::Constraint::Behavioral\nKobrA2::SUM::Constraint::Structural\nKobrA2::SUM::Constraint\nKobrA2::SUM::Constraint::Common\nKobrA2::SUM::Behavior::ProtocolStateMachines\nKobrA2::SUM::Behavior::Common\nKobrA2::SUM::Behavior::Activities\nKobrA2::SUM::Behavior::Actions\nKobrA2::SUM::Behavior\nKobrA2::SUM::Structure::Classes\nKobrA2::SUM::Structure::Types\nKobrA2::SUM::Structure::Instances\nKobrA2::SUM::Structure::Elements\nKobrA2::SUM::Structure\nKobrA2::SUM::Constraint::OclExpressions\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\nFigure 4: KobrA 2.0 SUM Package.\nit possible to model whether its instances are active or pas-\nsive. Active objects, which can be used to model threads and\nprocesses ([8] p. 438), start to execute their behavior as soon\nas they are created and perform operations spontaneously.\nA ComponentClass may exhibit complex behavior. In Ko-\nbrA, this behavior may be speci\ufb01ed in the form of\nUML\nState Diagrams (de\ufb01ning acceptable operation invocation\nsequences), and in the form of Activities (de\ufb01ning algorithms\nof operations). UML Interaction elements (in sequence dia-\ngrams) can be derived from the activity elements and thus\nare not included in the SUM. As KobrA aims to facilitate\nautomatic checking of allowed sequences of operation calls,\nProtocol State Machines are supported instead of general\nstate machines. Since the latter include a large variety of\nelements not needed for specifying acceptable operation se-\nquences or automatic checking, OCL constraints are used to\nprohibit the use of unwanted features.\ncontext\nComponentClass\n-- only\nallow\nActivity\nelements\nor\nProtocolStateMachines\ninv: ownedBehavior ->forAll( oclIsKindOf( Actitivity) or\noclIsKindOf ( ProtocolStateMachine ))\nFor example, since KobrA has no concept of roles for com-\nponents, the use of role also needs to be prohibited. The part\nassociation refers to owned properties of components whose\nattribute isComposite is true. As KobrA uses associations\nlike nests and creates for components, part, required and\nprovided are not needed. Connectors (i.e. delegation and\nassembly) are not used in KobrA either so ownedConnector\nis excluded.\nClass\nKobrA2::SUM::Structure::Classes\nGeneralizationSet\nAssociationClass\nComponentClass\nProperty\nUsage\nAssociation\nOperation\nPackageable\nElement\nParameter\nAcquires\nCreates\nNests\nUML::Component::PackagingComponents::Component\nUML::CommonBehaviors::Communications::Class\n+ownedOperation\n*\n+class\n0..1\n+supplier\n1..*\n{subsets supplierDependency}\n+supplierUsage\n*\n+client\n1..*\n{subsets clientDependency}\n+clientUsage\n*\n+ownedAttribute\n*\n+class\n0..1\n+powertype\n0..1\n+powertypeExtent\n*\n+packagedElement\n*\n{subsets component}\n+componentClass\n0..1\n+/superClass\nFigure 5: KobrA 2.0 Classes Package.\ncontext\nComponentClass\ninv: role ->union(part)->union( ownedConnector )\n->union( collaborationUse )-> union( representation )\n->union( realization)->union(required)\n->union(provided)->isEmpty ()\n3.\nVIEWS PACKAGE\nThe structure of the Views package is illustrated in Figure\n6. Again, since most of the views de\ufb01ned in KobrA 2.0 are\nbased on UML diagrams, the view metamodels have similar\nelements to the SUM metamodel. The big di\ufb00erence to the\nSUM is that there are no restrictions on the use of the view\nmetamodel elements.\nFor instance, views for a particular\npurpose such as supporting model checkers can be supported\nby adding elements unrelated to the UML.\nThe substructure of the Views package re\ufb02ects the types\nand organization of the KobrA views according to the view\n\u201cdimensions\u201d supported in nAOMi (cf. example in Section\n6). At the top level, the Views package is thus decomposed\ninto the Speci\ufb01cation and Realization options of the encap-\nsulation dimension.\nThese, in turn are both decomposed\ninto the Structural, Behavioral and Operational options of\nthe Projection dimension.\nFinally, with the exception of\nthe behavioral option, these are also all subdivided into the\nService and Type options of the granularity dimension. This\ndimension, with its two options, is an addition to the original\nversion of KobrA.\nThe Service view shows the direct, publicly visible rela-\ntionships of the subject ComponentClass to other Compo-\nnentClasses, while the Type view shows the publicly visi-\nble relationships of the subject to simple Classes. As with\nthe SUM, constraints have been de\ufb01ned to control what can\ngo into each view and when they are well formed. For ev-\nery view, a constraint enumerates all allowed elements (not\nshown in this paper).\nIn the following, some of the other constraints for the\nService view are elaborated. Since this view is a black-box\nview, the internals of ComponentClasses (nestedClassi\ufb01er)\nare not shown.\ncontext\nComponentClass\n-- no nested\nclassifiers , no\nprotocol\ninv: nestedClassifier ->union(protocol)->isEmpty ()\nClasses are only allowed if they are generalizations of Com-\nponentClasses, (or any of its superclasses, since a Compo-\nnentClass may inherit from a class as shown in the con-\nstraints with context Class. The following invariants ensure\nthat only publicly visible attributes and operations are in\nthis view, for both classes and ComponentClasses (which\ninherit from Class).\nClass\nService\nType\nInstance\nService\nType\nStructural\nSpecification\nOperational\nService\nType\nProtocol\nBehavioral\nKobrA2::Views::Derived\nComponentClassDependencies\nOperationDependencies\nInstance\nService\nType\nClass\nService\nType\nStructural\nRealization\nOperational\nService\nType\nBehavioral\nAlgorithm\nViews\nConcreteSyntax\nSubject\n<<import>>\n<<merge>>\n<<merge>>\n<<import>>\n<<merge>>\n<<import>>\nFigure 6: KobrA 2.0 Views package nesting.\ncontext\nClass\n-- only\nallow\nclasses\nthat\nare\ndirect or\nindirect\ngeneralizations\nof\nComponentClasses\nin this\nview\ndef: ccGeneralization : generalization .specific ->\nexists( oclIsKindOf ( ComponentClass ))\ninv:\ngeneralization .specific ->select( oclIsTypeOf (\nClass))->exists(s|s. ccGeneralization )\nor\nccGeneralization\n-- only\npublic\nattributes\nin this\nview\ninv: ownedAttribute ->forAll(visibility =# public)\n-- only\npublic\nOperations\nare\nallowed\nin the\nspecification\ninv: ownedOperation ->forAll(visibility =# public)\nOnly operation signatures are shown in this view, so pre-,\npost- and bodyconditions, as well as activities are omitted,\nwhich is re\ufb02ected in the last constraint.\ncontext\nOperation\n-- only\nthe\nsignature\nof the\nOperation\nis shown , not\nits\nbehavior (role\nname \"method\" refers to the\nActivities\nof the\noperation), or\ndependencies\ninv: method ->union( precondition )->union(body)->union(\npostcondition )->isEmpty ()\n4.\nTRANSFORMATIONS PACKAGE\nThe package AllViews provides the foundation for speci-\nfying the transformations between the SUM and the views\nin both directions. Part of the package\u2019s contents are shown\nin Figure 7.\nThe Abstraction concept (which is in fact a\nKobrA2::Transformation::Common::AllViews\nAbstraction\nTransformationExpression\nViewElement\nSumElement\nView\nKobrA2::SUM::Structure::Elements::Element\nKobrA2::Views::ConcreteSyntax::Element\nKobrA2::SUM::Constraint::Behavioral::Exp\nressionInOcl\nKobrA2::Views::Subject::View\n{subsets mapping}\n0..1\n0..1\n{subsets clientDependency}\n+abstraction 1\n{subsets client}\n+ve 1\n1..*\n1\n{subsets supplier}\n+se 1\n{subsets supplierDependency}\n+abstraction 1..*\nFigure 7: Transformation abstractions.\ndependency reused from the UML but with additional con-\nstraints) plays the key role in relating elements from the\nSUM to elements of a view. Abstraction is actually mapped\nto ExpressionInOcl.\nWhen appearing in transformations,\nthe equals sign links elements in the SUM to the respective\nelements in the view, and vice versa. For instance, equal-\nity of the general meta-association of a Generalization in\na transformation invariant means that, when following gen-\neral, there must be an element in the SUM and in the view\nfor which similar transformation expressions are speci\ufb01ed.\nIn the case of KobrA 2.0, which has many projections that\njust select a subset of elements using one-to-one abstrac-\ntions, this allows concise declarative TransformationExpres-\nsions. Together with the view constraints, a CASE tool can\nbe implemented which uses a transformation language of the\nimplementor\u2019s choice, for instance the Atlas Transformation\nLanguage (ATL) [11] or QVT [9]. The role names se and ve\nare short for SumElement and ViewElement, respectively.\nThese roles subset the client and supplier roles from the\nUML.\nSUM elements are translated into UML elements with\nstereotypes, so that the views are easy to manage for de-\nvelopers familiar with the UML. The bidirectional mappings\nbetween stereotyped view elements and non-stereotyped SUM\nelements are expressed in the constraints of the Association-\nAbstraction, a subclass of the Abstraction from the AllViews\npackage. This is also an example of a transformation which\nis reused in other views.\ncontext\nAssociationAbstraction\ninv: ve.memberEnd = se.memberEnd\ninv: ve.ownedEnd = se.ownedEnd\nivn: ve. navigableOwnedEnd = se. navigableOwnedEnd\ninv: se. oclIsKindOf(Acquires) implies ve.\nhasStereotype (\u2019acquires \u2019)\ninv: ve. hasStereotype (\u2019acquires \u2019)\nimplies\nse.\noclIsKindOf (Aquires)\ninv: se. oclIsKindOf(Nests) implies\nve. hasStereotype (\u2019\nnests \u2019)\ninv: ve. hasStereotype (\u2019nests \u2019)\nimplies se. oclIsKindOf\n(Nests)\ninv: se. oclIsKindOf (Creates) implies\nve. hasStereotype\n(\u2019creates \u2019)\ninv: ve. hasStereotype (\u2019creates \u2019)\nimplies se.\noclIsKindOf (Creates)\nFigure 8 shows the main elements involved in the trans-\nformation of the black box structural view for Component-\nClasses. The \ufb01rst transformation constraint is on the view\nand declares the starting point for the transformation. It\nstates that the subject ComponentClass and its generaliza-\ntions (using a SUM utility function, superClosure) are in the\nview.\nThe following transformation rules illustrate how to create\nthe output (i.e. view) elements from the input (i.e. SUM) el-\nements, such as the publicly visible attributes and operations\nof the ComponentClass and the acquired ComponentClasses.\nThe \ufb01rst constraint for ComponentClassAbstraction states\nthat references to potential general classes (and Component-\nClasses) of ComponentClasses are mirrored in the view. In\naddition, ComponentClasses will be shown with the corre-\nsponding stereotypes.\nThe ComponentClass owns various\ntypes of associations, so in this view only the acquires asso-\nciations are selected (whose transformation rules are cov-\nered in the common transformation packages).For classes\nand ComponentClasses, only publicly visible attributes and\noperations appear in the view.\nClass invariants are also\ncopied. Classes that may appear in this view (e.g. as gener-\nalizations of ComponentClasses) may have a powertype (role\nname powertypeExtent) which will be displayed.\nThe last transformation statement copies the class refer-\nences of operations. As with all views, the transformation\nrules, the common transformation statements (which also\ncover operations) and the view constraints serve as a speci-\n\ufb01cation for the implementation of a view. Individual CASE\ntools can use di\ufb00erent implementation techniques as long as\nthey conform to the semantics of these rules and constraints.\nKobrA2::Transformation::Specification::Structural::Class::Service\nComponentClassAbstraction\nKobrA2::Transformation::Common::Feature::OperationAbstraction\nKobrA2::Transformation::Common::AllViews::Abstraction\nKobrA2::SUM::Structure::Classes::ComponentClass\nKobrA2::SUM::Structure::Classes::Operation\nKobrA2::SUM::Structure::Classes::Class\nOperationAbstraction\nClassAbstraction\n+se\n1\n1..*\n+se\n1\n1..*\n+se\n1\n1..*\nFigure 8: Transformation to the Speci\ufb01cation Structural Service View.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassService\ninv: ownedMember ->select( oclIsKindOf(Class)) =\nsubject.superClosure ->union(subject.acquires.\nsuperClosure )\ncontext\nComponentClassAbstraction\ninv: ve.superClass = se. superClass\ninv: ve. hasStereotype (\u2019ComponentClass \u2019)\ninv: se.isSubject\nimplies (ve. hasStereotype (\u2019subject\n\u2019) and ve.ownedMember ->select( oclIsKindOf (\nAssociation )) = se.ownedMember ->select(\noclIsKindOf (Acquires)))\ncontext\nClassAbstraction\ninv: ve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\ninv: ve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public)\ninv: ve.\u2018inv \u2019 = se.\u2018inv \u2019\n-- copy\npowertypeExtent\nthat is only\nallowed\nfor\nclass\ninv: ve. powertypeExtent = se. powertypeExtent\ncontext\nOperationAbstraction\ninv: ve.class = se.class\nFor the black box type view, only publicly visible at-\ntributes and operations of classes (as opposed to Compo-\nnentClasses) used by the subject can be seen. This is spec-\ni\ufb01ed in the \ufb01rst rule which de\ufb01nes owned members of the\nview and thus serves as the starting point of the transfor-\nmation. cbbTypes is a utility function de\ufb01ned in the SUM\nwhich computes the black box types by selecting the types\nof the subject\u2019s public attributes and parameter types of its\npublic operations.\nClass invariants and potential powertypes and connections\nto the classes in this view are shown as well. There may\nalso be Enumerations, for which the EnumerationLiterals\nare displayed.\nThe transformation rules for this view are almost the same\nas the realization transformation constraints from the pack-\nage Transformation::Realization::Structural::Class::Type. The\ndi\ufb00erences are the select(visibility=#public) statements for\noperations and attributes.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassType\ninv: ownedMember ->select( oclIsKindOf(Class) or\noclIsKindOf(\u2018Enumeration \u2019) or\noclIsKindOf (\nAssociation)) = subject ->union(subject.cbbTypes)\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nClassAbstraction\ninv: not se.oclIsKindOf ( ComponentClass ) implies (\nve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\nve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public))\ninv: ve. powertypeExtent = se. powertypeExtent\ninv: ve. superClass = se.superClass\ninv: \u2018ve.inv \u2019 = \u2018se.inv \u2019\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nEnumerationAbstraction\ninv: ve. ownedLiteral = se. ownedLiteral\ncontext\nEnumerationLiteralAbstraction\ninv: ve. specification = se. specification .\nstringInSignature\n5.\nNAVIGATION\nMost of today\u2019s tools use some combination of trees to\norganize the content of models as well as the views used to\nvisualize a software system or component. In an any envi-\nronment incorporating a number of di\ufb00erent tools there is\ninvariably a large number of di\ufb00erent trees storing a het-\nerogeneous mix of artifacts including model elements (e.g.\nclasses, instances, associations), diagrams (e.g.\nclass dia-\ngrams, state diagrams) and other artifact types (source code,\nXML \ufb01les, con\ufb01guration \ufb01les ). To work with all the views in\na traditional development environment, therefore, engineers\ntypically have to learn about the organization structures of\nall the incorporated tools.\nIn contrast to conventional paradigms for organizing and\nnavigating the many views used to visualize a system, OSM\nemploys the metaphor of a multi-dimensional cube. More\nspeci\ufb01cally, as illustrated in Figure 9, OSM regards dimen-\nsion of the underlying methodology as representing a di\ufb00er-\nent dimension of the cube, and each independently variable\naspect of that dimension is a selectable dimension element.\nSelecting a view thus simply corresponds to selecting a single\ncell within the cube. In general, three types of dimensions\nare supported: static dimensions in which the number of\nFigure 9: Dimension-based navigation.\nselectable elements (i.e. coordinates) is \ufb01xed, dynamic di-\nmensions in which the number of elements is dynamic (i.e.\nderived from the SUM), and mixed dimensions which have\nboth static and dynamic elements.\nTo support the OSM dimension based navigation metaphor\nfor KobrA, we de\ufb01ned the seven dimensions indicated on the\nleft hand side of Figure 10 which is a sceenshot of nAOMI.\nThe Abstraction dimension (not expanded here), which has\nthree static dimension elements, PIM (platform independent\nmodel), PSM (platform speci\ufb01c model) and Code, captures\nthe model-driven development concern of KobrA. The ver-\nsion dimension captures the state of the modeled system at\nspeci\ufb01c points in time. The Component dimension, which\nhas dynamic dimension elements de\ufb01ned by instances of the\nclass ComponentClass in the SUM, captures the component-\nbased development concern of KobrA.\nThe Encapsulation dimension, which has two \ufb01xed ele-\nments, supports the distinction between Speci\ufb01cation (black\nbox) and Realization (white box) views of components, while\nthe Projection dimension with the \ufb01xed elements Structural,\nOperational and Behavioral covers the di\ufb00erent information\ntypes. The Granularity dimension provides a \ufb01ner grained\ndistinction between views describing the types used by com-\nponents (Type granularity) and views describing the required\nand provided interfaces (Service granularity). The Opera-\ntion dimension allows a selection of individual operations.\nIn the ideal case, when all views are truly orthogonal, the\nchoices that can be made in each dimensions are completely\nindependent.\nHowever, this is very di\ufb03cult to achieve in\nsoftware engineering. The approach still works if the views\nare not completely orthogonal, but dependencies then occur\nbetween di\ufb00erent choices in di\ufb00erent dimensions, so that the\ndecisions made in one dimensions may a\ufb00ect choices possi-\nble in another dimension. This is best handled by giving\ndimensions a precedence ranking determined by the order\nin which they appear (the top being the highest). When an\nelement in a dimension is selected, the tool automatically\nmakes default selections for dimensions of lower precedence\n(i.e.\ndimensions lower down) and disables selections that\nwould navigate to cells (i.e. views) which are not (yet) de-\n\ufb01ned by the method at hand.\n6.\nSHOPPING CART EXAMPLE\nTo show how a software system can be speci\ufb01ed using\nnAOMi, this section presents a case study based on a shop-\nping cart system. A ShoppingCart component collects and\nFigure 10: Speci\ufb01cation Structural View.\nmanages the products selected by users and supports pay-\nment via a credit card.\nFigure 10 illustrates a structural\nview of the component.\nIn the dimension navigator on the left hand side, PIM\nwas chosen for the \u201cAbstraction Level\u201d (not expanded in the\nscreenshot). The second dimension is the state of the soft-\nware system at a certain point in time. The picture shows\nthat the latest available version was chosen. As with every\nchoice in a dimension, it may in\ufb02uence the options in lower\nranked dimensions. The component under consideration is\nthe ShoppingCart, for which a black box view is selected\nin the next dimension. After the user selects the structural\nprojection option and the service level granularity, the tool\nautomatically chooses the option for all operations in the\nlast dimension, as there is no editor registered for the other\noptions.\nThe component under development is presented with the\nstereotype subject and its relationship to other components\nand classes is shown in the view, which corresponds to a cell\nof the multi-dimensional navigation cube, and is generated\non-the-\ufb02y from the SUM when it is selected. The classes\nProduct and CreditCard can be used as data types in the\noperations of the component.\nFigure 11 illustrates the operational view in which an\noperation can be formalized using pre- and postconditions.\nThe precondition corresponds to the assumes clause in and\nthe postcondition corresponds to the result clause. As in the\nUML, the precondition of an operation must be true when\nthe operation is invoked and the postcondition must be true\nwhen the operation is \ufb01nished. The operation addProduct\nin Figure 11 must be in state CollectingProducts or Empty\nwhen invoked. This is also visible in the behavioral view,\nFigure 11: addProduct() Operation Speci\ufb01cation.\nsince there are only two transitions with the operation ad-\ndProduct. Both leads to the state CollectingProducts which\nis also a postcondition of the operation. The second post-\ncondition is that the cost attribute of the component must\nbe increased by the price of the added product. The pre- and\npostcondition can be expressed using the OCL. The proper-\nties of the component, states and operation parameters can\nbe used to formalise the constraints like as in this example.\nFigure 12 shows the publicly visible behaviour of the Shop-\npingCart component with states and transitions. The condi-\ntional transitions map to operations of the component. Like\nevery view, this view is also synchronized with the SUM so\nthat it is guaranteed that its operations, states and proper-\nties are consistent with those in the structural view.\nFigure 12: Speci\ufb01cation Behavioral Model.\nAlthough the operational view seems to be similar to the\nbehavioral view because of the overlapping information within\nthem, there are signi\ufb01cant di\ufb00erences. The focus of the op-\nerational view is on a precise formal de\ufb01nition of an opera-\ntion of a component. The operations can be enriched by pre-\nand postconditions which can be de\ufb01ned using complex OCL\nstatements, that formalize the complete behavior of an op-\neration. The additional information in the OCL statements\ncan be used for code generation and documentation.\n7.\nCONCLUSION\nAt the beginning of the paper we identi\ufb01ed three funda-\nmental hypothesis upon which the notion of OSM is based\n\u2014 (a) that it is feasible to integrate the many di\ufb00erent kinds\nof artifacts used in contemporary software engineering meth-\nods within a single coherent methodology in which they are\ntreated as views, (b) that it is feasible to create an e\ufb03-\ncient and scalable way of supporting these views by gener-\nating them dynamically, on-the-\ufb02y, from a Single Underly-\ning Model (SUM) using model-based transformations and\n(c) that it is feasible to provide an intuitive metaphor for\nnavigating around these many views by adapting the ortho-\ngraphic projection technique underpinning the CAD tools\nused in other engineering disciplines.\nThe prototype tool, nAOMi, described in this paper rep-\nresents the \ufb01rst step towards demonstrating the validity of\nthese hypotheses and showing that OSM is a viable approach\nto software engineering. Of the three hypotheses, (a) and (c)\nare most convincingly demonstrated by the prototype, since\nit shows that it is indeed possible to support all the views\nof the KobrA method within a single navigation metaphor.\nThe prototype tool does not demonstrate the validity of hy-\npothesis (b) to the same extent as the others due to its\nsmall size. Although it demonstrates the feasibility of gen-\nerating views from the SUM and vice-versa, the question of\nwhether such an approach scales up to large environments\nis still open.\nAlthough nOAMi is the only tool developed with the spe-\nci\ufb01c aim of supporting KobrA-based OSM, several other\ntools and methods have similar properties or aims.\nFor\nexample, Glinz et al.\n[10] describe a tool with a \ufb01sheye\nzooming algorithm which lets the user view a model with\nvarying amounts of detail depending on the context. It has\nto be investigated whether it is possible to combine the \ufb01sh-\neye zooming concept with the dimension-based navigation\nparadigm. While the KobrA 2.0 implementation of nAOMi\nheavily uses UML diagrams for developers, Glinz et al. use\ncustom diagram types, e.g.\nfor structural and behavioral\nviews.\nAn approach which also emphasizes the description of for-\nmal consistency rules (correspondences) between views is\nRM-ODP [5][6].\nHowever, this approach does not explic-\nitly mention the notion of a SUM and thus implies that\nconsistency rules should be de\ufb01ned in a pairwise fashion be-\ntween individual pairs of views. ArchiMate [7], which com-\nplements TOGAF [12], is an enterprise architecture mod-\neling language which o\ufb00ers two orthogonal \u201ddimensions\u201d for\nmodeling, (business, architecture, and technology) layers and\n(informational, behavioral and structural) aspects and also\nsuggests two more dimensions, purpose and abstraction level.\nHowever, as many of these views span multiple choices of a\nsingle\u201cdimension\u201d, the intuitive dimension-based navigation\nmetaphor of OSM can not be easily applied. There are also\nmore general approaches for view-based modeling but they\nare less speci\ufb01c in terms of consistency rules between views\nand provide little guidance on how to manage and navigate\nviews, for example the Zachman Framework [14].\nRegarding the practical use of OSM environments in the\nfuture, the biggest challenge is developing appropriate SUM\nmetamodels which can accommodate all the types of views\nand services that software engineers are accustomed to to-\nday. For this \ufb01rst prototypical SUM-based environment sup-\nporting the OSM approach we had a method at our disposal\n(KobrA) that already de\ufb01ned a full set of orthogonal UML-\nbased views. This allowed us to model the required SUM\nand view metamodels by simply adapting the UML meta-\nmodels, removing and adding model elements as needed.\nIn doing so we were able to manually ensure that the meta-\nmodels ful\ufb01lled the two core requirements of SUM-based en-\nvironments \u2014 (1) being minimalistic and (2) redundancy\nfree. If SUM-based software engineering environments are\nto take o\ufb00, and to be introduced into existing, heteroge-\nneous environments, more sophisticated ways of integrating\nexisting metamodels into a single uni\ufb01ed metamodel will be\nrequired.\n8.\nREFERENCES\n[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,\nO. Laitenberger, R. Laqua, D. Muthig, B. Paech,\nJ. W\u00a8ust, and J. Zettel. Component-Based Product Line\nEngineering with UML. Addison Wesley, Reading,\nMassachusetts, USA, 1st edition, November 2001.\n[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic\nSoftware Modeling: A Practical Approach to\nView-Based Development. In Evaluation of Novel\nApproaches to Software Engineering, volume 69 of\nCommunications in Computer and Information\nScience, pages 206\u2013219. Springer Berlin Heidelberg,\n2010.\n[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic\nService Modeling. In Proceedings of 15th IEEE EDOC\nConference Workshops (EDOCW), Helsinki, Finland,\n2011.\n[4] Eclipse Foundation. UML2Tools.\nhttp://wiki.eclipse.org/MDT-UML2Tools, 2013.\n[5] ISO/IEC and ITU-T. The Reference Model of Open\nDistributed Processing. RM-ODP, ITU-T Rec.\nX.901-X.904 / ISO/IEC 10746.\nhttp://standards.iso.org/\nittf/PubliclyAvailableStandards/index.html,\n1998.\n[6] J. I. J. Jose Raul Romero and A. Vallecillo. Realizing\nCorrespondences in MultiViewpoint Speci\ufb01cations. In\nProceedings of the Thirteenth IEEE International\nEDOC Conference, 1 - 4 September 2009, Auckland,\nNew Zealand, September 2009.\n[7] M. Lankhorst. Enterprise Architecture at Work.\nSpringer Berlin Heidelberg, 2009.\n[8] Object Management Group (OMG). OMG Uni\ufb01ed\nModeling Language (OMG UML), Superstructure,\nV2.1.2.\nhttp://www.omg.org/cgi-bin/doc?formal/07-11-02,\nNovember 2007.\n[9] Object Management Group (OMG). Meta Object\nFacility (MOF) 2.0 Query/View/Transformation, v1.0.\nhttp://www.omg.org/spec/QVT/1.0/PDF/, April 2008.\n[10] C. Seybold, M. Glinz, S. Meier, and N. Merlo-Schett.\nAn e\ufb00ective layout adaptation technique for a\ngraphical modeling tool. In Proceedings of the 2003\nInternational Conference on Software Engineering,\nPortland, 2003.\n[11] The Atlas Transformation Language (ATL). O\ufb03cial\nWebsite. http://www.eclipse.org/atl/, 2013.\n[12] The Open Group. TOGAF Version 9 - The Open\nGroup Architecture Framework.\nhttp://www.opengroup.org/architecture/\ntogaf9-doc/arch/index.html, Feb 2009.\n[13] University of Mannheim - Software Engineering\nGroup. nAOMi - opeN, Adaptable, Orthographic\nModeling EnvIronment.\nhttp://eclipselabs.org/p/naomi.\n[14] J. A. Zachman. The Zachman Framework: A Primer\nfor Enterprise Engineering and Manufacturing.\nhttp://www.zachmaninternational.com, 2009.\n",
    "pdf_url": "",
    "references": [
      "[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,",
      "O. Laitenberger, R. Laqua, D. Muthig, B. Paech,",
      "J. W\u00a8ust, and J. Zettel. Component-Based Product Line",
      "Engineering with UML. Addison Wesley, Reading,",
      "Massachusetts, USA, 1st edition, November 2001.",
      "[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic",
      "Software Modeling: A Practical Approach to",
      "View-Based Development. In Evaluation of Novel",
      "Approaches to Software Engineering, volume 69 of",
      "Communications in Computer and Information",
      "Science, pages 206\u2013219. Springer Berlin Heidelberg,",
      "2010.",
      "[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "uage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).Addison-Wesley Professional.",
      "University of Kent"
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "University of Kent",
      "uage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).Addison-Wesley Professional."
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "A Prototype Implementation of an Orthographic Software Modeling Environment",
    "resume": "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
    "auteurs": [
      "Colin Atkinson",
      "Dietmar Stoll",
      "Jacques Robin",
      "Recife",
      "Brasil",
      "D.2.2"
    ],
    "institutions": [
      "Dietmar Stoll University of Mannheim, TunjicUniversity of Mannheim,",
      "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
      "Colin Atkinson University of Mannheim,"
    ],
    "mots_cles": [
      " Orthographic Software Modeling",
      " View-based Modeling "
    ],
    "texte_integral": "A Prototype Implementation of an Orthographic Software\nModeling Environment\nColin Atkinson\nUniversity of Mannheim,\nGermany\natkinson@informatik.uni-\nmannheim.de\nDietmar Stoll\nUniversity of Mannheim,\nGermany\nstoll@informatik.uni-\nmannheim.de\nChristian Tunjic\nUniversity of Mannheim,\nGermany\ntunjic@informatik.uni-\nmannheim.de\nJacques Robin\nUniversidade Federal de\nPernambuco, Recife, Brasil\njr@cin.ufpe.br\nABSTRACT\nOrthographic Software Modeling (OSM) is a view-centric\nsoftware engineering approach that aims to leverage the or-\nthographic projection metaphor used in the visualization of\nphysical objects to visualize software systems. Although the\ngeneral concept of OSM does not prescribe speci\ufb01c sets of\nviews, a concrete OSM environment has to be speci\ufb01c about\nthe particular views to be used in a particular project. At\nthe University of Mannheim we are developing a prototype\nOSM environment, nAOMi, that supports the views de\ufb01ned\nby the KobrA 2.0 method, a version of KobrA adapted for\nOSM. In this paper we provide an overview of the KobrA 2.0\nmetamodel underpinning nAOMi and give a small example\nof its use to model a software system.\nCategories and Subject Descriptors\nD.1.7 [Programming Techniques]: Visual Programming;\nD.2.2 [Design Tools and Techniques]: Computer-aided\nsoftware engineering (CASE); D.2.6 [Software Engineer-\ning]: Programming Environments\u2014Graphical environments\nKeywords\nOrthographic Software Modeling, View-based Modeling\n1.\nINTRODUCTION\nOrthographic Software Modeling (OSM) is based on three\nfundamental hypotheses \u2014 (a) that it is feasible to inte-\ngrate the many di\ufb00erent kinds of artifacts used in contempo-\nrary software engineering methods within a single coherent\nmethodology in which they are treated as views, (b) that it\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for pro\ufb01t or commercial advantage and that copies\nbear this notice and the full citation on the \ufb01rst page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior speci\ufb01c\npermission and/or a fee.\nVAO \u201913, July 2, 2013, Montpellier, France\nCopyright 2013 ACM 978-1-4503-2041-2 ...$15.00.\nis feasible to create an e\ufb03cient and scalable way of support-\ning these views by generating them dynamically, on-the-\ufb02y,\nfrom a Single Underlying Model (SUM) using model-based\ntransformations and (c) that it is feasible to provide an in-\ntuitive metaphor for navigating around these many views\nby adapting the orthographic projection technique under-\npinning the CAD tools used in other engineering disciplines.\nFigure 1: Orthographic Projection.\nAs shown in Figure 1, the main advantages of using the\nidea of orthographic projection to de\ufb01ne the views used\nto visualize and described a system are that they (a) can\nbe organized according to a simple and easy-to-understand\nmetaphor and (b) collectively represent all the properties of\na system with minimal overlap and redundancy. In practice\nthis translates into a set of \u201cdimensions\u201d, each containing\nwell de\ufb01ned choices (or so called \u201cdimension elements\u201d) that\ncan be used to select individuals views.\nAs shown in Figure 2, the main advantage of making the\nartifacts used to describe a software system views of a SUM\nis that the number of pairwise coherence relationships that\nhave to be maintained is reduced and new views can be in-\ntroduced by simply de\ufb01ning their relationship to the SUM.\nMoreover, the importance of this advantage grows quickly\nas the size of the system and the complexity of the deployed\ndevelopment methodology increase. Another important ad-\nvantage is that the dominance of one particular kind of view\nover the development process (e.g. code) at the expense of\nother kinds of views (e.g. graphical models) is reduced so\nthat any appropriate type of views can be used to enrich\nthe underlying description of the system, depending on the\nneeds and skills of the stakeholder involved. This makes it\npossible to subsume all view types under the same, overarch-\nSUM\nSUM / View Centric Environment\nArtifact / Tools Centric Environment\nFigure 2: Consistency Dependencies in Artifact-oriented versus View-oriented Environments.\ning development process and methodology (e.g. agile-driven,\nfocusing on small development cycles, or model-driven de-\nvelopment, based on transformations between abstraction\nlevels). Although the details of how the views are created\nfrom the SUM and how the SUM is updated from the views\nare not central to the approach, a natural implementation\nis to use the visualization and transformation technologies\no\ufb00ered by model driven software engineering (MDSE).\nTo explore the validity of these hypotheses at the Uni-\nversity of Mannheim we have been developing a prototype\nOSM modeling environment based on an enhanced version\nof the KobrA method for model-driven, component-oriented\ndevelopment, KobrA 2.0 [1]. This was chosen as a basis for\nthe prototype, known as the Open, Adaptable, Orthographic\nModeling Environment (nAOMi) [13] because its views were\ndesigned with the precise goals of being (a) genuine pro-\njections of a subject containing carefully selected subsets\nof information about that subject, (b) minimalistic in the\nsense that they should overlap to the smallest extent possible\nand contain the minimum necessary models elements, and\n(c) selectable via a set of independent \u201cdimensions\u201d which\nre\ufb02ect di\ufb00erent fundamental concerns of development (i.e.\nabstraction levels, composition or variants). In other words,\nKobrA already provided one of the \u201cmost orthogonal\u201d sets\nof views for visualizing software systems of any contempo-\nrary method. More details about the actual views and di-\nmensions de\ufb01ned in KobrA are presented in the following\nsections. More information on OSM can be found in [2] and\n[3].\nnAOMi is implemented as an Eclipse plugin using the\nEclipse Modeling Framework (EMF) as the underlying mod-\neling platform and UML 2.0 tools [4] to generate and edit\nviews.\nThe KobrA 2.0 metamodel on which the current\nversion of nAOMi is based is a specialization of the UML\nmetamodel composed of three separate packages \u2014 one for\nthe SUM, one for the views and one for the transformations\n(Figure 3). The UML was chosen as the base language be-\ncause of its maturity and widespread acceptance, making the\nenvironment usable to the largest possible body of develop-\ners. UML elements not needed in KobrA 2.0 are excluded\nusing OCL constraints while new elements or properties are\nKobrA2\nTransformation\nSUM\nViews\nFigure 3: KobrA 2.0 Top Level Packages.\nintroduced by specializing existing elements.\nThe unique contribution of this paper is to elaborate on\nthe structure of the KobrA 2.0 metamodel and how it is used\nto drive nAOMi. The three following sections each focus on\none of the three main components of the metamodel \u2014 the\nSUM, the views and the transformations . This is followed\nby a brief overview of the OSM navigation paradigm in Sec-\ntion 5 before a small example of the approach is presented in\nSection 6. Section 7 then concludes the paper with related\nand future work.\n2.\nSUM PACKAGE\nFigure 4 depicts the internal structure of the SUM pack-\nage which is based on the UML metamodel. There are three\nmain subpackages, two containing the structural and behav-\nioral constructs respectively, and one containing the con-\nstraints that ensure that the metaclasses are used according\nto the KobrA conventions and rules.\nThe Classes subpackage of the Structure package contains\nsome of the most fundamental elements of the KobrA meta-\nmodel, such as Class and ComponentClass.\nThe internal\nstructure of this package is illustrated in Figure 5. Com-\nponentClass represents objects with complex and reusable\nbehaviors, while Class captures simple \u201cdata type\u201d objects\nthat have only very simple or non-reusable behaviors. The\nmodeler has to decide whether it is necessary to model a\nspeci\ufb01c part of the system as a ComponentClass and include\nstate charts and activity diagrams, or whether it is su\ufb03cient\nto use a Class (which is limited to using OCL constraints).\nComponentClass inherits (indirectly via Class) from Com-\nmunications so it also has the isActive attribute. This makes\nKobrA2::SUM::Constraint::Behavioral\nKobrA2::SUM::Constraint::Structural\nKobrA2::SUM::Constraint\nKobrA2::SUM::Constraint::Common\nKobrA2::SUM::Behavior::ProtocolStateMachines\nKobrA2::SUM::Behavior::Common\nKobrA2::SUM::Behavior::Activities\nKobrA2::SUM::Behavior::Actions\nKobrA2::SUM::Behavior\nKobrA2::SUM::Structure::Classes\nKobrA2::SUM::Structure::Types\nKobrA2::SUM::Structure::Instances\nKobrA2::SUM::Structure::Elements\nKobrA2::SUM::Structure\nKobrA2::SUM::Constraint::OclExpressions\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\nFigure 4: KobrA 2.0 SUM Package.\nit possible to model whether its instances are active or pas-\nsive. Active objects, which can be used to model threads and\nprocesses ([8] p. 438), start to execute their behavior as soon\nas they are created and perform operations spontaneously.\nA ComponentClass may exhibit complex behavior. In Ko-\nbrA, this behavior may be speci\ufb01ed in the form of\nUML\nState Diagrams (de\ufb01ning acceptable operation invocation\nsequences), and in the form of Activities (de\ufb01ning algorithms\nof operations). UML Interaction elements (in sequence dia-\ngrams) can be derived from the activity elements and thus\nare not included in the SUM. As KobrA aims to facilitate\nautomatic checking of allowed sequences of operation calls,\nProtocol State Machines are supported instead of general\nstate machines. Since the latter include a large variety of\nelements not needed for specifying acceptable operation se-\nquences or automatic checking, OCL constraints are used to\nprohibit the use of unwanted features.\ncontext\nComponentClass\n-- only\nallow\nActivity\nelements\nor\nProtocolStateMachines\ninv: ownedBehavior ->forAll( oclIsKindOf( Actitivity) or\noclIsKindOf ( ProtocolStateMachine ))\nFor example, since KobrA has no concept of roles for com-\nponents, the use of role also needs to be prohibited. The part\nassociation refers to owned properties of components whose\nattribute isComposite is true. As KobrA uses associations\nlike nests and creates for components, part, required and\nprovided are not needed. Connectors (i.e. delegation and\nassembly) are not used in KobrA either so ownedConnector\nis excluded.\nClass\nKobrA2::SUM::Structure::Classes\nGeneralizationSet\nAssociationClass\nComponentClass\nProperty\nUsage\nAssociation\nOperation\nPackageable\nElement\nParameter\nAcquires\nCreates\nNests\nUML::Component::PackagingComponents::Component\nUML::CommonBehaviors::Communications::Class\n+ownedOperation\n*\n+class\n0..1\n+supplier\n1..*\n{subsets supplierDependency}\n+supplierUsage\n*\n+client\n1..*\n{subsets clientDependency}\n+clientUsage\n*\n+ownedAttribute\n*\n+class\n0..1\n+powertype\n0..1\n+powertypeExtent\n*\n+packagedElement\n*\n{subsets component}\n+componentClass\n0..1\n+/superClass\nFigure 5: KobrA 2.0 Classes Package.\ncontext\nComponentClass\ninv: role ->union(part)->union( ownedConnector )\n->union( collaborationUse )-> union( representation )\n->union( realization)->union(required)\n->union(provided)->isEmpty ()\n3.\nVIEWS PACKAGE\nThe structure of the Views package is illustrated in Figure\n6. Again, since most of the views de\ufb01ned in KobrA 2.0 are\nbased on UML diagrams, the view metamodels have similar\nelements to the SUM metamodel. The big di\ufb00erence to the\nSUM is that there are no restrictions on the use of the view\nmetamodel elements.\nFor instance, views for a particular\npurpose such as supporting model checkers can be supported\nby adding elements unrelated to the UML.\nThe substructure of the Views package re\ufb02ects the types\nand organization of the KobrA views according to the view\n\u201cdimensions\u201d supported in nAOMi (cf. example in Section\n6). At the top level, the Views package is thus decomposed\ninto the Speci\ufb01cation and Realization options of the encap-\nsulation dimension.\nThese, in turn are both decomposed\ninto the Structural, Behavioral and Operational options of\nthe Projection dimension.\nFinally, with the exception of\nthe behavioral option, these are also all subdivided into the\nService and Type options of the granularity dimension. This\ndimension, with its two options, is an addition to the original\nversion of KobrA.\nThe Service view shows the direct, publicly visible rela-\ntionships of the subject ComponentClass to other Compo-\nnentClasses, while the Type view shows the publicly visi-\nble relationships of the subject to simple Classes. As with\nthe SUM, constraints have been de\ufb01ned to control what can\ngo into each view and when they are well formed. For ev-\nery view, a constraint enumerates all allowed elements (not\nshown in this paper).\nIn the following, some of the other constraints for the\nService view are elaborated. Since this view is a black-box\nview, the internals of ComponentClasses (nestedClassi\ufb01er)\nare not shown.\ncontext\nComponentClass\n-- no nested\nclassifiers , no\nprotocol\ninv: nestedClassifier ->union(protocol)->isEmpty ()\nClasses are only allowed if they are generalizations of Com-\nponentClasses, (or any of its superclasses, since a Compo-\nnentClass may inherit from a class as shown in the con-\nstraints with context Class. The following invariants ensure\nthat only publicly visible attributes and operations are in\nthis view, for both classes and ComponentClasses (which\ninherit from Class).\nClass\nService\nType\nInstance\nService\nType\nStructural\nSpecification\nOperational\nService\nType\nProtocol\nBehavioral\nKobrA2::Views::Derived\nComponentClassDependencies\nOperationDependencies\nInstance\nService\nType\nClass\nService\nType\nStructural\nRealization\nOperational\nService\nType\nBehavioral\nAlgorithm\nViews\nConcreteSyntax\nSubject\n<<import>>\n<<merge>>\n<<merge>>\n<<import>>\n<<merge>>\n<<import>>\nFigure 6: KobrA 2.0 Views package nesting.\ncontext\nClass\n-- only\nallow\nclasses\nthat\nare\ndirect or\nindirect\ngeneralizations\nof\nComponentClasses\nin this\nview\ndef: ccGeneralization : generalization .specific ->\nexists( oclIsKindOf ( ComponentClass ))\ninv:\ngeneralization .specific ->select( oclIsTypeOf (\nClass))->exists(s|s. ccGeneralization )\nor\nccGeneralization\n-- only\npublic\nattributes\nin this\nview\ninv: ownedAttribute ->forAll(visibility =# public)\n-- only\npublic\nOperations\nare\nallowed\nin the\nspecification\ninv: ownedOperation ->forAll(visibility =# public)\nOnly operation signatures are shown in this view, so pre-,\npost- and bodyconditions, as well as activities are omitted,\nwhich is re\ufb02ected in the last constraint.\ncontext\nOperation\n-- only\nthe\nsignature\nof the\nOperation\nis shown , not\nits\nbehavior (role\nname \"method\" refers to the\nActivities\nof the\noperation), or\ndependencies\ninv: method ->union( precondition )->union(body)->union(\npostcondition )->isEmpty ()\n4.\nTRANSFORMATIONS PACKAGE\nThe package AllViews provides the foundation for speci-\nfying the transformations between the SUM and the views\nin both directions. Part of the package\u2019s contents are shown\nin Figure 7.\nThe Abstraction concept (which is in fact a\nKobrA2::Transformation::Common::AllViews\nAbstraction\nTransformationExpression\nViewElement\nSumElement\nView\nKobrA2::SUM::Structure::Elements::Element\nKobrA2::Views::ConcreteSyntax::Element\nKobrA2::SUM::Constraint::Behavioral::Exp\nressionInOcl\nKobrA2::Views::Subject::View\n{subsets mapping}\n0..1\n0..1\n{subsets clientDependency}\n+abstraction 1\n{subsets client}\n+ve 1\n1..*\n1\n{subsets supplier}\n+se 1\n{subsets supplierDependency}\n+abstraction 1..*\nFigure 7: Transformation abstractions.\ndependency reused from the UML but with additional con-\nstraints) plays the key role in relating elements from the\nSUM to elements of a view. Abstraction is actually mapped\nto ExpressionInOcl.\nWhen appearing in transformations,\nthe equals sign links elements in the SUM to the respective\nelements in the view, and vice versa. For instance, equal-\nity of the general meta-association of a Generalization in\na transformation invariant means that, when following gen-\neral, there must be an element in the SUM and in the view\nfor which similar transformation expressions are speci\ufb01ed.\nIn the case of KobrA 2.0, which has many projections that\njust select a subset of elements using one-to-one abstrac-\ntions, this allows concise declarative TransformationExpres-\nsions. Together with the view constraints, a CASE tool can\nbe implemented which uses a transformation language of the\nimplementor\u2019s choice, for instance the Atlas Transformation\nLanguage (ATL) [11] or QVT [9]. The role names se and ve\nare short for SumElement and ViewElement, respectively.\nThese roles subset the client and supplier roles from the\nUML.\nSUM elements are translated into UML elements with\nstereotypes, so that the views are easy to manage for de-\nvelopers familiar with the UML. The bidirectional mappings\nbetween stereotyped view elements and non-stereotyped SUM\nelements are expressed in the constraints of the Association-\nAbstraction, a subclass of the Abstraction from the AllViews\npackage. This is also an example of a transformation which\nis reused in other views.\ncontext\nAssociationAbstraction\ninv: ve.memberEnd = se.memberEnd\ninv: ve.ownedEnd = se.ownedEnd\nivn: ve. navigableOwnedEnd = se. navigableOwnedEnd\ninv: se. oclIsKindOf(Acquires) implies ve.\nhasStereotype (\u2019acquires \u2019)\ninv: ve. hasStereotype (\u2019acquires \u2019)\nimplies\nse.\noclIsKindOf (Aquires)\ninv: se. oclIsKindOf(Nests) implies\nve. hasStereotype (\u2019\nnests \u2019)\ninv: ve. hasStereotype (\u2019nests \u2019)\nimplies se. oclIsKindOf\n(Nests)\ninv: se. oclIsKindOf (Creates) implies\nve. hasStereotype\n(\u2019creates \u2019)\ninv: ve. hasStereotype (\u2019creates \u2019)\nimplies se.\noclIsKindOf (Creates)\nFigure 8 shows the main elements involved in the trans-\nformation of the black box structural view for Component-\nClasses. The \ufb01rst transformation constraint is on the view\nand declares the starting point for the transformation. It\nstates that the subject ComponentClass and its generaliza-\ntions (using a SUM utility function, superClosure) are in the\nview.\nThe following transformation rules illustrate how to create\nthe output (i.e. view) elements from the input (i.e. SUM) el-\nements, such as the publicly visible attributes and operations\nof the ComponentClass and the acquired ComponentClasses.\nThe \ufb01rst constraint for ComponentClassAbstraction states\nthat references to potential general classes (and Component-\nClasses) of ComponentClasses are mirrored in the view. In\naddition, ComponentClasses will be shown with the corre-\nsponding stereotypes.\nThe ComponentClass owns various\ntypes of associations, so in this view only the acquires asso-\nciations are selected (whose transformation rules are cov-\nered in the common transformation packages).For classes\nand ComponentClasses, only publicly visible attributes and\noperations appear in the view.\nClass invariants are also\ncopied. Classes that may appear in this view (e.g. as gener-\nalizations of ComponentClasses) may have a powertype (role\nname powertypeExtent) which will be displayed.\nThe last transformation statement copies the class refer-\nences of operations. As with all views, the transformation\nrules, the common transformation statements (which also\ncover operations) and the view constraints serve as a speci-\n\ufb01cation for the implementation of a view. Individual CASE\ntools can use di\ufb00erent implementation techniques as long as\nthey conform to the semantics of these rules and constraints.\nKobrA2::Transformation::Specification::Structural::Class::Service\nComponentClassAbstraction\nKobrA2::Transformation::Common::Feature::OperationAbstraction\nKobrA2::Transformation::Common::AllViews::Abstraction\nKobrA2::SUM::Structure::Classes::ComponentClass\nKobrA2::SUM::Structure::Classes::Operation\nKobrA2::SUM::Structure::Classes::Class\nOperationAbstraction\nClassAbstraction\n+se\n1\n1..*\n+se\n1\n1..*\n+se\n1\n1..*\nFigure 8: Transformation to the Speci\ufb01cation Structural Service View.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassService\ninv: ownedMember ->select( oclIsKindOf(Class)) =\nsubject.superClosure ->union(subject.acquires.\nsuperClosure )\ncontext\nComponentClassAbstraction\ninv: ve.superClass = se. superClass\ninv: ve. hasStereotype (\u2019ComponentClass \u2019)\ninv: se.isSubject\nimplies (ve. hasStereotype (\u2019subject\n\u2019) and ve.ownedMember ->select( oclIsKindOf (\nAssociation )) = se.ownedMember ->select(\noclIsKindOf (Acquires)))\ncontext\nClassAbstraction\ninv: ve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\ninv: ve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public)\ninv: ve.\u2018inv \u2019 = se.\u2018inv \u2019\n-- copy\npowertypeExtent\nthat is only\nallowed\nfor\nclass\ninv: ve. powertypeExtent = se. powertypeExtent\ncontext\nOperationAbstraction\ninv: ve.class = se.class\nFor the black box type view, only publicly visible at-\ntributes and operations of classes (as opposed to Compo-\nnentClasses) used by the subject can be seen. This is spec-\ni\ufb01ed in the \ufb01rst rule which de\ufb01nes owned members of the\nview and thus serves as the starting point of the transfor-\nmation. cbbTypes is a utility function de\ufb01ned in the SUM\nwhich computes the black box types by selecting the types\nof the subject\u2019s public attributes and parameter types of its\npublic operations.\nClass invariants and potential powertypes and connections\nto the classes in this view are shown as well. There may\nalso be Enumerations, for which the EnumerationLiterals\nare displayed.\nThe transformation rules for this view are almost the same\nas the realization transformation constraints from the pack-\nage Transformation::Realization::Structural::Class::Type. The\ndi\ufb00erences are the select(visibility=#public) statements for\noperations and attributes.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassType\ninv: ownedMember ->select( oclIsKindOf(Class) or\noclIsKindOf(\u2018Enumeration \u2019) or\noclIsKindOf (\nAssociation)) = subject ->union(subject.cbbTypes)\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nClassAbstraction\ninv: not se.oclIsKindOf ( ComponentClass ) implies (\nve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\nve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public))\ninv: ve. powertypeExtent = se. powertypeExtent\ninv: ve. superClass = se.superClass\ninv: \u2018ve.inv \u2019 = \u2018se.inv \u2019\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nEnumerationAbstraction\ninv: ve. ownedLiteral = se. ownedLiteral\ncontext\nEnumerationLiteralAbstraction\ninv: ve. specification = se. specification .\nstringInSignature\n5.\nNAVIGATION\nMost of today\u2019s tools use some combination of trees to\norganize the content of models as well as the views used to\nvisualize a software system or component. In an any envi-\nronment incorporating a number of di\ufb00erent tools there is\ninvariably a large number of di\ufb00erent trees storing a het-\nerogeneous mix of artifacts including model elements (e.g.\nclasses, instances, associations), diagrams (e.g.\nclass dia-\ngrams, state diagrams) and other artifact types (source code,\nXML \ufb01les, con\ufb01guration \ufb01les ). To work with all the views in\na traditional development environment, therefore, engineers\ntypically have to learn about the organization structures of\nall the incorporated tools.\nIn contrast to conventional paradigms for organizing and\nnavigating the many views used to visualize a system, OSM\nemploys the metaphor of a multi-dimensional cube. More\nspeci\ufb01cally, as illustrated in Figure 9, OSM regards dimen-\nsion of the underlying methodology as representing a di\ufb00er-\nent dimension of the cube, and each independently variable\naspect of that dimension is a selectable dimension element.\nSelecting a view thus simply corresponds to selecting a single\ncell within the cube. In general, three types of dimensions\nare supported: static dimensions in which the number of\nFigure 9: Dimension-based navigation.\nselectable elements (i.e. coordinates) is \ufb01xed, dynamic di-\nmensions in which the number of elements is dynamic (i.e.\nderived from the SUM), and mixed dimensions which have\nboth static and dynamic elements.\nTo support the OSM dimension based navigation metaphor\nfor KobrA, we de\ufb01ned the seven dimensions indicated on the\nleft hand side of Figure 10 which is a sceenshot of nAOMI.\nThe Abstraction dimension (not expanded here), which has\nthree static dimension elements, PIM (platform independent\nmodel), PSM (platform speci\ufb01c model) and Code, captures\nthe model-driven development concern of KobrA. The ver-\nsion dimension captures the state of the modeled system at\nspeci\ufb01c points in time. The Component dimension, which\nhas dynamic dimension elements de\ufb01ned by instances of the\nclass ComponentClass in the SUM, captures the component-\nbased development concern of KobrA.\nThe Encapsulation dimension, which has two \ufb01xed ele-\nments, supports the distinction between Speci\ufb01cation (black\nbox) and Realization (white box) views of components, while\nthe Projection dimension with the \ufb01xed elements Structural,\nOperational and Behavioral covers the di\ufb00erent information\ntypes. The Granularity dimension provides a \ufb01ner grained\ndistinction between views describing the types used by com-\nponents (Type granularity) and views describing the required\nand provided interfaces (Service granularity). The Opera-\ntion dimension allows a selection of individual operations.\nIn the ideal case, when all views are truly orthogonal, the\nchoices that can be made in each dimensions are completely\nindependent.\nHowever, this is very di\ufb03cult to achieve in\nsoftware engineering. The approach still works if the views\nare not completely orthogonal, but dependencies then occur\nbetween di\ufb00erent choices in di\ufb00erent dimensions, so that the\ndecisions made in one dimensions may a\ufb00ect choices possi-\nble in another dimension. This is best handled by giving\ndimensions a precedence ranking determined by the order\nin which they appear (the top being the highest). When an\nelement in a dimension is selected, the tool automatically\nmakes default selections for dimensions of lower precedence\n(i.e.\ndimensions lower down) and disables selections that\nwould navigate to cells (i.e. views) which are not (yet) de-\n\ufb01ned by the method at hand.\n6.\nSHOPPING CART EXAMPLE\nTo show how a software system can be speci\ufb01ed using\nnAOMi, this section presents a case study based on a shop-\nping cart system. A ShoppingCart component collects and\nFigure 10: Speci\ufb01cation Structural View.\nmanages the products selected by users and supports pay-\nment via a credit card.\nFigure 10 illustrates a structural\nview of the component.\nIn the dimension navigator on the left hand side, PIM\nwas chosen for the \u201cAbstraction Level\u201d (not expanded in the\nscreenshot). The second dimension is the state of the soft-\nware system at a certain point in time. The picture shows\nthat the latest available version was chosen. As with every\nchoice in a dimension, it may in\ufb02uence the options in lower\nranked dimensions. The component under consideration is\nthe ShoppingCart, for which a black box view is selected\nin the next dimension. After the user selects the structural\nprojection option and the service level granularity, the tool\nautomatically chooses the option for all operations in the\nlast dimension, as there is no editor registered for the other\noptions.\nThe component under development is presented with the\nstereotype subject and its relationship to other components\nand classes is shown in the view, which corresponds to a cell\nof the multi-dimensional navigation cube, and is generated\non-the-\ufb02y from the SUM when it is selected. The classes\nProduct and CreditCard can be used as data types in the\noperations of the component.\nFigure 11 illustrates the operational view in which an\noperation can be formalized using pre- and postconditions.\nThe precondition corresponds to the assumes clause in and\nthe postcondition corresponds to the result clause. As in the\nUML, the precondition of an operation must be true when\nthe operation is invoked and the postcondition must be true\nwhen the operation is \ufb01nished. The operation addProduct\nin Figure 11 must be in state CollectingProducts or Empty\nwhen invoked. This is also visible in the behavioral view,\nFigure 11: addProduct() Operation Speci\ufb01cation.\nsince there are only two transitions with the operation ad-\ndProduct. Both leads to the state CollectingProducts which\nis also a postcondition of the operation. The second post-\ncondition is that the cost attribute of the component must\nbe increased by the price of the added product. The pre- and\npostcondition can be expressed using the OCL. The proper-\nties of the component, states and operation parameters can\nbe used to formalise the constraints like as in this example.\nFigure 12 shows the publicly visible behaviour of the Shop-\npingCart component with states and transitions. The condi-\ntional transitions map to operations of the component. Like\nevery view, this view is also synchronized with the SUM so\nthat it is guaranteed that its operations, states and proper-\nties are consistent with those in the structural view.\nFigure 12: Speci\ufb01cation Behavioral Model.\nAlthough the operational view seems to be similar to the\nbehavioral view because of the overlapping information within\nthem, there are signi\ufb01cant di\ufb00erences. The focus of the op-\nerational view is on a precise formal de\ufb01nition of an opera-\ntion of a component. The operations can be enriched by pre-\nand postconditions which can be de\ufb01ned using complex OCL\nstatements, that formalize the complete behavior of an op-\neration. The additional information in the OCL statements\ncan be used for code generation and documentation.\n7.\nCONCLUSION\nAt the beginning of the paper we identi\ufb01ed three funda-\nmental hypothesis upon which the notion of OSM is based\n\u2014 (a) that it is feasible to integrate the many di\ufb00erent kinds\nof artifacts used in contemporary software engineering meth-\nods within a single coherent methodology in which they are\ntreated as views, (b) that it is feasible to create an e\ufb03-\ncient and scalable way of supporting these views by gener-\nating them dynamically, on-the-\ufb02y, from a Single Underly-\ning Model (SUM) using model-based transformations and\n(c) that it is feasible to provide an intuitive metaphor for\nnavigating around these many views by adapting the ortho-\ngraphic projection technique underpinning the CAD tools\nused in other engineering disciplines.\nThe prototype tool, nAOMi, described in this paper rep-\nresents the \ufb01rst step towards demonstrating the validity of\nthese hypotheses and showing that OSM is a viable approach\nto software engineering. Of the three hypotheses, (a) and (c)\nare most convincingly demonstrated by the prototype, since\nit shows that it is indeed possible to support all the views\nof the KobrA method within a single navigation metaphor.\nThe prototype tool does not demonstrate the validity of hy-\npothesis (b) to the same extent as the others due to its\nsmall size. Although it demonstrates the feasibility of gen-\nerating views from the SUM and vice-versa, the question of\nwhether such an approach scales up to large environments\nis still open.\nAlthough nOAMi is the only tool developed with the spe-\nci\ufb01c aim of supporting KobrA-based OSM, several other\ntools and methods have similar properties or aims.\nFor\nexample, Glinz et al.\n[10] describe a tool with a \ufb01sheye\nzooming algorithm which lets the user view a model with\nvarying amounts of detail depending on the context. It has\nto be investigated whether it is possible to combine the \ufb01sh-\neye zooming concept with the dimension-based navigation\nparadigm. While the KobrA 2.0 implementation of nAOMi\nheavily uses UML diagrams for developers, Glinz et al. use\ncustom diagram types, e.g.\nfor structural and behavioral\nviews.\nAn approach which also emphasizes the description of for-\nmal consistency rules (correspondences) between views is\nRM-ODP [5][6].\nHowever, this approach does not explic-\nitly mention the notion of a SUM and thus implies that\nconsistency rules should be de\ufb01ned in a pairwise fashion be-\ntween individual pairs of views. ArchiMate [7], which com-\nplements TOGAF [12], is an enterprise architecture mod-\neling language which o\ufb00ers two orthogonal \u201ddimensions\u201d for\nmodeling, (business, architecture, and technology) layers and\n(informational, behavioral and structural) aspects and also\nsuggests two more dimensions, purpose and abstraction level.\nHowever, as many of these views span multiple choices of a\nsingle\u201cdimension\u201d, the intuitive dimension-based navigation\nmetaphor of OSM can not be easily applied. There are also\nmore general approaches for view-based modeling but they\nare less speci\ufb01c in terms of consistency rules between views\nand provide little guidance on how to manage and navigate\nviews, for example the Zachman Framework [14].\nRegarding the practical use of OSM environments in the\nfuture, the biggest challenge is developing appropriate SUM\nmetamodels which can accommodate all the types of views\nand services that software engineers are accustomed to to-\nday. For this \ufb01rst prototypical SUM-based environment sup-\nporting the OSM approach we had a method at our disposal\n(KobrA) that already de\ufb01ned a full set of orthogonal UML-\nbased views. This allowed us to model the required SUM\nand view metamodels by simply adapting the UML meta-\nmodels, removing and adding model elements as needed.\nIn doing so we were able to manually ensure that the meta-\nmodels ful\ufb01lled the two core requirements of SUM-based en-\nvironments \u2014 (1) being minimalistic and (2) redundancy\nfree. If SUM-based software engineering environments are\nto take o\ufb00, and to be introduced into existing, heteroge-\nneous environments, more sophisticated ways of integrating\nexisting metamodels into a single uni\ufb01ed metamodel will be\nrequired.\n8.\nREFERENCES\n[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,\nO. Laitenberger, R. Laqua, D. Muthig, B. Paech,\nJ. W\u00a8ust, and J. Zettel. Component-Based Product Line\nEngineering with UML. Addison Wesley, Reading,\nMassachusetts, USA, 1st edition, November 2001.\n[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic\nSoftware Modeling: A Practical Approach to\nView-Based Development. In Evaluation of Novel\nApproaches to Software Engineering, volume 69 of\nCommunications in Computer and Information\nScience, pages 206\u2013219. Springer Berlin Heidelberg,\n2010.\n[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic\nService Modeling. In Proceedings of 15th IEEE EDOC\nConference Workshops (EDOCW), Helsinki, Finland,\n2011.\n[4] Eclipse Foundation. UML2Tools.\nhttp://wiki.eclipse.org/MDT-UML2Tools, 2013.\n[5] ISO/IEC and ITU-T. The Reference Model of Open\nDistributed Processing. RM-ODP, ITU-T Rec.\nX.901-X.904 / ISO/IEC 10746.\nhttp://standards.iso.org/\nittf/PubliclyAvailableStandards/index.html,\n1998.\n[6] J. I. J. Jose Raul Romero and A. Vallecillo. Realizing\nCorrespondences in MultiViewpoint Speci\ufb01cations. In\nProceedings of the Thirteenth IEEE International\nEDOC Conference, 1 - 4 September 2009, Auckland,\nNew Zealand, September 2009.\n[7] M. Lankhorst. Enterprise Architecture at Work.\nSpringer Berlin Heidelberg, 2009.\n[8] Object Management Group (OMG). OMG Uni\ufb01ed\nModeling Language (OMG UML), Superstructure,\nV2.1.2.\nhttp://www.omg.org/cgi-bin/doc?formal/07-11-02,\nNovember 2007.\n[9] Object Management Group (OMG). Meta Object\nFacility (MOF) 2.0 Query/View/Transformation, v1.0.\nhttp://www.omg.org/spec/QVT/1.0/PDF/, April 2008.\n[10] C. Seybold, M. Glinz, S. Meier, and N. Merlo-Schett.\nAn e\ufb00ective layout adaptation technique for a\ngraphical modeling tool. In Proceedings of the 2003\nInternational Conference on Software Engineering,\nPortland, 2003.\n[11] The Atlas Transformation Language (ATL). O\ufb03cial\nWebsite. http://www.eclipse.org/atl/, 2013.\n[12] The Open Group. TOGAF Version 9 - The Open\nGroup Architecture Framework.\nhttp://www.opengroup.org/architecture/\ntogaf9-doc/arch/index.html, Feb 2009.\n[13] University of Mannheim - Software Engineering\nGroup. nAOMi - opeN, Adaptable, Orthographic\nModeling EnvIronment.\nhttp://eclipselabs.org/p/naomi.\n[14] J. A. Zachman. The Zachman Framework: A Primer\nfor Enterprise Engineering and Manufacturing.\nhttp://www.zachmaninternational.com, 2009.\n",
    "pdf_url": "",
    "references": [
      "[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,",
      "O. Laitenberger, R. Laqua, D. Muthig, B. Paech,",
      "J. W\u00a8ust, and J. Zettel. Component-Based Product Line",
      "Engineering with UML. Addison Wesley, Reading,",
      "Massachusetts, USA, 1st edition, November 2001.",
      "[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic",
      "Software Modeling: A Practical Approach to",
      "View-Based Development. In Evaluation of Novel",
      "Approaches to Software Engineering, volume 69 of",
      "Communications in Computer and Information",
      "Science, pages 206\u2013219. Springer Berlin Heidelberg,",
      "2010.",
      "[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "University of Kent",
      "uage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).Addison-Wesley Professional."
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "A Prototype Implementation of an Orthographic Software Modeling Environment",
    "resume": "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
    "auteurs": [
      "Colin Atkinson",
      "Dietmar Stoll",
      "Jacques Robin",
      "Recife",
      "Brasil",
      "D.2.2"
    ],
    "institutions": [
      "Dietmar Stoll University of Mannheim, TunjicUniversity of Mannheim,",
      "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
      "Colin Atkinson University of Mannheim,"
    ],
    "mots_cles": [
      " Orthographic Software Modeling",
      " View-based Modeling "
    ],
    "texte_integral": "A Prototype Implementation of an Orthographic Software\nModeling Environment\nColin Atkinson\nUniversity of Mannheim,\nGermany\natkinson@informatik.uni-\nmannheim.de\nDietmar Stoll\nUniversity of Mannheim,\nGermany\nstoll@informatik.uni-\nmannheim.de\nChristian Tunjic\nUniversity of Mannheim,\nGermany\ntunjic@informatik.uni-\nmannheim.de\nJacques Robin\nUniversidade Federal de\nPernambuco, Recife, Brasil\njr@cin.ufpe.br\nABSTRACT\nOrthographic Software Modeling (OSM) is a view-centric\nsoftware engineering approach that aims to leverage the or-\nthographic projection metaphor used in the visualization of\nphysical objects to visualize software systems. Although the\ngeneral concept of OSM does not prescribe speci\ufb01c sets of\nviews, a concrete OSM environment has to be speci\ufb01c about\nthe particular views to be used in a particular project. At\nthe University of Mannheim we are developing a prototype\nOSM environment, nAOMi, that supports the views de\ufb01ned\nby the KobrA 2.0 method, a version of KobrA adapted for\nOSM. In this paper we provide an overview of the KobrA 2.0\nmetamodel underpinning nAOMi and give a small example\nof its use to model a software system.\nCategories and Subject Descriptors\nD.1.7 [Programming Techniques]: Visual Programming;\nD.2.2 [Design Tools and Techniques]: Computer-aided\nsoftware engineering (CASE); D.2.6 [Software Engineer-\ning]: Programming Environments\u2014Graphical environments\nKeywords\nOrthographic Software Modeling, View-based Modeling\n1.\nINTRODUCTION\nOrthographic Software Modeling (OSM) is based on three\nfundamental hypotheses \u2014 (a) that it is feasible to inte-\ngrate the many di\ufb00erent kinds of artifacts used in contempo-\nrary software engineering methods within a single coherent\nmethodology in which they are treated as views, (b) that it\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for pro\ufb01t or commercial advantage and that copies\nbear this notice and the full citation on the \ufb01rst page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior speci\ufb01c\npermission and/or a fee.\nVAO \u201913, July 2, 2013, Montpellier, France\nCopyright 2013 ACM 978-1-4503-2041-2 ...$15.00.\nis feasible to create an e\ufb03cient and scalable way of support-\ning these views by generating them dynamically, on-the-\ufb02y,\nfrom a Single Underlying Model (SUM) using model-based\ntransformations and (c) that it is feasible to provide an in-\ntuitive metaphor for navigating around these many views\nby adapting the orthographic projection technique under-\npinning the CAD tools used in other engineering disciplines.\nFigure 1: Orthographic Projection.\nAs shown in Figure 1, the main advantages of using the\nidea of orthographic projection to de\ufb01ne the views used\nto visualize and described a system are that they (a) can\nbe organized according to a simple and easy-to-understand\nmetaphor and (b) collectively represent all the properties of\na system with minimal overlap and redundancy. In practice\nthis translates into a set of \u201cdimensions\u201d, each containing\nwell de\ufb01ned choices (or so called \u201cdimension elements\u201d) that\ncan be used to select individuals views.\nAs shown in Figure 2, the main advantage of making the\nartifacts used to describe a software system views of a SUM\nis that the number of pairwise coherence relationships that\nhave to be maintained is reduced and new views can be in-\ntroduced by simply de\ufb01ning their relationship to the SUM.\nMoreover, the importance of this advantage grows quickly\nas the size of the system and the complexity of the deployed\ndevelopment methodology increase. Another important ad-\nvantage is that the dominance of one particular kind of view\nover the development process (e.g. code) at the expense of\nother kinds of views (e.g. graphical models) is reduced so\nthat any appropriate type of views can be used to enrich\nthe underlying description of the system, depending on the\nneeds and skills of the stakeholder involved. This makes it\npossible to subsume all view types under the same, overarch-\nSUM\nSUM / View Centric Environment\nArtifact / Tools Centric Environment\nFigure 2: Consistency Dependencies in Artifact-oriented versus View-oriented Environments.\ning development process and methodology (e.g. agile-driven,\nfocusing on small development cycles, or model-driven de-\nvelopment, based on transformations between abstraction\nlevels). Although the details of how the views are created\nfrom the SUM and how the SUM is updated from the views\nare not central to the approach, a natural implementation\nis to use the visualization and transformation technologies\no\ufb00ered by model driven software engineering (MDSE).\nTo explore the validity of these hypotheses at the Uni-\nversity of Mannheim we have been developing a prototype\nOSM modeling environment based on an enhanced version\nof the KobrA method for model-driven, component-oriented\ndevelopment, KobrA 2.0 [1]. This was chosen as a basis for\nthe prototype, known as the Open, Adaptable, Orthographic\nModeling Environment (nAOMi) [13] because its views were\ndesigned with the precise goals of being (a) genuine pro-\njections of a subject containing carefully selected subsets\nof information about that subject, (b) minimalistic in the\nsense that they should overlap to the smallest extent possible\nand contain the minimum necessary models elements, and\n(c) selectable via a set of independent \u201cdimensions\u201d which\nre\ufb02ect di\ufb00erent fundamental concerns of development (i.e.\nabstraction levels, composition or variants). In other words,\nKobrA already provided one of the \u201cmost orthogonal\u201d sets\nof views for visualizing software systems of any contempo-\nrary method. More details about the actual views and di-\nmensions de\ufb01ned in KobrA are presented in the following\nsections. More information on OSM can be found in [2] and\n[3].\nnAOMi is implemented as an Eclipse plugin using the\nEclipse Modeling Framework (EMF) as the underlying mod-\neling platform and UML 2.0 tools [4] to generate and edit\nviews.\nThe KobrA 2.0 metamodel on which the current\nversion of nAOMi is based is a specialization of the UML\nmetamodel composed of three separate packages \u2014 one for\nthe SUM, one for the views and one for the transformations\n(Figure 3). The UML was chosen as the base language be-\ncause of its maturity and widespread acceptance, making the\nenvironment usable to the largest possible body of develop-\ners. UML elements not needed in KobrA 2.0 are excluded\nusing OCL constraints while new elements or properties are\nKobrA2\nTransformation\nSUM\nViews\nFigure 3: KobrA 2.0 Top Level Packages.\nintroduced by specializing existing elements.\nThe unique contribution of this paper is to elaborate on\nthe structure of the KobrA 2.0 metamodel and how it is used\nto drive nAOMi. The three following sections each focus on\none of the three main components of the metamodel \u2014 the\nSUM, the views and the transformations . This is followed\nby a brief overview of the OSM navigation paradigm in Sec-\ntion 5 before a small example of the approach is presented in\nSection 6. Section 7 then concludes the paper with related\nand future work.\n2.\nSUM PACKAGE\nFigure 4 depicts the internal structure of the SUM pack-\nage which is based on the UML metamodel. There are three\nmain subpackages, two containing the structural and behav-\nioral constructs respectively, and one containing the con-\nstraints that ensure that the metaclasses are used according\nto the KobrA conventions and rules.\nThe Classes subpackage of the Structure package contains\nsome of the most fundamental elements of the KobrA meta-\nmodel, such as Class and ComponentClass.\nThe internal\nstructure of this package is illustrated in Figure 5. Com-\nponentClass represents objects with complex and reusable\nbehaviors, while Class captures simple \u201cdata type\u201d objects\nthat have only very simple or non-reusable behaviors. The\nmodeler has to decide whether it is necessary to model a\nspeci\ufb01c part of the system as a ComponentClass and include\nstate charts and activity diagrams, or whether it is su\ufb03cient\nto use a Class (which is limited to using OCL constraints).\nComponentClass inherits (indirectly via Class) from Com-\nmunications so it also has the isActive attribute. This makes\nKobrA2::SUM::Constraint::Behavioral\nKobrA2::SUM::Constraint::Structural\nKobrA2::SUM::Constraint\nKobrA2::SUM::Constraint::Common\nKobrA2::SUM::Behavior::ProtocolStateMachines\nKobrA2::SUM::Behavior::Common\nKobrA2::SUM::Behavior::Activities\nKobrA2::SUM::Behavior::Actions\nKobrA2::SUM::Behavior\nKobrA2::SUM::Structure::Classes\nKobrA2::SUM::Structure::Types\nKobrA2::SUM::Structure::Instances\nKobrA2::SUM::Structure::Elements\nKobrA2::SUM::Structure\nKobrA2::SUM::Constraint::OclExpressions\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\nFigure 4: KobrA 2.0 SUM Package.\nit possible to model whether its instances are active or pas-\nsive. Active objects, which can be used to model threads and\nprocesses ([8] p. 438), start to execute their behavior as soon\nas they are created and perform operations spontaneously.\nA ComponentClass may exhibit complex behavior. In Ko-\nbrA, this behavior may be speci\ufb01ed in the form of\nUML\nState Diagrams (de\ufb01ning acceptable operation invocation\nsequences), and in the form of Activities (de\ufb01ning algorithms\nof operations). UML Interaction elements (in sequence dia-\ngrams) can be derived from the activity elements and thus\nare not included in the SUM. As KobrA aims to facilitate\nautomatic checking of allowed sequences of operation calls,\nProtocol State Machines are supported instead of general\nstate machines. Since the latter include a large variety of\nelements not needed for specifying acceptable operation se-\nquences or automatic checking, OCL constraints are used to\nprohibit the use of unwanted features.\ncontext\nComponentClass\n-- only\nallow\nActivity\nelements\nor\nProtocolStateMachines\ninv: ownedBehavior ->forAll( oclIsKindOf( Actitivity) or\noclIsKindOf ( ProtocolStateMachine ))\nFor example, since KobrA has no concept of roles for com-\nponents, the use of role also needs to be prohibited. The part\nassociation refers to owned properties of components whose\nattribute isComposite is true. As KobrA uses associations\nlike nests and creates for components, part, required and\nprovided are not needed. Connectors (i.e. delegation and\nassembly) are not used in KobrA either so ownedConnector\nis excluded.\nClass\nKobrA2::SUM::Structure::Classes\nGeneralizationSet\nAssociationClass\nComponentClass\nProperty\nUsage\nAssociation\nOperation\nPackageable\nElement\nParameter\nAcquires\nCreates\nNests\nUML::Component::PackagingComponents::Component\nUML::CommonBehaviors::Communications::Class\n+ownedOperation\n*\n+class\n0..1\n+supplier\n1..*\n{subsets supplierDependency}\n+supplierUsage\n*\n+client\n1..*\n{subsets clientDependency}\n+clientUsage\n*\n+ownedAttribute\n*\n+class\n0..1\n+powertype\n0..1\n+powertypeExtent\n*\n+packagedElement\n*\n{subsets component}\n+componentClass\n0..1\n+/superClass\nFigure 5: KobrA 2.0 Classes Package.\ncontext\nComponentClass\ninv: role ->union(part)->union( ownedConnector )\n->union( collaborationUse )-> union( representation )\n->union( realization)->union(required)\n->union(provided)->isEmpty ()\n3.\nVIEWS PACKAGE\nThe structure of the Views package is illustrated in Figure\n6. Again, since most of the views de\ufb01ned in KobrA 2.0 are\nbased on UML diagrams, the view metamodels have similar\nelements to the SUM metamodel. The big di\ufb00erence to the\nSUM is that there are no restrictions on the use of the view\nmetamodel elements.\nFor instance, views for a particular\npurpose such as supporting model checkers can be supported\nby adding elements unrelated to the UML.\nThe substructure of the Views package re\ufb02ects the types\nand organization of the KobrA views according to the view\n\u201cdimensions\u201d supported in nAOMi (cf. example in Section\n6). At the top level, the Views package is thus decomposed\ninto the Speci\ufb01cation and Realization options of the encap-\nsulation dimension.\nThese, in turn are both decomposed\ninto the Structural, Behavioral and Operational options of\nthe Projection dimension.\nFinally, with the exception of\nthe behavioral option, these are also all subdivided into the\nService and Type options of the granularity dimension. This\ndimension, with its two options, is an addition to the original\nversion of KobrA.\nThe Service view shows the direct, publicly visible rela-\ntionships of the subject ComponentClass to other Compo-\nnentClasses, while the Type view shows the publicly visi-\nble relationships of the subject to simple Classes. As with\nthe SUM, constraints have been de\ufb01ned to control what can\ngo into each view and when they are well formed. For ev-\nery view, a constraint enumerates all allowed elements (not\nshown in this paper).\nIn the following, some of the other constraints for the\nService view are elaborated. Since this view is a black-box\nview, the internals of ComponentClasses (nestedClassi\ufb01er)\nare not shown.\ncontext\nComponentClass\n-- no nested\nclassifiers , no\nprotocol\ninv: nestedClassifier ->union(protocol)->isEmpty ()\nClasses are only allowed if they are generalizations of Com-\nponentClasses, (or any of its superclasses, since a Compo-\nnentClass may inherit from a class as shown in the con-\nstraints with context Class. The following invariants ensure\nthat only publicly visible attributes and operations are in\nthis view, for both classes and ComponentClasses (which\ninherit from Class).\nClass\nService\nType\nInstance\nService\nType\nStructural\nSpecification\nOperational\nService\nType\nProtocol\nBehavioral\nKobrA2::Views::Derived\nComponentClassDependencies\nOperationDependencies\nInstance\nService\nType\nClass\nService\nType\nStructural\nRealization\nOperational\nService\nType\nBehavioral\nAlgorithm\nViews\nConcreteSyntax\nSubject\n<<import>>\n<<merge>>\n<<merge>>\n<<import>>\n<<merge>>\n<<import>>\nFigure 6: KobrA 2.0 Views package nesting.\ncontext\nClass\n-- only\nallow\nclasses\nthat\nare\ndirect or\nindirect\ngeneralizations\nof\nComponentClasses\nin this\nview\ndef: ccGeneralization : generalization .specific ->\nexists( oclIsKindOf ( ComponentClass ))\ninv:\ngeneralization .specific ->select( oclIsTypeOf (\nClass))->exists(s|s. ccGeneralization )\nor\nccGeneralization\n-- only\npublic\nattributes\nin this\nview\ninv: ownedAttribute ->forAll(visibility =# public)\n-- only\npublic\nOperations\nare\nallowed\nin the\nspecification\ninv: ownedOperation ->forAll(visibility =# public)\nOnly operation signatures are shown in this view, so pre-,\npost- and bodyconditions, as well as activities are omitted,\nwhich is re\ufb02ected in the last constraint.\ncontext\nOperation\n-- only\nthe\nsignature\nof the\nOperation\nis shown , not\nits\nbehavior (role\nname \"method\" refers to the\nActivities\nof the\noperation), or\ndependencies\ninv: method ->union( precondition )->union(body)->union(\npostcondition )->isEmpty ()\n4.\nTRANSFORMATIONS PACKAGE\nThe package AllViews provides the foundation for speci-\nfying the transformations between the SUM and the views\nin both directions. Part of the package\u2019s contents are shown\nin Figure 7.\nThe Abstraction concept (which is in fact a\nKobrA2::Transformation::Common::AllViews\nAbstraction\nTransformationExpression\nViewElement\nSumElement\nView\nKobrA2::SUM::Structure::Elements::Element\nKobrA2::Views::ConcreteSyntax::Element\nKobrA2::SUM::Constraint::Behavioral::Exp\nressionInOcl\nKobrA2::Views::Subject::View\n{subsets mapping}\n0..1\n0..1\n{subsets clientDependency}\n+abstraction 1\n{subsets client}\n+ve 1\n1..*\n1\n{subsets supplier}\n+se 1\n{subsets supplierDependency}\n+abstraction 1..*\nFigure 7: Transformation abstractions.\ndependency reused from the UML but with additional con-\nstraints) plays the key role in relating elements from the\nSUM to elements of a view. Abstraction is actually mapped\nto ExpressionInOcl.\nWhen appearing in transformations,\nthe equals sign links elements in the SUM to the respective\nelements in the view, and vice versa. For instance, equal-\nity of the general meta-association of a Generalization in\na transformation invariant means that, when following gen-\neral, there must be an element in the SUM and in the view\nfor which similar transformation expressions are speci\ufb01ed.\nIn the case of KobrA 2.0, which has many projections that\njust select a subset of elements using one-to-one abstrac-\ntions, this allows concise declarative TransformationExpres-\nsions. Together with the view constraints, a CASE tool can\nbe implemented which uses a transformation language of the\nimplementor\u2019s choice, for instance the Atlas Transformation\nLanguage (ATL) [11] or QVT [9]. The role names se and ve\nare short for SumElement and ViewElement, respectively.\nThese roles subset the client and supplier roles from the\nUML.\nSUM elements are translated into UML elements with\nstereotypes, so that the views are easy to manage for de-\nvelopers familiar with the UML. The bidirectional mappings\nbetween stereotyped view elements and non-stereotyped SUM\nelements are expressed in the constraints of the Association-\nAbstraction, a subclass of the Abstraction from the AllViews\npackage. This is also an example of a transformation which\nis reused in other views.\ncontext\nAssociationAbstraction\ninv: ve.memberEnd = se.memberEnd\ninv: ve.ownedEnd = se.ownedEnd\nivn: ve. navigableOwnedEnd = se. navigableOwnedEnd\ninv: se. oclIsKindOf(Acquires) implies ve.\nhasStereotype (\u2019acquires \u2019)\ninv: ve. hasStereotype (\u2019acquires \u2019)\nimplies\nse.\noclIsKindOf (Aquires)\ninv: se. oclIsKindOf(Nests) implies\nve. hasStereotype (\u2019\nnests \u2019)\ninv: ve. hasStereotype (\u2019nests \u2019)\nimplies se. oclIsKindOf\n(Nests)\ninv: se. oclIsKindOf (Creates) implies\nve. hasStereotype\n(\u2019creates \u2019)\ninv: ve. hasStereotype (\u2019creates \u2019)\nimplies se.\noclIsKindOf (Creates)\nFigure 8 shows the main elements involved in the trans-\nformation of the black box structural view for Component-\nClasses. The \ufb01rst transformation constraint is on the view\nand declares the starting point for the transformation. It\nstates that the subject ComponentClass and its generaliza-\ntions (using a SUM utility function, superClosure) are in the\nview.\nThe following transformation rules illustrate how to create\nthe output (i.e. view) elements from the input (i.e. SUM) el-\nements, such as the publicly visible attributes and operations\nof the ComponentClass and the acquired ComponentClasses.\nThe \ufb01rst constraint for ComponentClassAbstraction states\nthat references to potential general classes (and Component-\nClasses) of ComponentClasses are mirrored in the view. In\naddition, ComponentClasses will be shown with the corre-\nsponding stereotypes.\nThe ComponentClass owns various\ntypes of associations, so in this view only the acquires asso-\nciations are selected (whose transformation rules are cov-\nered in the common transformation packages).For classes\nand ComponentClasses, only publicly visible attributes and\noperations appear in the view.\nClass invariants are also\ncopied. Classes that may appear in this view (e.g. as gener-\nalizations of ComponentClasses) may have a powertype (role\nname powertypeExtent) which will be displayed.\nThe last transformation statement copies the class refer-\nences of operations. As with all views, the transformation\nrules, the common transformation statements (which also\ncover operations) and the view constraints serve as a speci-\n\ufb01cation for the implementation of a view. Individual CASE\ntools can use di\ufb00erent implementation techniques as long as\nthey conform to the semantics of these rules and constraints.\nKobrA2::Transformation::Specification::Structural::Class::Service\nComponentClassAbstraction\nKobrA2::Transformation::Common::Feature::OperationAbstraction\nKobrA2::Transformation::Common::AllViews::Abstraction\nKobrA2::SUM::Structure::Classes::ComponentClass\nKobrA2::SUM::Structure::Classes::Operation\nKobrA2::SUM::Structure::Classes::Class\nOperationAbstraction\nClassAbstraction\n+se\n1\n1..*\n+se\n1\n1..*\n+se\n1\n1..*\nFigure 8: Transformation to the Speci\ufb01cation Structural Service View.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassService\ninv: ownedMember ->select( oclIsKindOf(Class)) =\nsubject.superClosure ->union(subject.acquires.\nsuperClosure )\ncontext\nComponentClassAbstraction\ninv: ve.superClass = se. superClass\ninv: ve. hasStereotype (\u2019ComponentClass \u2019)\ninv: se.isSubject\nimplies (ve. hasStereotype (\u2019subject\n\u2019) and ve.ownedMember ->select( oclIsKindOf (\nAssociation )) = se.ownedMember ->select(\noclIsKindOf (Acquires)))\ncontext\nClassAbstraction\ninv: ve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\ninv: ve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public)\ninv: ve.\u2018inv \u2019 = se.\u2018inv \u2019\n-- copy\npowertypeExtent\nthat is only\nallowed\nfor\nclass\ninv: ve. powertypeExtent = se. powertypeExtent\ncontext\nOperationAbstraction\ninv: ve.class = se.class\nFor the black box type view, only publicly visible at-\ntributes and operations of classes (as opposed to Compo-\nnentClasses) used by the subject can be seen. This is spec-\ni\ufb01ed in the \ufb01rst rule which de\ufb01nes owned members of the\nview and thus serves as the starting point of the transfor-\nmation. cbbTypes is a utility function de\ufb01ned in the SUM\nwhich computes the black box types by selecting the types\nof the subject\u2019s public attributes and parameter types of its\npublic operations.\nClass invariants and potential powertypes and connections\nto the classes in this view are shown as well. There may\nalso be Enumerations, for which the EnumerationLiterals\nare displayed.\nThe transformation rules for this view are almost the same\nas the realization transformation constraints from the pack-\nage Transformation::Realization::Structural::Class::Type. The\ndi\ufb00erences are the select(visibility=#public) statements for\noperations and attributes.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassType\ninv: ownedMember ->select( oclIsKindOf(Class) or\noclIsKindOf(\u2018Enumeration \u2019) or\noclIsKindOf (\nAssociation)) = subject ->union(subject.cbbTypes)\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nClassAbstraction\ninv: not se.oclIsKindOf ( ComponentClass ) implies (\nve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\nve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public))\ninv: ve. powertypeExtent = se. powertypeExtent\ninv: ve. superClass = se.superClass\ninv: \u2018ve.inv \u2019 = \u2018se.inv \u2019\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nEnumerationAbstraction\ninv: ve. ownedLiteral = se. ownedLiteral\ncontext\nEnumerationLiteralAbstraction\ninv: ve. specification = se. specification .\nstringInSignature\n5.\nNAVIGATION\nMost of today\u2019s tools use some combination of trees to\norganize the content of models as well as the views used to\nvisualize a software system or component. In an any envi-\nronment incorporating a number of di\ufb00erent tools there is\ninvariably a large number of di\ufb00erent trees storing a het-\nerogeneous mix of artifacts including model elements (e.g.\nclasses, instances, associations), diagrams (e.g.\nclass dia-\ngrams, state diagrams) and other artifact types (source code,\nXML \ufb01les, con\ufb01guration \ufb01les ). To work with all the views in\na traditional development environment, therefore, engineers\ntypically have to learn about the organization structures of\nall the incorporated tools.\nIn contrast to conventional paradigms for organizing and\nnavigating the many views used to visualize a system, OSM\nemploys the metaphor of a multi-dimensional cube. More\nspeci\ufb01cally, as illustrated in Figure 9, OSM regards dimen-\nsion of the underlying methodology as representing a di\ufb00er-\nent dimension of the cube, and each independently variable\naspect of that dimension is a selectable dimension element.\nSelecting a view thus simply corresponds to selecting a single\ncell within the cube. In general, three types of dimensions\nare supported: static dimensions in which the number of\nFigure 9: Dimension-based navigation.\nselectable elements (i.e. coordinates) is \ufb01xed, dynamic di-\nmensions in which the number of elements is dynamic (i.e.\nderived from the SUM), and mixed dimensions which have\nboth static and dynamic elements.\nTo support the OSM dimension based navigation metaphor\nfor KobrA, we de\ufb01ned the seven dimensions indicated on the\nleft hand side of Figure 10 which is a sceenshot of nAOMI.\nThe Abstraction dimension (not expanded here), which has\nthree static dimension elements, PIM (platform independent\nmodel), PSM (platform speci\ufb01c model) and Code, captures\nthe model-driven development concern of KobrA. The ver-\nsion dimension captures the state of the modeled system at\nspeci\ufb01c points in time. The Component dimension, which\nhas dynamic dimension elements de\ufb01ned by instances of the\nclass ComponentClass in the SUM, captures the component-\nbased development concern of KobrA.\nThe Encapsulation dimension, which has two \ufb01xed ele-\nments, supports the distinction between Speci\ufb01cation (black\nbox) and Realization (white box) views of components, while\nthe Projection dimension with the \ufb01xed elements Structural,\nOperational and Behavioral covers the di\ufb00erent information\ntypes. The Granularity dimension provides a \ufb01ner grained\ndistinction between views describing the types used by com-\nponents (Type granularity) and views describing the required\nand provided interfaces (Service granularity). The Opera-\ntion dimension allows a selection of individual operations.\nIn the ideal case, when all views are truly orthogonal, the\nchoices that can be made in each dimensions are completely\nindependent.\nHowever, this is very di\ufb03cult to achieve in\nsoftware engineering. The approach still works if the views\nare not completely orthogonal, but dependencies then occur\nbetween di\ufb00erent choices in di\ufb00erent dimensions, so that the\ndecisions made in one dimensions may a\ufb00ect choices possi-\nble in another dimension. This is best handled by giving\ndimensions a precedence ranking determined by the order\nin which they appear (the top being the highest). When an\nelement in a dimension is selected, the tool automatically\nmakes default selections for dimensions of lower precedence\n(i.e.\ndimensions lower down) and disables selections that\nwould navigate to cells (i.e. views) which are not (yet) de-\n\ufb01ned by the method at hand.\n6.\nSHOPPING CART EXAMPLE\nTo show how a software system can be speci\ufb01ed using\nnAOMi, this section presents a case study based on a shop-\nping cart system. A ShoppingCart component collects and\nFigure 10: Speci\ufb01cation Structural View.\nmanages the products selected by users and supports pay-\nment via a credit card.\nFigure 10 illustrates a structural\nview of the component.\nIn the dimension navigator on the left hand side, PIM\nwas chosen for the \u201cAbstraction Level\u201d (not expanded in the\nscreenshot). The second dimension is the state of the soft-\nware system at a certain point in time. The picture shows\nthat the latest available version was chosen. As with every\nchoice in a dimension, it may in\ufb02uence the options in lower\nranked dimensions. The component under consideration is\nthe ShoppingCart, for which a black box view is selected\nin the next dimension. After the user selects the structural\nprojection option and the service level granularity, the tool\nautomatically chooses the option for all operations in the\nlast dimension, as there is no editor registered for the other\noptions.\nThe component under development is presented with the\nstereotype subject and its relationship to other components\nand classes is shown in the view, which corresponds to a cell\nof the multi-dimensional navigation cube, and is generated\non-the-\ufb02y from the SUM when it is selected. The classes\nProduct and CreditCard can be used as data types in the\noperations of the component.\nFigure 11 illustrates the operational view in which an\noperation can be formalized using pre- and postconditions.\nThe precondition corresponds to the assumes clause in and\nthe postcondition corresponds to the result clause. As in the\nUML, the precondition of an operation must be true when\nthe operation is invoked and the postcondition must be true\nwhen the operation is \ufb01nished. The operation addProduct\nin Figure 11 must be in state CollectingProducts or Empty\nwhen invoked. This is also visible in the behavioral view,\nFigure 11: addProduct() Operation Speci\ufb01cation.\nsince there are only two transitions with the operation ad-\ndProduct. Both leads to the state CollectingProducts which\nis also a postcondition of the operation. The second post-\ncondition is that the cost attribute of the component must\nbe increased by the price of the added product. The pre- and\npostcondition can be expressed using the OCL. The proper-\nties of the component, states and operation parameters can\nbe used to formalise the constraints like as in this example.\nFigure 12 shows the publicly visible behaviour of the Shop-\npingCart component with states and transitions. The condi-\ntional transitions map to operations of the component. Like\nevery view, this view is also synchronized with the SUM so\nthat it is guaranteed that its operations, states and proper-\nties are consistent with those in the structural view.\nFigure 12: Speci\ufb01cation Behavioral Model.\nAlthough the operational view seems to be similar to the\nbehavioral view because of the overlapping information within\nthem, there are signi\ufb01cant di\ufb00erences. The focus of the op-\nerational view is on a precise formal de\ufb01nition of an opera-\ntion of a component. The operations can be enriched by pre-\nand postconditions which can be de\ufb01ned using complex OCL\nstatements, that formalize the complete behavior of an op-\neration. The additional information in the OCL statements\ncan be used for code generation and documentation.\n7.\nCONCLUSION\nAt the beginning of the paper we identi\ufb01ed three funda-\nmental hypothesis upon which the notion of OSM is based\n\u2014 (a) that it is feasible to integrate the many di\ufb00erent kinds\nof artifacts used in contemporary software engineering meth-\nods within a single coherent methodology in which they are\ntreated as views, (b) that it is feasible to create an e\ufb03-\ncient and scalable way of supporting these views by gener-\nating them dynamically, on-the-\ufb02y, from a Single Underly-\ning Model (SUM) using model-based transformations and\n(c) that it is feasible to provide an intuitive metaphor for\nnavigating around these many views by adapting the ortho-\ngraphic projection technique underpinning the CAD tools\nused in other engineering disciplines.\nThe prototype tool, nAOMi, described in this paper rep-\nresents the \ufb01rst step towards demonstrating the validity of\nthese hypotheses and showing that OSM is a viable approach\nto software engineering. Of the three hypotheses, (a) and (c)\nare most convincingly demonstrated by the prototype, since\nit shows that it is indeed possible to support all the views\nof the KobrA method within a single navigation metaphor.\nThe prototype tool does not demonstrate the validity of hy-\npothesis (b) to the same extent as the others due to its\nsmall size. Although it demonstrates the feasibility of gen-\nerating views from the SUM and vice-versa, the question of\nwhether such an approach scales up to large environments\nis still open.\nAlthough nOAMi is the only tool developed with the spe-\nci\ufb01c aim of supporting KobrA-based OSM, several other\ntools and methods have similar properties or aims.\nFor\nexample, Glinz et al.\n[10] describe a tool with a \ufb01sheye\nzooming algorithm which lets the user view a model with\nvarying amounts of detail depending on the context. It has\nto be investigated whether it is possible to combine the \ufb01sh-\neye zooming concept with the dimension-based navigation\nparadigm. While the KobrA 2.0 implementation of nAOMi\nheavily uses UML diagrams for developers, Glinz et al. use\ncustom diagram types, e.g.\nfor structural and behavioral\nviews.\nAn approach which also emphasizes the description of for-\nmal consistency rules (correspondences) between views is\nRM-ODP [5][6].\nHowever, this approach does not explic-\nitly mention the notion of a SUM and thus implies that\nconsistency rules should be de\ufb01ned in a pairwise fashion be-\ntween individual pairs of views. ArchiMate [7], which com-\nplements TOGAF [12], is an enterprise architecture mod-\neling language which o\ufb00ers two orthogonal \u201ddimensions\u201d for\nmodeling, (business, architecture, and technology) layers and\n(informational, behavioral and structural) aspects and also\nsuggests two more dimensions, purpose and abstraction level.\nHowever, as many of these views span multiple choices of a\nsingle\u201cdimension\u201d, the intuitive dimension-based navigation\nmetaphor of OSM can not be easily applied. There are also\nmore general approaches for view-based modeling but they\nare less speci\ufb01c in terms of consistency rules between views\nand provide little guidance on how to manage and navigate\nviews, for example the Zachman Framework [14].\nRegarding the practical use of OSM environments in the\nfuture, the biggest challenge is developing appropriate SUM\nmetamodels which can accommodate all the types of views\nand services that software engineers are accustomed to to-\nday. For this \ufb01rst prototypical SUM-based environment sup-\nporting the OSM approach we had a method at our disposal\n(KobrA) that already de\ufb01ned a full set of orthogonal UML-\nbased views. This allowed us to model the required SUM\nand view metamodels by simply adapting the UML meta-\nmodels, removing and adding model elements as needed.\nIn doing so we were able to manually ensure that the meta-\nmodels ful\ufb01lled the two core requirements of SUM-based en-\nvironments \u2014 (1) being minimalistic and (2) redundancy\nfree. If SUM-based software engineering environments are\nto take o\ufb00, and to be introduced into existing, heteroge-\nneous environments, more sophisticated ways of integrating\nexisting metamodels into a single uni\ufb01ed metamodel will be\nrequired.\n8.\nREFERENCES\n[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,\nO. Laitenberger, R. Laqua, D. Muthig, B. Paech,\nJ. W\u00a8ust, and J. Zettel. Component-Based Product Line\nEngineering with UML. Addison Wesley, Reading,\nMassachusetts, USA, 1st edition, November 2001.\n[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic\nSoftware Modeling: A Practical Approach to\nView-Based Development. In Evaluation of Novel\nApproaches to Software Engineering, volume 69 of\nCommunications in Computer and Information\nScience, pages 206\u2013219. Springer Berlin Heidelberg,\n2010.\n[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic\nService Modeling. In Proceedings of 15th IEEE EDOC\nConference Workshops (EDOCW), Helsinki, Finland,\n2011.\n[4] Eclipse Foundation. UML2Tools.\nhttp://wiki.eclipse.org/MDT-UML2Tools, 2013.\n[5] ISO/IEC and ITU-T. The Reference Model of Open\nDistributed Processing. RM-ODP, ITU-T Rec.\nX.901-X.904 / ISO/IEC 10746.\nhttp://standards.iso.org/\nittf/PubliclyAvailableStandards/index.html,\n1998.\n[6] J. I. J. Jose Raul Romero and A. Vallecillo. Realizing\nCorrespondences in MultiViewpoint Speci\ufb01cations. In\nProceedings of the Thirteenth IEEE International\nEDOC Conference, 1 - 4 September 2009, Auckland,\nNew Zealand, September 2009.\n[7] M. Lankhorst. Enterprise Architecture at Work.\nSpringer Berlin Heidelberg, 2009.\n[8] Object Management Group (OMG). OMG Uni\ufb01ed\nModeling Language (OMG UML), Superstructure,\nV2.1.2.\nhttp://www.omg.org/cgi-bin/doc?formal/07-11-02,\nNovember 2007.\n[9] Object Management Group (OMG). Meta Object\nFacility (MOF) 2.0 Query/View/Transformation, v1.0.\nhttp://www.omg.org/spec/QVT/1.0/PDF/, April 2008.\n[10] C. Seybold, M. Glinz, S. Meier, and N. Merlo-Schett.\nAn e\ufb00ective layout adaptation technique for a\ngraphical modeling tool. In Proceedings of the 2003\nInternational Conference on Software Engineering,\nPortland, 2003.\n[11] The Atlas Transformation Language (ATL). O\ufb03cial\nWebsite. http://www.eclipse.org/atl/, 2013.\n[12] The Open Group. TOGAF Version 9 - The Open\nGroup Architecture Framework.\nhttp://www.opengroup.org/architecture/\ntogaf9-doc/arch/index.html, Feb 2009.\n[13] University of Mannheim - Software Engineering\nGroup. nAOMi - opeN, Adaptable, Orthographic\nModeling EnvIronment.\nhttp://eclipselabs.org/p/naomi.\n[14] J. A. Zachman. The Zachman Framework: A Primer\nfor Enterprise Engineering and Manufacturing.\nhttp://www.zachmaninternational.com, 2009.\n",
    "pdf_url": "",
    "references": [
      "[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,",
      "O. Laitenberger, R. Laqua, D. Muthig, B. Paech,",
      "J. W\u00a8ust, and J. Zettel. Component-Based Product Line",
      "Engineering with UML. Addison Wesley, Reading,",
      "Massachusetts, USA, 1st edition, November 2001.",
      "[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic",
      "Software Modeling: A Practical Approach to",
      "View-Based Development. In Evaluation of Novel",
      "Approaches to Software Engineering, volume 69 of",
      "Communications in Computer and Information",
      "Science, pages 206\u2013219. Springer Berlin Heidelberg,",
      "2010.",
      "[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "University of Kent",
      "uage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).Addison-Wesley Professional."
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "A Prototype Implementation of an Orthographic Software Modeling Environment",
    "resume": "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
    "auteurs": [
      "Colin Atkinson",
      "Dietmar Stoll",
      "Jacques Robin",
      "Recife",
      "Brasil",
      "D.2.2"
    ],
    "institutions": [
      "Dietmar Stoll University of Mannheim, TunjicUniversity of Mannheim,",
      "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
      "Colin Atkinson University of Mannheim,"
    ],
    "mots_cles": [
      " Orthographic Software Modeling",
      " View-based Modeling "
    ],
    "texte_integral": "A Prototype Implementation of an Orthographic Software\nModeling Environment\nColin Atkinson\nUniversity of Mannheim,\nGermany\natkinson@informatik.uni-\nmannheim.de\nDietmar Stoll\nUniversity of Mannheim,\nGermany\nstoll@informatik.uni-\nmannheim.de\nChristian Tunjic\nUniversity of Mannheim,\nGermany\ntunjic@informatik.uni-\nmannheim.de\nJacques Robin\nUniversidade Federal de\nPernambuco, Recife, Brasil\njr@cin.ufpe.br\nABSTRACT\nOrthographic Software Modeling (OSM) is a view-centric\nsoftware engineering approach that aims to leverage the or-\nthographic projection metaphor used in the visualization of\nphysical objects to visualize software systems. Although the\ngeneral concept of OSM does not prescribe speci\ufb01c sets of\nviews, a concrete OSM environment has to be speci\ufb01c about\nthe particular views to be used in a particular project. At\nthe University of Mannheim we are developing a prototype\nOSM environment, nAOMi, that supports the views de\ufb01ned\nby the KobrA 2.0 method, a version of KobrA adapted for\nOSM. In this paper we provide an overview of the KobrA 2.0\nmetamodel underpinning nAOMi and give a small example\nof its use to model a software system.\nCategories and Subject Descriptors\nD.1.7 [Programming Techniques]: Visual Programming;\nD.2.2 [Design Tools and Techniques]: Computer-aided\nsoftware engineering (CASE); D.2.6 [Software Engineer-\ning]: Programming Environments\u2014Graphical environments\nKeywords\nOrthographic Software Modeling, View-based Modeling\n1.\nINTRODUCTION\nOrthographic Software Modeling (OSM) is based on three\nfundamental hypotheses \u2014 (a) that it is feasible to inte-\ngrate the many di\ufb00erent kinds of artifacts used in contempo-\nrary software engineering methods within a single coherent\nmethodology in which they are treated as views, (b) that it\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for pro\ufb01t or commercial advantage and that copies\nbear this notice and the full citation on the \ufb01rst page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior speci\ufb01c\npermission and/or a fee.\nVAO \u201913, July 2, 2013, Montpellier, France\nCopyright 2013 ACM 978-1-4503-2041-2 ...$15.00.\nis feasible to create an e\ufb03cient and scalable way of support-\ning these views by generating them dynamically, on-the-\ufb02y,\nfrom a Single Underlying Model (SUM) using model-based\ntransformations and (c) that it is feasible to provide an in-\ntuitive metaphor for navigating around these many views\nby adapting the orthographic projection technique under-\npinning the CAD tools used in other engineering disciplines.\nFigure 1: Orthographic Projection.\nAs shown in Figure 1, the main advantages of using the\nidea of orthographic projection to de\ufb01ne the views used\nto visualize and described a system are that they (a) can\nbe organized according to a simple and easy-to-understand\nmetaphor and (b) collectively represent all the properties of\na system with minimal overlap and redundancy. In practice\nthis translates into a set of \u201cdimensions\u201d, each containing\nwell de\ufb01ned choices (or so called \u201cdimension elements\u201d) that\ncan be used to select individuals views.\nAs shown in Figure 2, the main advantage of making the\nartifacts used to describe a software system views of a SUM\nis that the number of pairwise coherence relationships that\nhave to be maintained is reduced and new views can be in-\ntroduced by simply de\ufb01ning their relationship to the SUM.\nMoreover, the importance of this advantage grows quickly\nas the size of the system and the complexity of the deployed\ndevelopment methodology increase. Another important ad-\nvantage is that the dominance of one particular kind of view\nover the development process (e.g. code) at the expense of\nother kinds of views (e.g. graphical models) is reduced so\nthat any appropriate type of views can be used to enrich\nthe underlying description of the system, depending on the\nneeds and skills of the stakeholder involved. This makes it\npossible to subsume all view types under the same, overarch-\nSUM\nSUM / View Centric Environment\nArtifact / Tools Centric Environment\nFigure 2: Consistency Dependencies in Artifact-oriented versus View-oriented Environments.\ning development process and methodology (e.g. agile-driven,\nfocusing on small development cycles, or model-driven de-\nvelopment, based on transformations between abstraction\nlevels). Although the details of how the views are created\nfrom the SUM and how the SUM is updated from the views\nare not central to the approach, a natural implementation\nis to use the visualization and transformation technologies\no\ufb00ered by model driven software engineering (MDSE).\nTo explore the validity of these hypotheses at the Uni-\nversity of Mannheim we have been developing a prototype\nOSM modeling environment based on an enhanced version\nof the KobrA method for model-driven, component-oriented\ndevelopment, KobrA 2.0 [1]. This was chosen as a basis for\nthe prototype, known as the Open, Adaptable, Orthographic\nModeling Environment (nAOMi) [13] because its views were\ndesigned with the precise goals of being (a) genuine pro-\njections of a subject containing carefully selected subsets\nof information about that subject, (b) minimalistic in the\nsense that they should overlap to the smallest extent possible\nand contain the minimum necessary models elements, and\n(c) selectable via a set of independent \u201cdimensions\u201d which\nre\ufb02ect di\ufb00erent fundamental concerns of development (i.e.\nabstraction levels, composition or variants). In other words,\nKobrA already provided one of the \u201cmost orthogonal\u201d sets\nof views for visualizing software systems of any contempo-\nrary method. More details about the actual views and di-\nmensions de\ufb01ned in KobrA are presented in the following\nsections. More information on OSM can be found in [2] and\n[3].\nnAOMi is implemented as an Eclipse plugin using the\nEclipse Modeling Framework (EMF) as the underlying mod-\neling platform and UML 2.0 tools [4] to generate and edit\nviews.\nThe KobrA 2.0 metamodel on which the current\nversion of nAOMi is based is a specialization of the UML\nmetamodel composed of three separate packages \u2014 one for\nthe SUM, one for the views and one for the transformations\n(Figure 3). The UML was chosen as the base language be-\ncause of its maturity and widespread acceptance, making the\nenvironment usable to the largest possible body of develop-\ners. UML elements not needed in KobrA 2.0 are excluded\nusing OCL constraints while new elements or properties are\nKobrA2\nTransformation\nSUM\nViews\nFigure 3: KobrA 2.0 Top Level Packages.\nintroduced by specializing existing elements.\nThe unique contribution of this paper is to elaborate on\nthe structure of the KobrA 2.0 metamodel and how it is used\nto drive nAOMi. The three following sections each focus on\none of the three main components of the metamodel \u2014 the\nSUM, the views and the transformations . This is followed\nby a brief overview of the OSM navigation paradigm in Sec-\ntion 5 before a small example of the approach is presented in\nSection 6. Section 7 then concludes the paper with related\nand future work.\n2.\nSUM PACKAGE\nFigure 4 depicts the internal structure of the SUM pack-\nage which is based on the UML metamodel. There are three\nmain subpackages, two containing the structural and behav-\nioral constructs respectively, and one containing the con-\nstraints that ensure that the metaclasses are used according\nto the KobrA conventions and rules.\nThe Classes subpackage of the Structure package contains\nsome of the most fundamental elements of the KobrA meta-\nmodel, such as Class and ComponentClass.\nThe internal\nstructure of this package is illustrated in Figure 5. Com-\nponentClass represents objects with complex and reusable\nbehaviors, while Class captures simple \u201cdata type\u201d objects\nthat have only very simple or non-reusable behaviors. The\nmodeler has to decide whether it is necessary to model a\nspeci\ufb01c part of the system as a ComponentClass and include\nstate charts and activity diagrams, or whether it is su\ufb03cient\nto use a Class (which is limited to using OCL constraints).\nComponentClass inherits (indirectly via Class) from Com-\nmunications so it also has the isActive attribute. This makes\nKobrA2::SUM::Constraint::Behavioral\nKobrA2::SUM::Constraint::Structural\nKobrA2::SUM::Constraint\nKobrA2::SUM::Constraint::Common\nKobrA2::SUM::Behavior::ProtocolStateMachines\nKobrA2::SUM::Behavior::Common\nKobrA2::SUM::Behavior::Activities\nKobrA2::SUM::Behavior::Actions\nKobrA2::SUM::Behavior\nKobrA2::SUM::Structure::Classes\nKobrA2::SUM::Structure::Types\nKobrA2::SUM::Structure::Instances\nKobrA2::SUM::Structure::Elements\nKobrA2::SUM::Structure\nKobrA2::SUM::Constraint::OclExpressions\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\nFigure 4: KobrA 2.0 SUM Package.\nit possible to model whether its instances are active or pas-\nsive. Active objects, which can be used to model threads and\nprocesses ([8] p. 438), start to execute their behavior as soon\nas they are created and perform operations spontaneously.\nA ComponentClass may exhibit complex behavior. In Ko-\nbrA, this behavior may be speci\ufb01ed in the form of\nUML\nState Diagrams (de\ufb01ning acceptable operation invocation\nsequences), and in the form of Activities (de\ufb01ning algorithms\nof operations). UML Interaction elements (in sequence dia-\ngrams) can be derived from the activity elements and thus\nare not included in the SUM. As KobrA aims to facilitate\nautomatic checking of allowed sequences of operation calls,\nProtocol State Machines are supported instead of general\nstate machines. Since the latter include a large variety of\nelements not needed for specifying acceptable operation se-\nquences or automatic checking, OCL constraints are used to\nprohibit the use of unwanted features.\ncontext\nComponentClass\n-- only\nallow\nActivity\nelements\nor\nProtocolStateMachines\ninv: ownedBehavior ->forAll( oclIsKindOf( Actitivity) or\noclIsKindOf ( ProtocolStateMachine ))\nFor example, since KobrA has no concept of roles for com-\nponents, the use of role also needs to be prohibited. The part\nassociation refers to owned properties of components whose\nattribute isComposite is true. As KobrA uses associations\nlike nests and creates for components, part, required and\nprovided are not needed. Connectors (i.e. delegation and\nassembly) are not used in KobrA either so ownedConnector\nis excluded.\nClass\nKobrA2::SUM::Structure::Classes\nGeneralizationSet\nAssociationClass\nComponentClass\nProperty\nUsage\nAssociation\nOperation\nPackageable\nElement\nParameter\nAcquires\nCreates\nNests\nUML::Component::PackagingComponents::Component\nUML::CommonBehaviors::Communications::Class\n+ownedOperation\n*\n+class\n0..1\n+supplier\n1..*\n{subsets supplierDependency}\n+supplierUsage\n*\n+client\n1..*\n{subsets clientDependency}\n+clientUsage\n*\n+ownedAttribute\n*\n+class\n0..1\n+powertype\n0..1\n+powertypeExtent\n*\n+packagedElement\n*\n{subsets component}\n+componentClass\n0..1\n+/superClass\nFigure 5: KobrA 2.0 Classes Package.\ncontext\nComponentClass\ninv: role ->union(part)->union( ownedConnector )\n->union( collaborationUse )-> union( representation )\n->union( realization)->union(required)\n->union(provided)->isEmpty ()\n3.\nVIEWS PACKAGE\nThe structure of the Views package is illustrated in Figure\n6. Again, since most of the views de\ufb01ned in KobrA 2.0 are\nbased on UML diagrams, the view metamodels have similar\nelements to the SUM metamodel. The big di\ufb00erence to the\nSUM is that there are no restrictions on the use of the view\nmetamodel elements.\nFor instance, views for a particular\npurpose such as supporting model checkers can be supported\nby adding elements unrelated to the UML.\nThe substructure of the Views package re\ufb02ects the types\nand organization of the KobrA views according to the view\n\u201cdimensions\u201d supported in nAOMi (cf. example in Section\n6). At the top level, the Views package is thus decomposed\ninto the Speci\ufb01cation and Realization options of the encap-\nsulation dimension.\nThese, in turn are both decomposed\ninto the Structural, Behavioral and Operational options of\nthe Projection dimension.\nFinally, with the exception of\nthe behavioral option, these are also all subdivided into the\nService and Type options of the granularity dimension. This\ndimension, with its two options, is an addition to the original\nversion of KobrA.\nThe Service view shows the direct, publicly visible rela-\ntionships of the subject ComponentClass to other Compo-\nnentClasses, while the Type view shows the publicly visi-\nble relationships of the subject to simple Classes. As with\nthe SUM, constraints have been de\ufb01ned to control what can\ngo into each view and when they are well formed. For ev-\nery view, a constraint enumerates all allowed elements (not\nshown in this paper).\nIn the following, some of the other constraints for the\nService view are elaborated. Since this view is a black-box\nview, the internals of ComponentClasses (nestedClassi\ufb01er)\nare not shown.\ncontext\nComponentClass\n-- no nested\nclassifiers , no\nprotocol\ninv: nestedClassifier ->union(protocol)->isEmpty ()\nClasses are only allowed if they are generalizations of Com-\nponentClasses, (or any of its superclasses, since a Compo-\nnentClass may inherit from a class as shown in the con-\nstraints with context Class. The following invariants ensure\nthat only publicly visible attributes and operations are in\nthis view, for both classes and ComponentClasses (which\ninherit from Class).\nClass\nService\nType\nInstance\nService\nType\nStructural\nSpecification\nOperational\nService\nType\nProtocol\nBehavioral\nKobrA2::Views::Derived\nComponentClassDependencies\nOperationDependencies\nInstance\nService\nType\nClass\nService\nType\nStructural\nRealization\nOperational\nService\nType\nBehavioral\nAlgorithm\nViews\nConcreteSyntax\nSubject\n<<import>>\n<<merge>>\n<<merge>>\n<<import>>\n<<merge>>\n<<import>>\nFigure 6: KobrA 2.0 Views package nesting.\ncontext\nClass\n-- only\nallow\nclasses\nthat\nare\ndirect or\nindirect\ngeneralizations\nof\nComponentClasses\nin this\nview\ndef: ccGeneralization : generalization .specific ->\nexists( oclIsKindOf ( ComponentClass ))\ninv:\ngeneralization .specific ->select( oclIsTypeOf (\nClass))->exists(s|s. ccGeneralization )\nor\nccGeneralization\n-- only\npublic\nattributes\nin this\nview\ninv: ownedAttribute ->forAll(visibility =# public)\n-- only\npublic\nOperations\nare\nallowed\nin the\nspecification\ninv: ownedOperation ->forAll(visibility =# public)\nOnly operation signatures are shown in this view, so pre-,\npost- and bodyconditions, as well as activities are omitted,\nwhich is re\ufb02ected in the last constraint.\ncontext\nOperation\n-- only\nthe\nsignature\nof the\nOperation\nis shown , not\nits\nbehavior (role\nname \"method\" refers to the\nActivities\nof the\noperation), or\ndependencies\ninv: method ->union( precondition )->union(body)->union(\npostcondition )->isEmpty ()\n4.\nTRANSFORMATIONS PACKAGE\nThe package AllViews provides the foundation for speci-\nfying the transformations between the SUM and the views\nin both directions. Part of the package\u2019s contents are shown\nin Figure 7.\nThe Abstraction concept (which is in fact a\nKobrA2::Transformation::Common::AllViews\nAbstraction\nTransformationExpression\nViewElement\nSumElement\nView\nKobrA2::SUM::Structure::Elements::Element\nKobrA2::Views::ConcreteSyntax::Element\nKobrA2::SUM::Constraint::Behavioral::Exp\nressionInOcl\nKobrA2::Views::Subject::View\n{subsets mapping}\n0..1\n0..1\n{subsets clientDependency}\n+abstraction 1\n{subsets client}\n+ve 1\n1..*\n1\n{subsets supplier}\n+se 1\n{subsets supplierDependency}\n+abstraction 1..*\nFigure 7: Transformation abstractions.\ndependency reused from the UML but with additional con-\nstraints) plays the key role in relating elements from the\nSUM to elements of a view. Abstraction is actually mapped\nto ExpressionInOcl.\nWhen appearing in transformations,\nthe equals sign links elements in the SUM to the respective\nelements in the view, and vice versa. For instance, equal-\nity of the general meta-association of a Generalization in\na transformation invariant means that, when following gen-\neral, there must be an element in the SUM and in the view\nfor which similar transformation expressions are speci\ufb01ed.\nIn the case of KobrA 2.0, which has many projections that\njust select a subset of elements using one-to-one abstrac-\ntions, this allows concise declarative TransformationExpres-\nsions. Together with the view constraints, a CASE tool can\nbe implemented which uses a transformation language of the\nimplementor\u2019s choice, for instance the Atlas Transformation\nLanguage (ATL) [11] or QVT [9]. The role names se and ve\nare short for SumElement and ViewElement, respectively.\nThese roles subset the client and supplier roles from the\nUML.\nSUM elements are translated into UML elements with\nstereotypes, so that the views are easy to manage for de-\nvelopers familiar with the UML. The bidirectional mappings\nbetween stereotyped view elements and non-stereotyped SUM\nelements are expressed in the constraints of the Association-\nAbstraction, a subclass of the Abstraction from the AllViews\npackage. This is also an example of a transformation which\nis reused in other views.\ncontext\nAssociationAbstraction\ninv: ve.memberEnd = se.memberEnd\ninv: ve.ownedEnd = se.ownedEnd\nivn: ve. navigableOwnedEnd = se. navigableOwnedEnd\ninv: se. oclIsKindOf(Acquires) implies ve.\nhasStereotype (\u2019acquires \u2019)\ninv: ve. hasStereotype (\u2019acquires \u2019)\nimplies\nse.\noclIsKindOf (Aquires)\ninv: se. oclIsKindOf(Nests) implies\nve. hasStereotype (\u2019\nnests \u2019)\ninv: ve. hasStereotype (\u2019nests \u2019)\nimplies se. oclIsKindOf\n(Nests)\ninv: se. oclIsKindOf (Creates) implies\nve. hasStereotype\n(\u2019creates \u2019)\ninv: ve. hasStereotype (\u2019creates \u2019)\nimplies se.\noclIsKindOf (Creates)\nFigure 8 shows the main elements involved in the trans-\nformation of the black box structural view for Component-\nClasses. The \ufb01rst transformation constraint is on the view\nand declares the starting point for the transformation. It\nstates that the subject ComponentClass and its generaliza-\ntions (using a SUM utility function, superClosure) are in the\nview.\nThe following transformation rules illustrate how to create\nthe output (i.e. view) elements from the input (i.e. SUM) el-\nements, such as the publicly visible attributes and operations\nof the ComponentClass and the acquired ComponentClasses.\nThe \ufb01rst constraint for ComponentClassAbstraction states\nthat references to potential general classes (and Component-\nClasses) of ComponentClasses are mirrored in the view. In\naddition, ComponentClasses will be shown with the corre-\nsponding stereotypes.\nThe ComponentClass owns various\ntypes of associations, so in this view only the acquires asso-\nciations are selected (whose transformation rules are cov-\nered in the common transformation packages).For classes\nand ComponentClasses, only publicly visible attributes and\noperations appear in the view.\nClass invariants are also\ncopied. Classes that may appear in this view (e.g. as gener-\nalizations of ComponentClasses) may have a powertype (role\nname powertypeExtent) which will be displayed.\nThe last transformation statement copies the class refer-\nences of operations. As with all views, the transformation\nrules, the common transformation statements (which also\ncover operations) and the view constraints serve as a speci-\n\ufb01cation for the implementation of a view. Individual CASE\ntools can use di\ufb00erent implementation techniques as long as\nthey conform to the semantics of these rules and constraints.\nKobrA2::Transformation::Specification::Structural::Class::Service\nComponentClassAbstraction\nKobrA2::Transformation::Common::Feature::OperationAbstraction\nKobrA2::Transformation::Common::AllViews::Abstraction\nKobrA2::SUM::Structure::Classes::ComponentClass\nKobrA2::SUM::Structure::Classes::Operation\nKobrA2::SUM::Structure::Classes::Class\nOperationAbstraction\nClassAbstraction\n+se\n1\n1..*\n+se\n1\n1..*\n+se\n1\n1..*\nFigure 8: Transformation to the Speci\ufb01cation Structural Service View.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassService\ninv: ownedMember ->select( oclIsKindOf(Class)) =\nsubject.superClosure ->union(subject.acquires.\nsuperClosure )\ncontext\nComponentClassAbstraction\ninv: ve.superClass = se. superClass\ninv: ve. hasStereotype (\u2019ComponentClass \u2019)\ninv: se.isSubject\nimplies (ve. hasStereotype (\u2019subject\n\u2019) and ve.ownedMember ->select( oclIsKindOf (\nAssociation )) = se.ownedMember ->select(\noclIsKindOf (Acquires)))\ncontext\nClassAbstraction\ninv: ve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\ninv: ve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public)\ninv: ve.\u2018inv \u2019 = se.\u2018inv \u2019\n-- copy\npowertypeExtent\nthat is only\nallowed\nfor\nclass\ninv: ve. powertypeExtent = se. powertypeExtent\ncontext\nOperationAbstraction\ninv: ve.class = se.class\nFor the black box type view, only publicly visible at-\ntributes and operations of classes (as opposed to Compo-\nnentClasses) used by the subject can be seen. This is spec-\ni\ufb01ed in the \ufb01rst rule which de\ufb01nes owned members of the\nview and thus serves as the starting point of the transfor-\nmation. cbbTypes is a utility function de\ufb01ned in the SUM\nwhich computes the black box types by selecting the types\nof the subject\u2019s public attributes and parameter types of its\npublic operations.\nClass invariants and potential powertypes and connections\nto the classes in this view are shown as well. There may\nalso be Enumerations, for which the EnumerationLiterals\nare displayed.\nThe transformation rules for this view are almost the same\nas the realization transformation constraints from the pack-\nage Transformation::Realization::Structural::Class::Type. The\ndi\ufb00erences are the select(visibility=#public) statements for\noperations and attributes.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassType\ninv: ownedMember ->select( oclIsKindOf(Class) or\noclIsKindOf(\u2018Enumeration \u2019) or\noclIsKindOf (\nAssociation)) = subject ->union(subject.cbbTypes)\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nClassAbstraction\ninv: not se.oclIsKindOf ( ComponentClass ) implies (\nve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\nve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public))\ninv: ve. powertypeExtent = se. powertypeExtent\ninv: ve. superClass = se.superClass\ninv: \u2018ve.inv \u2019 = \u2018se.inv \u2019\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nEnumerationAbstraction\ninv: ve. ownedLiteral = se. ownedLiteral\ncontext\nEnumerationLiteralAbstraction\ninv: ve. specification = se. specification .\nstringInSignature\n5.\nNAVIGATION\nMost of today\u2019s tools use some combination of trees to\norganize the content of models as well as the views used to\nvisualize a software system or component. In an any envi-\nronment incorporating a number of di\ufb00erent tools there is\ninvariably a large number of di\ufb00erent trees storing a het-\nerogeneous mix of artifacts including model elements (e.g.\nclasses, instances, associations), diagrams (e.g.\nclass dia-\ngrams, state diagrams) and other artifact types (source code,\nXML \ufb01les, con\ufb01guration \ufb01les ). To work with all the views in\na traditional development environment, therefore, engineers\ntypically have to learn about the organization structures of\nall the incorporated tools.\nIn contrast to conventional paradigms for organizing and\nnavigating the many views used to visualize a system, OSM\nemploys the metaphor of a multi-dimensional cube. More\nspeci\ufb01cally, as illustrated in Figure 9, OSM regards dimen-\nsion of the underlying methodology as representing a di\ufb00er-\nent dimension of the cube, and each independently variable\naspect of that dimension is a selectable dimension element.\nSelecting a view thus simply corresponds to selecting a single\ncell within the cube. In general, three types of dimensions\nare supported: static dimensions in which the number of\nFigure 9: Dimension-based navigation.\nselectable elements (i.e. coordinates) is \ufb01xed, dynamic di-\nmensions in which the number of elements is dynamic (i.e.\nderived from the SUM), and mixed dimensions which have\nboth static and dynamic elements.\nTo support the OSM dimension based navigation metaphor\nfor KobrA, we de\ufb01ned the seven dimensions indicated on the\nleft hand side of Figure 10 which is a sceenshot of nAOMI.\nThe Abstraction dimension (not expanded here), which has\nthree static dimension elements, PIM (platform independent\nmodel), PSM (platform speci\ufb01c model) and Code, captures\nthe model-driven development concern of KobrA. The ver-\nsion dimension captures the state of the modeled system at\nspeci\ufb01c points in time. The Component dimension, which\nhas dynamic dimension elements de\ufb01ned by instances of the\nclass ComponentClass in the SUM, captures the component-\nbased development concern of KobrA.\nThe Encapsulation dimension, which has two \ufb01xed ele-\nments, supports the distinction between Speci\ufb01cation (black\nbox) and Realization (white box) views of components, while\nthe Projection dimension with the \ufb01xed elements Structural,\nOperational and Behavioral covers the di\ufb00erent information\ntypes. The Granularity dimension provides a \ufb01ner grained\ndistinction between views describing the types used by com-\nponents (Type granularity) and views describing the required\nand provided interfaces (Service granularity). The Opera-\ntion dimension allows a selection of individual operations.\nIn the ideal case, when all views are truly orthogonal, the\nchoices that can be made in each dimensions are completely\nindependent.\nHowever, this is very di\ufb03cult to achieve in\nsoftware engineering. The approach still works if the views\nare not completely orthogonal, but dependencies then occur\nbetween di\ufb00erent choices in di\ufb00erent dimensions, so that the\ndecisions made in one dimensions may a\ufb00ect choices possi-\nble in another dimension. This is best handled by giving\ndimensions a precedence ranking determined by the order\nin which they appear (the top being the highest). When an\nelement in a dimension is selected, the tool automatically\nmakes default selections for dimensions of lower precedence\n(i.e.\ndimensions lower down) and disables selections that\nwould navigate to cells (i.e. views) which are not (yet) de-\n\ufb01ned by the method at hand.\n6.\nSHOPPING CART EXAMPLE\nTo show how a software system can be speci\ufb01ed using\nnAOMi, this section presents a case study based on a shop-\nping cart system. A ShoppingCart component collects and\nFigure 10: Speci\ufb01cation Structural View.\nmanages the products selected by users and supports pay-\nment via a credit card.\nFigure 10 illustrates a structural\nview of the component.\nIn the dimension navigator on the left hand side, PIM\nwas chosen for the \u201cAbstraction Level\u201d (not expanded in the\nscreenshot). The second dimension is the state of the soft-\nware system at a certain point in time. The picture shows\nthat the latest available version was chosen. As with every\nchoice in a dimension, it may in\ufb02uence the options in lower\nranked dimensions. The component under consideration is\nthe ShoppingCart, for which a black box view is selected\nin the next dimension. After the user selects the structural\nprojection option and the service level granularity, the tool\nautomatically chooses the option for all operations in the\nlast dimension, as there is no editor registered for the other\noptions.\nThe component under development is presented with the\nstereotype subject and its relationship to other components\nand classes is shown in the view, which corresponds to a cell\nof the multi-dimensional navigation cube, and is generated\non-the-\ufb02y from the SUM when it is selected. The classes\nProduct and CreditCard can be used as data types in the\noperations of the component.\nFigure 11 illustrates the operational view in which an\noperation can be formalized using pre- and postconditions.\nThe precondition corresponds to the assumes clause in and\nthe postcondition corresponds to the result clause. As in the\nUML, the precondition of an operation must be true when\nthe operation is invoked and the postcondition must be true\nwhen the operation is \ufb01nished. The operation addProduct\nin Figure 11 must be in state CollectingProducts or Empty\nwhen invoked. This is also visible in the behavioral view,\nFigure 11: addProduct() Operation Speci\ufb01cation.\nsince there are only two transitions with the operation ad-\ndProduct. Both leads to the state CollectingProducts which\nis also a postcondition of the operation. The second post-\ncondition is that the cost attribute of the component must\nbe increased by the price of the added product. The pre- and\npostcondition can be expressed using the OCL. The proper-\nties of the component, states and operation parameters can\nbe used to formalise the constraints like as in this example.\nFigure 12 shows the publicly visible behaviour of the Shop-\npingCart component with states and transitions. The condi-\ntional transitions map to operations of the component. Like\nevery view, this view is also synchronized with the SUM so\nthat it is guaranteed that its operations, states and proper-\nties are consistent with those in the structural view.\nFigure 12: Speci\ufb01cation Behavioral Model.\nAlthough the operational view seems to be similar to the\nbehavioral view because of the overlapping information within\nthem, there are signi\ufb01cant di\ufb00erences. The focus of the op-\nerational view is on a precise formal de\ufb01nition of an opera-\ntion of a component. The operations can be enriched by pre-\nand postconditions which can be de\ufb01ned using complex OCL\nstatements, that formalize the complete behavior of an op-\neration. The additional information in the OCL statements\ncan be used for code generation and documentation.\n7.\nCONCLUSION\nAt the beginning of the paper we identi\ufb01ed three funda-\nmental hypothesis upon which the notion of OSM is based\n\u2014 (a) that it is feasible to integrate the many di\ufb00erent kinds\nof artifacts used in contemporary software engineering meth-\nods within a single coherent methodology in which they are\ntreated as views, (b) that it is feasible to create an e\ufb03-\ncient and scalable way of supporting these views by gener-\nating them dynamically, on-the-\ufb02y, from a Single Underly-\ning Model (SUM) using model-based transformations and\n(c) that it is feasible to provide an intuitive metaphor for\nnavigating around these many views by adapting the ortho-\ngraphic projection technique underpinning the CAD tools\nused in other engineering disciplines.\nThe prototype tool, nAOMi, described in this paper rep-\nresents the \ufb01rst step towards demonstrating the validity of\nthese hypotheses and showing that OSM is a viable approach\nto software engineering. Of the three hypotheses, (a) and (c)\nare most convincingly demonstrated by the prototype, since\nit shows that it is indeed possible to support all the views\nof the KobrA method within a single navigation metaphor.\nThe prototype tool does not demonstrate the validity of hy-\npothesis (b) to the same extent as the others due to its\nsmall size. Although it demonstrates the feasibility of gen-\nerating views from the SUM and vice-versa, the question of\nwhether such an approach scales up to large environments\nis still open.\nAlthough nOAMi is the only tool developed with the spe-\nci\ufb01c aim of supporting KobrA-based OSM, several other\ntools and methods have similar properties or aims.\nFor\nexample, Glinz et al.\n[10] describe a tool with a \ufb01sheye\nzooming algorithm which lets the user view a model with\nvarying amounts of detail depending on the context. It has\nto be investigated whether it is possible to combine the \ufb01sh-\neye zooming concept with the dimension-based navigation\nparadigm. While the KobrA 2.0 implementation of nAOMi\nheavily uses UML diagrams for developers, Glinz et al. use\ncustom diagram types, e.g.\nfor structural and behavioral\nviews.\nAn approach which also emphasizes the description of for-\nmal consistency rules (correspondences) between views is\nRM-ODP [5][6].\nHowever, this approach does not explic-\nitly mention the notion of a SUM and thus implies that\nconsistency rules should be de\ufb01ned in a pairwise fashion be-\ntween individual pairs of views. ArchiMate [7], which com-\nplements TOGAF [12], is an enterprise architecture mod-\neling language which o\ufb00ers two orthogonal \u201ddimensions\u201d for\nmodeling, (business, architecture, and technology) layers and\n(informational, behavioral and structural) aspects and also\nsuggests two more dimensions, purpose and abstraction level.\nHowever, as many of these views span multiple choices of a\nsingle\u201cdimension\u201d, the intuitive dimension-based navigation\nmetaphor of OSM can not be easily applied. There are also\nmore general approaches for view-based modeling but they\nare less speci\ufb01c in terms of consistency rules between views\nand provide little guidance on how to manage and navigate\nviews, for example the Zachman Framework [14].\nRegarding the practical use of OSM environments in the\nfuture, the biggest challenge is developing appropriate SUM\nmetamodels which can accommodate all the types of views\nand services that software engineers are accustomed to to-\nday. For this \ufb01rst prototypical SUM-based environment sup-\nporting the OSM approach we had a method at our disposal\n(KobrA) that already de\ufb01ned a full set of orthogonal UML-\nbased views. This allowed us to model the required SUM\nand view metamodels by simply adapting the UML meta-\nmodels, removing and adding model elements as needed.\nIn doing so we were able to manually ensure that the meta-\nmodels ful\ufb01lled the two core requirements of SUM-based en-\nvironments \u2014 (1) being minimalistic and (2) redundancy\nfree. If SUM-based software engineering environments are\nto take o\ufb00, and to be introduced into existing, heteroge-\nneous environments, more sophisticated ways of integrating\nexisting metamodels into a single uni\ufb01ed metamodel will be\nrequired.\n8.\nREFERENCES\n[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,\nO. Laitenberger, R. Laqua, D. Muthig, B. Paech,\nJ. W\u00a8ust, and J. Zettel. Component-Based Product Line\nEngineering with UML. Addison Wesley, Reading,\nMassachusetts, USA, 1st edition, November 2001.\n[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic\nSoftware Modeling: A Practical Approach to\nView-Based Development. In Evaluation of Novel\nApproaches to Software Engineering, volume 69 of\nCommunications in Computer and Information\nScience, pages 206\u2013219. Springer Berlin Heidelberg,\n2010.\n[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic\nService Modeling. In Proceedings of 15th IEEE EDOC\nConference Workshops (EDOCW), Helsinki, Finland,\n2011.\n[4] Eclipse Foundation. UML2Tools.\nhttp://wiki.eclipse.org/MDT-UML2Tools, 2013.\n[5] ISO/IEC and ITU-T. The Reference Model of Open\nDistributed Processing. RM-ODP, ITU-T Rec.\nX.901-X.904 / ISO/IEC 10746.\nhttp://standards.iso.org/\nittf/PubliclyAvailableStandards/index.html,\n1998.\n[6] J. I. J. Jose Raul Romero and A. Vallecillo. Realizing\nCorrespondences in MultiViewpoint Speci\ufb01cations. In\nProceedings of the Thirteenth IEEE International\nEDOC Conference, 1 - 4 September 2009, Auckland,\nNew Zealand, September 2009.\n[7] M. Lankhorst. Enterprise Architecture at Work.\nSpringer Berlin Heidelberg, 2009.\n[8] Object Management Group (OMG). OMG Uni\ufb01ed\nModeling Language (OMG UML), Superstructure,\nV2.1.2.\nhttp://www.omg.org/cgi-bin/doc?formal/07-11-02,\nNovember 2007.\n[9] Object Management Group (OMG). Meta Object\nFacility (MOF) 2.0 Query/View/Transformation, v1.0.\nhttp://www.omg.org/spec/QVT/1.0/PDF/, April 2008.\n[10] C. Seybold, M. Glinz, S. Meier, and N. Merlo-Schett.\nAn e\ufb00ective layout adaptation technique for a\ngraphical modeling tool. In Proceedings of the 2003\nInternational Conference on Software Engineering,\nPortland, 2003.\n[11] The Atlas Transformation Language (ATL). O\ufb03cial\nWebsite. http://www.eclipse.org/atl/, 2013.\n[12] The Open Group. TOGAF Version 9 - The Open\nGroup Architecture Framework.\nhttp://www.opengroup.org/architecture/\ntogaf9-doc/arch/index.html, Feb 2009.\n[13] University of Mannheim - Software Engineering\nGroup. nAOMi - opeN, Adaptable, Orthographic\nModeling EnvIronment.\nhttp://eclipselabs.org/p/naomi.\n[14] J. A. Zachman. The Zachman Framework: A Primer\nfor Enterprise Engineering and Manufacturing.\nhttp://www.zachmaninternational.com, 2009.\n",
    "pdf_url": "",
    "references": [
      "[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,",
      "O. Laitenberger, R. Laqua, D. Muthig, B. Paech,",
      "J. W\u00a8ust, and J. Zettel. Component-Based Product Line",
      "Engineering with UML. Addison Wesley, Reading,",
      "Massachusetts, USA, 1st edition, November 2001.",
      "[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic",
      "Software Modeling: A Practical Approach to",
      "View-Based Development. In Evaluation of Novel",
      "Approaches to Software Engineering, volume 69 of",
      "Communications in Computer and Information",
      "Science, pages 206\u2013219. Springer Berlin Heidelberg,",
      "2010.",
      "[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "University of Kent",
      "uage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).Addison-Wesley Professional."
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "A Prototype Implementation of an Orthographic Software Modeling Environment",
    "resume": "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
    "auteurs": [
      "Colin Atkinson",
      "Dietmar Stoll",
      "Jacques Robin",
      "Recife",
      "Brasil",
      "D.2.2"
    ],
    "institutions": [
      "Dietmar Stoll University of Mannheim, TunjicUniversity of Mannheim,",
      "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
      "Colin Atkinson University of Mannheim,"
    ],
    "mots_cles": [
      " Orthographic Software Modeling",
      " View-based Modeling "
    ],
    "texte_integral": "A Prototype Implementation of an Orthographic Software\nModeling Environment\nColin Atkinson\nUniversity of Mannheim,\nGermany\natkinson@informatik.uni-\nmannheim.de\nDietmar Stoll\nUniversity of Mannheim,\nGermany\nstoll@informatik.uni-\nmannheim.de\nChristian Tunjic\nUniversity of Mannheim,\nGermany\ntunjic@informatik.uni-\nmannheim.de\nJacques Robin\nUniversidade Federal de\nPernambuco, Recife, Brasil\njr@cin.ufpe.br\nABSTRACT\nOrthographic Software Modeling (OSM) is a view-centric\nsoftware engineering approach that aims to leverage the or-\nthographic projection metaphor used in the visualization of\nphysical objects to visualize software systems. Although the\ngeneral concept of OSM does not prescribe speci\ufb01c sets of\nviews, a concrete OSM environment has to be speci\ufb01c about\nthe particular views to be used in a particular project. At\nthe University of Mannheim we are developing a prototype\nOSM environment, nAOMi, that supports the views de\ufb01ned\nby the KobrA 2.0 method, a version of KobrA adapted for\nOSM. In this paper we provide an overview of the KobrA 2.0\nmetamodel underpinning nAOMi and give a small example\nof its use to model a software system.\nCategories and Subject Descriptors\nD.1.7 [Programming Techniques]: Visual Programming;\nD.2.2 [Design Tools and Techniques]: Computer-aided\nsoftware engineering (CASE); D.2.6 [Software Engineer-\ning]: Programming Environments\u2014Graphical environments\nKeywords\nOrthographic Software Modeling, View-based Modeling\n1.\nINTRODUCTION\nOrthographic Software Modeling (OSM) is based on three\nfundamental hypotheses \u2014 (a) that it is feasible to inte-\ngrate the many di\ufb00erent kinds of artifacts used in contempo-\nrary software engineering methods within a single coherent\nmethodology in which they are treated as views, (b) that it\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for pro\ufb01t or commercial advantage and that copies\nbear this notice and the full citation on the \ufb01rst page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior speci\ufb01c\npermission and/or a fee.\nVAO \u201913, July 2, 2013, Montpellier, France\nCopyright 2013 ACM 978-1-4503-2041-2 ...$15.00.\nis feasible to create an e\ufb03cient and scalable way of support-\ning these views by generating them dynamically, on-the-\ufb02y,\nfrom a Single Underlying Model (SUM) using model-based\ntransformations and (c) that it is feasible to provide an in-\ntuitive metaphor for navigating around these many views\nby adapting the orthographic projection technique under-\npinning the CAD tools used in other engineering disciplines.\nFigure 1: Orthographic Projection.\nAs shown in Figure 1, the main advantages of using the\nidea of orthographic projection to de\ufb01ne the views used\nto visualize and described a system are that they (a) can\nbe organized according to a simple and easy-to-understand\nmetaphor and (b) collectively represent all the properties of\na system with minimal overlap and redundancy. In practice\nthis translates into a set of \u201cdimensions\u201d, each containing\nwell de\ufb01ned choices (or so called \u201cdimension elements\u201d) that\ncan be used to select individuals views.\nAs shown in Figure 2, the main advantage of making the\nartifacts used to describe a software system views of a SUM\nis that the number of pairwise coherence relationships that\nhave to be maintained is reduced and new views can be in-\ntroduced by simply de\ufb01ning their relationship to the SUM.\nMoreover, the importance of this advantage grows quickly\nas the size of the system and the complexity of the deployed\ndevelopment methodology increase. Another important ad-\nvantage is that the dominance of one particular kind of view\nover the development process (e.g. code) at the expense of\nother kinds of views (e.g. graphical models) is reduced so\nthat any appropriate type of views can be used to enrich\nthe underlying description of the system, depending on the\nneeds and skills of the stakeholder involved. This makes it\npossible to subsume all view types under the same, overarch-\nSUM\nSUM / View Centric Environment\nArtifact / Tools Centric Environment\nFigure 2: Consistency Dependencies in Artifact-oriented versus View-oriented Environments.\ning development process and methodology (e.g. agile-driven,\nfocusing on small development cycles, or model-driven de-\nvelopment, based on transformations between abstraction\nlevels). Although the details of how the views are created\nfrom the SUM and how the SUM is updated from the views\nare not central to the approach, a natural implementation\nis to use the visualization and transformation technologies\no\ufb00ered by model driven software engineering (MDSE).\nTo explore the validity of these hypotheses at the Uni-\nversity of Mannheim we have been developing a prototype\nOSM modeling environment based on an enhanced version\nof the KobrA method for model-driven, component-oriented\ndevelopment, KobrA 2.0 [1]. This was chosen as a basis for\nthe prototype, known as the Open, Adaptable, Orthographic\nModeling Environment (nAOMi) [13] because its views were\ndesigned with the precise goals of being (a) genuine pro-\njections of a subject containing carefully selected subsets\nof information about that subject, (b) minimalistic in the\nsense that they should overlap to the smallest extent possible\nand contain the minimum necessary models elements, and\n(c) selectable via a set of independent \u201cdimensions\u201d which\nre\ufb02ect di\ufb00erent fundamental concerns of development (i.e.\nabstraction levels, composition or variants). In other words,\nKobrA already provided one of the \u201cmost orthogonal\u201d sets\nof views for visualizing software systems of any contempo-\nrary method. More details about the actual views and di-\nmensions de\ufb01ned in KobrA are presented in the following\nsections. More information on OSM can be found in [2] and\n[3].\nnAOMi is implemented as an Eclipse plugin using the\nEclipse Modeling Framework (EMF) as the underlying mod-\neling platform and UML 2.0 tools [4] to generate and edit\nviews.\nThe KobrA 2.0 metamodel on which the current\nversion of nAOMi is based is a specialization of the UML\nmetamodel composed of three separate packages \u2014 one for\nthe SUM, one for the views and one for the transformations\n(Figure 3). The UML was chosen as the base language be-\ncause of its maturity and widespread acceptance, making the\nenvironment usable to the largest possible body of develop-\ners. UML elements not needed in KobrA 2.0 are excluded\nusing OCL constraints while new elements or properties are\nKobrA2\nTransformation\nSUM\nViews\nFigure 3: KobrA 2.0 Top Level Packages.\nintroduced by specializing existing elements.\nThe unique contribution of this paper is to elaborate on\nthe structure of the KobrA 2.0 metamodel and how it is used\nto drive nAOMi. The three following sections each focus on\none of the three main components of the metamodel \u2014 the\nSUM, the views and the transformations . This is followed\nby a brief overview of the OSM navigation paradigm in Sec-\ntion 5 before a small example of the approach is presented in\nSection 6. Section 7 then concludes the paper with related\nand future work.\n2.\nSUM PACKAGE\nFigure 4 depicts the internal structure of the SUM pack-\nage which is based on the UML metamodel. There are three\nmain subpackages, two containing the structural and behav-\nioral constructs respectively, and one containing the con-\nstraints that ensure that the metaclasses are used according\nto the KobrA conventions and rules.\nThe Classes subpackage of the Structure package contains\nsome of the most fundamental elements of the KobrA meta-\nmodel, such as Class and ComponentClass.\nThe internal\nstructure of this package is illustrated in Figure 5. Com-\nponentClass represents objects with complex and reusable\nbehaviors, while Class captures simple \u201cdata type\u201d objects\nthat have only very simple or non-reusable behaviors. The\nmodeler has to decide whether it is necessary to model a\nspeci\ufb01c part of the system as a ComponentClass and include\nstate charts and activity diagrams, or whether it is su\ufb03cient\nto use a Class (which is limited to using OCL constraints).\nComponentClass inherits (indirectly via Class) from Com-\nmunications so it also has the isActive attribute. This makes\nKobrA2::SUM::Constraint::Behavioral\nKobrA2::SUM::Constraint::Structural\nKobrA2::SUM::Constraint\nKobrA2::SUM::Constraint::Common\nKobrA2::SUM::Behavior::ProtocolStateMachines\nKobrA2::SUM::Behavior::Common\nKobrA2::SUM::Behavior::Activities\nKobrA2::SUM::Behavior::Actions\nKobrA2::SUM::Behavior\nKobrA2::SUM::Structure::Classes\nKobrA2::SUM::Structure::Types\nKobrA2::SUM::Structure::Instances\nKobrA2::SUM::Structure::Elements\nKobrA2::SUM::Structure\nKobrA2::SUM::Constraint::OclExpressions\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\nFigure 4: KobrA 2.0 SUM Package.\nit possible to model whether its instances are active or pas-\nsive. Active objects, which can be used to model threads and\nprocesses ([8] p. 438), start to execute their behavior as soon\nas they are created and perform operations spontaneously.\nA ComponentClass may exhibit complex behavior. In Ko-\nbrA, this behavior may be speci\ufb01ed in the form of\nUML\nState Diagrams (de\ufb01ning acceptable operation invocation\nsequences), and in the form of Activities (de\ufb01ning algorithms\nof operations). UML Interaction elements (in sequence dia-\ngrams) can be derived from the activity elements and thus\nare not included in the SUM. As KobrA aims to facilitate\nautomatic checking of allowed sequences of operation calls,\nProtocol State Machines are supported instead of general\nstate machines. Since the latter include a large variety of\nelements not needed for specifying acceptable operation se-\nquences or automatic checking, OCL constraints are used to\nprohibit the use of unwanted features.\ncontext\nComponentClass\n-- only\nallow\nActivity\nelements\nor\nProtocolStateMachines\ninv: ownedBehavior ->forAll( oclIsKindOf( Actitivity) or\noclIsKindOf ( ProtocolStateMachine ))\nFor example, since KobrA has no concept of roles for com-\nponents, the use of role also needs to be prohibited. The part\nassociation refers to owned properties of components whose\nattribute isComposite is true. As KobrA uses associations\nlike nests and creates for components, part, required and\nprovided are not needed. Connectors (i.e. delegation and\nassembly) are not used in KobrA either so ownedConnector\nis excluded.\nClass\nKobrA2::SUM::Structure::Classes\nGeneralizationSet\nAssociationClass\nComponentClass\nProperty\nUsage\nAssociation\nOperation\nPackageable\nElement\nParameter\nAcquires\nCreates\nNests\nUML::Component::PackagingComponents::Component\nUML::CommonBehaviors::Communications::Class\n+ownedOperation\n*\n+class\n0..1\n+supplier\n1..*\n{subsets supplierDependency}\n+supplierUsage\n*\n+client\n1..*\n{subsets clientDependency}\n+clientUsage\n*\n+ownedAttribute\n*\n+class\n0..1\n+powertype\n0..1\n+powertypeExtent\n*\n+packagedElement\n*\n{subsets component}\n+componentClass\n0..1\n+/superClass\nFigure 5: KobrA 2.0 Classes Package.\ncontext\nComponentClass\ninv: role ->union(part)->union( ownedConnector )\n->union( collaborationUse )-> union( representation )\n->union( realization)->union(required)\n->union(provided)->isEmpty ()\n3.\nVIEWS PACKAGE\nThe structure of the Views package is illustrated in Figure\n6. Again, since most of the views de\ufb01ned in KobrA 2.0 are\nbased on UML diagrams, the view metamodels have similar\nelements to the SUM metamodel. The big di\ufb00erence to the\nSUM is that there are no restrictions on the use of the view\nmetamodel elements.\nFor instance, views for a particular\npurpose such as supporting model checkers can be supported\nby adding elements unrelated to the UML.\nThe substructure of the Views package re\ufb02ects the types\nand organization of the KobrA views according to the view\n\u201cdimensions\u201d supported in nAOMi (cf. example in Section\n6). At the top level, the Views package is thus decomposed\ninto the Speci\ufb01cation and Realization options of the encap-\nsulation dimension.\nThese, in turn are both decomposed\ninto the Structural, Behavioral and Operational options of\nthe Projection dimension.\nFinally, with the exception of\nthe behavioral option, these are also all subdivided into the\nService and Type options of the granularity dimension. This\ndimension, with its two options, is an addition to the original\nversion of KobrA.\nThe Service view shows the direct, publicly visible rela-\ntionships of the subject ComponentClass to other Compo-\nnentClasses, while the Type view shows the publicly visi-\nble relationships of the subject to simple Classes. As with\nthe SUM, constraints have been de\ufb01ned to control what can\ngo into each view and when they are well formed. For ev-\nery view, a constraint enumerates all allowed elements (not\nshown in this paper).\nIn the following, some of the other constraints for the\nService view are elaborated. Since this view is a black-box\nview, the internals of ComponentClasses (nestedClassi\ufb01er)\nare not shown.\ncontext\nComponentClass\n-- no nested\nclassifiers , no\nprotocol\ninv: nestedClassifier ->union(protocol)->isEmpty ()\nClasses are only allowed if they are generalizations of Com-\nponentClasses, (or any of its superclasses, since a Compo-\nnentClass may inherit from a class as shown in the con-\nstraints with context Class. The following invariants ensure\nthat only publicly visible attributes and operations are in\nthis view, for both classes and ComponentClasses (which\ninherit from Class).\nClass\nService\nType\nInstance\nService\nType\nStructural\nSpecification\nOperational\nService\nType\nProtocol\nBehavioral\nKobrA2::Views::Derived\nComponentClassDependencies\nOperationDependencies\nInstance\nService\nType\nClass\nService\nType\nStructural\nRealization\nOperational\nService\nType\nBehavioral\nAlgorithm\nViews\nConcreteSyntax\nSubject\n<<import>>\n<<merge>>\n<<merge>>\n<<import>>\n<<merge>>\n<<import>>\nFigure 6: KobrA 2.0 Views package nesting.\ncontext\nClass\n-- only\nallow\nclasses\nthat\nare\ndirect or\nindirect\ngeneralizations\nof\nComponentClasses\nin this\nview\ndef: ccGeneralization : generalization .specific ->\nexists( oclIsKindOf ( ComponentClass ))\ninv:\ngeneralization .specific ->select( oclIsTypeOf (\nClass))->exists(s|s. ccGeneralization )\nor\nccGeneralization\n-- only\npublic\nattributes\nin this\nview\ninv: ownedAttribute ->forAll(visibility =# public)\n-- only\npublic\nOperations\nare\nallowed\nin the\nspecification\ninv: ownedOperation ->forAll(visibility =# public)\nOnly operation signatures are shown in this view, so pre-,\npost- and bodyconditions, as well as activities are omitted,\nwhich is re\ufb02ected in the last constraint.\ncontext\nOperation\n-- only\nthe\nsignature\nof the\nOperation\nis shown , not\nits\nbehavior (role\nname \"method\" refers to the\nActivities\nof the\noperation), or\ndependencies\ninv: method ->union( precondition )->union(body)->union(\npostcondition )->isEmpty ()\n4.\nTRANSFORMATIONS PACKAGE\nThe package AllViews provides the foundation for speci-\nfying the transformations between the SUM and the views\nin both directions. Part of the package\u2019s contents are shown\nin Figure 7.\nThe Abstraction concept (which is in fact a\nKobrA2::Transformation::Common::AllViews\nAbstraction\nTransformationExpression\nViewElement\nSumElement\nView\nKobrA2::SUM::Structure::Elements::Element\nKobrA2::Views::ConcreteSyntax::Element\nKobrA2::SUM::Constraint::Behavioral::Exp\nressionInOcl\nKobrA2::Views::Subject::View\n{subsets mapping}\n0..1\n0..1\n{subsets clientDependency}\n+abstraction 1\n{subsets client}\n+ve 1\n1..*\n1\n{subsets supplier}\n+se 1\n{subsets supplierDependency}\n+abstraction 1..*\nFigure 7: Transformation abstractions.\ndependency reused from the UML but with additional con-\nstraints) plays the key role in relating elements from the\nSUM to elements of a view. Abstraction is actually mapped\nto ExpressionInOcl.\nWhen appearing in transformations,\nthe equals sign links elements in the SUM to the respective\nelements in the view, and vice versa. For instance, equal-\nity of the general meta-association of a Generalization in\na transformation invariant means that, when following gen-\neral, there must be an element in the SUM and in the view\nfor which similar transformation expressions are speci\ufb01ed.\nIn the case of KobrA 2.0, which has many projections that\njust select a subset of elements using one-to-one abstrac-\ntions, this allows concise declarative TransformationExpres-\nsions. Together with the view constraints, a CASE tool can\nbe implemented which uses a transformation language of the\nimplementor\u2019s choice, for instance the Atlas Transformation\nLanguage (ATL) [11] or QVT [9]. The role names se and ve\nare short for SumElement and ViewElement, respectively.\nThese roles subset the client and supplier roles from the\nUML.\nSUM elements are translated into UML elements with\nstereotypes, so that the views are easy to manage for de-\nvelopers familiar with the UML. The bidirectional mappings\nbetween stereotyped view elements and non-stereotyped SUM\nelements are expressed in the constraints of the Association-\nAbstraction, a subclass of the Abstraction from the AllViews\npackage. This is also an example of a transformation which\nis reused in other views.\ncontext\nAssociationAbstraction\ninv: ve.memberEnd = se.memberEnd\ninv: ve.ownedEnd = se.ownedEnd\nivn: ve. navigableOwnedEnd = se. navigableOwnedEnd\ninv: se. oclIsKindOf(Acquires) implies ve.\nhasStereotype (\u2019acquires \u2019)\ninv: ve. hasStereotype (\u2019acquires \u2019)\nimplies\nse.\noclIsKindOf (Aquires)\ninv: se. oclIsKindOf(Nests) implies\nve. hasStereotype (\u2019\nnests \u2019)\ninv: ve. hasStereotype (\u2019nests \u2019)\nimplies se. oclIsKindOf\n(Nests)\ninv: se. oclIsKindOf (Creates) implies\nve. hasStereotype\n(\u2019creates \u2019)\ninv: ve. hasStereotype (\u2019creates \u2019)\nimplies se.\noclIsKindOf (Creates)\nFigure 8 shows the main elements involved in the trans-\nformation of the black box structural view for Component-\nClasses. The \ufb01rst transformation constraint is on the view\nand declares the starting point for the transformation. It\nstates that the subject ComponentClass and its generaliza-\ntions (using a SUM utility function, superClosure) are in the\nview.\nThe following transformation rules illustrate how to create\nthe output (i.e. view) elements from the input (i.e. SUM) el-\nements, such as the publicly visible attributes and operations\nof the ComponentClass and the acquired ComponentClasses.\nThe \ufb01rst constraint for ComponentClassAbstraction states\nthat references to potential general classes (and Component-\nClasses) of ComponentClasses are mirrored in the view. In\naddition, ComponentClasses will be shown with the corre-\nsponding stereotypes.\nThe ComponentClass owns various\ntypes of associations, so in this view only the acquires asso-\nciations are selected (whose transformation rules are cov-\nered in the common transformation packages).For classes\nand ComponentClasses, only publicly visible attributes and\noperations appear in the view.\nClass invariants are also\ncopied. Classes that may appear in this view (e.g. as gener-\nalizations of ComponentClasses) may have a powertype (role\nname powertypeExtent) which will be displayed.\nThe last transformation statement copies the class refer-\nences of operations. As with all views, the transformation\nrules, the common transformation statements (which also\ncover operations) and the view constraints serve as a speci-\n\ufb01cation for the implementation of a view. Individual CASE\ntools can use di\ufb00erent implementation techniques as long as\nthey conform to the semantics of these rules and constraints.\nKobrA2::Transformation::Specification::Structural::Class::Service\nComponentClassAbstraction\nKobrA2::Transformation::Common::Feature::OperationAbstraction\nKobrA2::Transformation::Common::AllViews::Abstraction\nKobrA2::SUM::Structure::Classes::ComponentClass\nKobrA2::SUM::Structure::Classes::Operation\nKobrA2::SUM::Structure::Classes::Class\nOperationAbstraction\nClassAbstraction\n+se\n1\n1..*\n+se\n1\n1..*\n+se\n1\n1..*\nFigure 8: Transformation to the Speci\ufb01cation Structural Service View.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassService\ninv: ownedMember ->select( oclIsKindOf(Class)) =\nsubject.superClosure ->union(subject.acquires.\nsuperClosure )\ncontext\nComponentClassAbstraction\ninv: ve.superClass = se. superClass\ninv: ve. hasStereotype (\u2019ComponentClass \u2019)\ninv: se.isSubject\nimplies (ve. hasStereotype (\u2019subject\n\u2019) and ve.ownedMember ->select( oclIsKindOf (\nAssociation )) = se.ownedMember ->select(\noclIsKindOf (Acquires)))\ncontext\nClassAbstraction\ninv: ve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\ninv: ve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public)\ninv: ve.\u2018inv \u2019 = se.\u2018inv \u2019\n-- copy\npowertypeExtent\nthat is only\nallowed\nfor\nclass\ninv: ve. powertypeExtent = se. powertypeExtent\ncontext\nOperationAbstraction\ninv: ve.class = se.class\nFor the black box type view, only publicly visible at-\ntributes and operations of classes (as opposed to Compo-\nnentClasses) used by the subject can be seen. This is spec-\ni\ufb01ed in the \ufb01rst rule which de\ufb01nes owned members of the\nview and thus serves as the starting point of the transfor-\nmation. cbbTypes is a utility function de\ufb01ned in the SUM\nwhich computes the black box types by selecting the types\nof the subject\u2019s public attributes and parameter types of its\npublic operations.\nClass invariants and potential powertypes and connections\nto the classes in this view are shown as well. There may\nalso be Enumerations, for which the EnumerationLiterals\nare displayed.\nThe transformation rules for this view are almost the same\nas the realization transformation constraints from the pack-\nage Transformation::Realization::Structural::Class::Type. The\ndi\ufb00erences are the select(visibility=#public) statements for\noperations and attributes.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassType\ninv: ownedMember ->select( oclIsKindOf(Class) or\noclIsKindOf(\u2018Enumeration \u2019) or\noclIsKindOf (\nAssociation)) = subject ->union(subject.cbbTypes)\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nClassAbstraction\ninv: not se.oclIsKindOf ( ComponentClass ) implies (\nve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\nve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public))\ninv: ve. powertypeExtent = se. powertypeExtent\ninv: ve. superClass = se.superClass\ninv: \u2018ve.inv \u2019 = \u2018se.inv \u2019\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nEnumerationAbstraction\ninv: ve. ownedLiteral = se. ownedLiteral\ncontext\nEnumerationLiteralAbstraction\ninv: ve. specification = se. specification .\nstringInSignature\n5.\nNAVIGATION\nMost of today\u2019s tools use some combination of trees to\norganize the content of models as well as the views used to\nvisualize a software system or component. In an any envi-\nronment incorporating a number of di\ufb00erent tools there is\ninvariably a large number of di\ufb00erent trees storing a het-\nerogeneous mix of artifacts including model elements (e.g.\nclasses, instances, associations), diagrams (e.g.\nclass dia-\ngrams, state diagrams) and other artifact types (source code,\nXML \ufb01les, con\ufb01guration \ufb01les ). To work with all the views in\na traditional development environment, therefore, engineers\ntypically have to learn about the organization structures of\nall the incorporated tools.\nIn contrast to conventional paradigms for organizing and\nnavigating the many views used to visualize a system, OSM\nemploys the metaphor of a multi-dimensional cube. More\nspeci\ufb01cally, as illustrated in Figure 9, OSM regards dimen-\nsion of the underlying methodology as representing a di\ufb00er-\nent dimension of the cube, and each independently variable\naspect of that dimension is a selectable dimension element.\nSelecting a view thus simply corresponds to selecting a single\ncell within the cube. In general, three types of dimensions\nare supported: static dimensions in which the number of\nFigure 9: Dimension-based navigation.\nselectable elements (i.e. coordinates) is \ufb01xed, dynamic di-\nmensions in which the number of elements is dynamic (i.e.\nderived from the SUM), and mixed dimensions which have\nboth static and dynamic elements.\nTo support the OSM dimension based navigation metaphor\nfor KobrA, we de\ufb01ned the seven dimensions indicated on the\nleft hand side of Figure 10 which is a sceenshot of nAOMI.\nThe Abstraction dimension (not expanded here), which has\nthree static dimension elements, PIM (platform independent\nmodel), PSM (platform speci\ufb01c model) and Code, captures\nthe model-driven development concern of KobrA. The ver-\nsion dimension captures the state of the modeled system at\nspeci\ufb01c points in time. The Component dimension, which\nhas dynamic dimension elements de\ufb01ned by instances of the\nclass ComponentClass in the SUM, captures the component-\nbased development concern of KobrA.\nThe Encapsulation dimension, which has two \ufb01xed ele-\nments, supports the distinction between Speci\ufb01cation (black\nbox) and Realization (white box) views of components, while\nthe Projection dimension with the \ufb01xed elements Structural,\nOperational and Behavioral covers the di\ufb00erent information\ntypes. The Granularity dimension provides a \ufb01ner grained\ndistinction between views describing the types used by com-\nponents (Type granularity) and views describing the required\nand provided interfaces (Service granularity). The Opera-\ntion dimension allows a selection of individual operations.\nIn the ideal case, when all views are truly orthogonal, the\nchoices that can be made in each dimensions are completely\nindependent.\nHowever, this is very di\ufb03cult to achieve in\nsoftware engineering. The approach still works if the views\nare not completely orthogonal, but dependencies then occur\nbetween di\ufb00erent choices in di\ufb00erent dimensions, so that the\ndecisions made in one dimensions may a\ufb00ect choices possi-\nble in another dimension. This is best handled by giving\ndimensions a precedence ranking determined by the order\nin which they appear (the top being the highest). When an\nelement in a dimension is selected, the tool automatically\nmakes default selections for dimensions of lower precedence\n(i.e.\ndimensions lower down) and disables selections that\nwould navigate to cells (i.e. views) which are not (yet) de-\n\ufb01ned by the method at hand.\n6.\nSHOPPING CART EXAMPLE\nTo show how a software system can be speci\ufb01ed using\nnAOMi, this section presents a case study based on a shop-\nping cart system. A ShoppingCart component collects and\nFigure 10: Speci\ufb01cation Structural View.\nmanages the products selected by users and supports pay-\nment via a credit card.\nFigure 10 illustrates a structural\nview of the component.\nIn the dimension navigator on the left hand side, PIM\nwas chosen for the \u201cAbstraction Level\u201d (not expanded in the\nscreenshot). The second dimension is the state of the soft-\nware system at a certain point in time. The picture shows\nthat the latest available version was chosen. As with every\nchoice in a dimension, it may in\ufb02uence the options in lower\nranked dimensions. The component under consideration is\nthe ShoppingCart, for which a black box view is selected\nin the next dimension. After the user selects the structural\nprojection option and the service level granularity, the tool\nautomatically chooses the option for all operations in the\nlast dimension, as there is no editor registered for the other\noptions.\nThe component under development is presented with the\nstereotype subject and its relationship to other components\nand classes is shown in the view, which corresponds to a cell\nof the multi-dimensional navigation cube, and is generated\non-the-\ufb02y from the SUM when it is selected. The classes\nProduct and CreditCard can be used as data types in the\noperations of the component.\nFigure 11 illustrates the operational view in which an\noperation can be formalized using pre- and postconditions.\nThe precondition corresponds to the assumes clause in and\nthe postcondition corresponds to the result clause. As in the\nUML, the precondition of an operation must be true when\nthe operation is invoked and the postcondition must be true\nwhen the operation is \ufb01nished. The operation addProduct\nin Figure 11 must be in state CollectingProducts or Empty\nwhen invoked. This is also visible in the behavioral view,\nFigure 11: addProduct() Operation Speci\ufb01cation.\nsince there are only two transitions with the operation ad-\ndProduct. Both leads to the state CollectingProducts which\nis also a postcondition of the operation. The second post-\ncondition is that the cost attribute of the component must\nbe increased by the price of the added product. The pre- and\npostcondition can be expressed using the OCL. The proper-\nties of the component, states and operation parameters can\nbe used to formalise the constraints like as in this example.\nFigure 12 shows the publicly visible behaviour of the Shop-\npingCart component with states and transitions. The condi-\ntional transitions map to operations of the component. Like\nevery view, this view is also synchronized with the SUM so\nthat it is guaranteed that its operations, states and proper-\nties are consistent with those in the structural view.\nFigure 12: Speci\ufb01cation Behavioral Model.\nAlthough the operational view seems to be similar to the\nbehavioral view because of the overlapping information within\nthem, there are signi\ufb01cant di\ufb00erences. The focus of the op-\nerational view is on a precise formal de\ufb01nition of an opera-\ntion of a component. The operations can be enriched by pre-\nand postconditions which can be de\ufb01ned using complex OCL\nstatements, that formalize the complete behavior of an op-\neration. The additional information in the OCL statements\ncan be used for code generation and documentation.\n7.\nCONCLUSION\nAt the beginning of the paper we identi\ufb01ed three funda-\nmental hypothesis upon which the notion of OSM is based\n\u2014 (a) that it is feasible to integrate the many di\ufb00erent kinds\nof artifacts used in contemporary software engineering meth-\nods within a single coherent methodology in which they are\ntreated as views, (b) that it is feasible to create an e\ufb03-\ncient and scalable way of supporting these views by gener-\nating them dynamically, on-the-\ufb02y, from a Single Underly-\ning Model (SUM) using model-based transformations and\n(c) that it is feasible to provide an intuitive metaphor for\nnavigating around these many views by adapting the ortho-\ngraphic projection technique underpinning the CAD tools\nused in other engineering disciplines.\nThe prototype tool, nAOMi, described in this paper rep-\nresents the \ufb01rst step towards demonstrating the validity of\nthese hypotheses and showing that OSM is a viable approach\nto software engineering. Of the three hypotheses, (a) and (c)\nare most convincingly demonstrated by the prototype, since\nit shows that it is indeed possible to support all the views\nof the KobrA method within a single navigation metaphor.\nThe prototype tool does not demonstrate the validity of hy-\npothesis (b) to the same extent as the others due to its\nsmall size. Although it demonstrates the feasibility of gen-\nerating views from the SUM and vice-versa, the question of\nwhether such an approach scales up to large environments\nis still open.\nAlthough nOAMi is the only tool developed with the spe-\nci\ufb01c aim of supporting KobrA-based OSM, several other\ntools and methods have similar properties or aims.\nFor\nexample, Glinz et al.\n[10] describe a tool with a \ufb01sheye\nzooming algorithm which lets the user view a model with\nvarying amounts of detail depending on the context. It has\nto be investigated whether it is possible to combine the \ufb01sh-\neye zooming concept with the dimension-based navigation\nparadigm. While the KobrA 2.0 implementation of nAOMi\nheavily uses UML diagrams for developers, Glinz et al. use\ncustom diagram types, e.g.\nfor structural and behavioral\nviews.\nAn approach which also emphasizes the description of for-\nmal consistency rules (correspondences) between views is\nRM-ODP [5][6].\nHowever, this approach does not explic-\nitly mention the notion of a SUM and thus implies that\nconsistency rules should be de\ufb01ned in a pairwise fashion be-\ntween individual pairs of views. ArchiMate [7], which com-\nplements TOGAF [12], is an enterprise architecture mod-\neling language which o\ufb00ers two orthogonal \u201ddimensions\u201d for\nmodeling, (business, architecture, and technology) layers and\n(informational, behavioral and structural) aspects and also\nsuggests two more dimensions, purpose and abstraction level.\nHowever, as many of these views span multiple choices of a\nsingle\u201cdimension\u201d, the intuitive dimension-based navigation\nmetaphor of OSM can not be easily applied. There are also\nmore general approaches for view-based modeling but they\nare less speci\ufb01c in terms of consistency rules between views\nand provide little guidance on how to manage and navigate\nviews, for example the Zachman Framework [14].\nRegarding the practical use of OSM environments in the\nfuture, the biggest challenge is developing appropriate SUM\nmetamodels which can accommodate all the types of views\nand services that software engineers are accustomed to to-\nday. For this \ufb01rst prototypical SUM-based environment sup-\nporting the OSM approach we had a method at our disposal\n(KobrA) that already de\ufb01ned a full set of orthogonal UML-\nbased views. This allowed us to model the required SUM\nand view metamodels by simply adapting the UML meta-\nmodels, removing and adding model elements as needed.\nIn doing so we were able to manually ensure that the meta-\nmodels ful\ufb01lled the two core requirements of SUM-based en-\nvironments \u2014 (1) being minimalistic and (2) redundancy\nfree. If SUM-based software engineering environments are\nto take o\ufb00, and to be introduced into existing, heteroge-\nneous environments, more sophisticated ways of integrating\nexisting metamodels into a single uni\ufb01ed metamodel will be\nrequired.\n8.\nREFERENCES\n[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,\nO. Laitenberger, R. Laqua, D. Muthig, B. Paech,\nJ. W\u00a8ust, and J. Zettel. Component-Based Product Line\nEngineering with UML. Addison Wesley, Reading,\nMassachusetts, USA, 1st edition, November 2001.\n[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic\nSoftware Modeling: A Practical Approach to\nView-Based Development. In Evaluation of Novel\nApproaches to Software Engineering, volume 69 of\nCommunications in Computer and Information\nScience, pages 206\u2013219. Springer Berlin Heidelberg,\n2010.\n[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic\nService Modeling. In Proceedings of 15th IEEE EDOC\nConference Workshops (EDOCW), Helsinki, Finland,\n2011.\n[4] Eclipse Foundation. UML2Tools.\nhttp://wiki.eclipse.org/MDT-UML2Tools, 2013.\n[5] ISO/IEC and ITU-T. The Reference Model of Open\nDistributed Processing. RM-ODP, ITU-T Rec.\nX.901-X.904 / ISO/IEC 10746.\nhttp://standards.iso.org/\nittf/PubliclyAvailableStandards/index.html,\n1998.\n[6] J. I. J. Jose Raul Romero and A. Vallecillo. Realizing\nCorrespondences in MultiViewpoint Speci\ufb01cations. In\nProceedings of the Thirteenth IEEE International\nEDOC Conference, 1 - 4 September 2009, Auckland,\nNew Zealand, September 2009.\n[7] M. Lankhorst. Enterprise Architecture at Work.\nSpringer Berlin Heidelberg, 2009.\n[8] Object Management Group (OMG). OMG Uni\ufb01ed\nModeling Language (OMG UML), Superstructure,\nV2.1.2.\nhttp://www.omg.org/cgi-bin/doc?formal/07-11-02,\nNovember 2007.\n[9] Object Management Group (OMG). Meta Object\nFacility (MOF) 2.0 Query/View/Transformation, v1.0.\nhttp://www.omg.org/spec/QVT/1.0/PDF/, April 2008.\n[10] C. Seybold, M. Glinz, S. Meier, and N. Merlo-Schett.\nAn e\ufb00ective layout adaptation technique for a\ngraphical modeling tool. In Proceedings of the 2003\nInternational Conference on Software Engineering,\nPortland, 2003.\n[11] The Atlas Transformation Language (ATL). O\ufb03cial\nWebsite. http://www.eclipse.org/atl/, 2013.\n[12] The Open Group. TOGAF Version 9 - The Open\nGroup Architecture Framework.\nhttp://www.opengroup.org/architecture/\ntogaf9-doc/arch/index.html, Feb 2009.\n[13] University of Mannheim - Software Engineering\nGroup. nAOMi - opeN, Adaptable, Orthographic\nModeling EnvIronment.\nhttp://eclipselabs.org/p/naomi.\n[14] J. A. Zachman. The Zachman Framework: A Primer\nfor Enterprise Engineering and Manufacturing.\nhttp://www.zachmaninternational.com, 2009.\n",
    "pdf_url": "",
    "references": [
      "[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,",
      "O. Laitenberger, R. Laqua, D. Muthig, B. Paech,",
      "J. W\u00a8ust, and J. Zettel. Component-Based Product Line",
      "Engineering with UML. Addison Wesley, Reading,",
      "Massachusetts, USA, 1st edition, November 2001.",
      "[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic",
      "Software Modeling: A Practical Approach to",
      "View-Based Development. In Evaluation of Novel",
      "Approaches to Software Engineering, volume 69 of",
      "Communications in Computer and Information",
      "Science, pages 206\u2013219. Springer Berlin Heidelberg,",
      "2010.",
      "[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "University of Kent",
      "uage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).Addison-Wesley Professional."
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "A Prototype Implementation of an Orthographic Software Modeling Environment",
    "resume": "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
    "auteurs": [
      "Colin Atkinson",
      "Dietmar Stoll",
      "Jacques Robin",
      "Recife",
      "Brasil",
      "D.2.2"
    ],
    "institutions": [
      "Dietmar Stoll University of Mannheim, TunjicUniversity of Mannheim,",
      "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
      "Colin Atkinson University of Mannheim,"
    ],
    "mots_cles": [
      " Orthographic Software Modeling",
      " View-based Modeling "
    ],
    "texte_integral": "A Prototype Implementation of an Orthographic Software\nModeling Environment\nColin Atkinson\nUniversity of Mannheim,\nGermany\natkinson@informatik.uni-\nmannheim.de\nDietmar Stoll\nUniversity of Mannheim,\nGermany\nstoll@informatik.uni-\nmannheim.de\nChristian Tunjic\nUniversity of Mannheim,\nGermany\ntunjic@informatik.uni-\nmannheim.de\nJacques Robin\nUniversidade Federal de\nPernambuco, Recife, Brasil\njr@cin.ufpe.br\nABSTRACT\nOrthographic Software Modeling (OSM) is a view-centric\nsoftware engineering approach that aims to leverage the or-\nthographic projection metaphor used in the visualization of\nphysical objects to visualize software systems. Although the\ngeneral concept of OSM does not prescribe speci\ufb01c sets of\nviews, a concrete OSM environment has to be speci\ufb01c about\nthe particular views to be used in a particular project. At\nthe University of Mannheim we are developing a prototype\nOSM environment, nAOMi, that supports the views de\ufb01ned\nby the KobrA 2.0 method, a version of KobrA adapted for\nOSM. In this paper we provide an overview of the KobrA 2.0\nmetamodel underpinning nAOMi and give a small example\nof its use to model a software system.\nCategories and Subject Descriptors\nD.1.7 [Programming Techniques]: Visual Programming;\nD.2.2 [Design Tools and Techniques]: Computer-aided\nsoftware engineering (CASE); D.2.6 [Software Engineer-\ning]: Programming Environments\u2014Graphical environments\nKeywords\nOrthographic Software Modeling, View-based Modeling\n1.\nINTRODUCTION\nOrthographic Software Modeling (OSM) is based on three\nfundamental hypotheses \u2014 (a) that it is feasible to inte-\ngrate the many di\ufb00erent kinds of artifacts used in contempo-\nrary software engineering methods within a single coherent\nmethodology in which they are treated as views, (b) that it\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for pro\ufb01t or commercial advantage and that copies\nbear this notice and the full citation on the \ufb01rst page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior speci\ufb01c\npermission and/or a fee.\nVAO \u201913, July 2, 2013, Montpellier, France\nCopyright 2013 ACM 978-1-4503-2041-2 ...$15.00.\nis feasible to create an e\ufb03cient and scalable way of support-\ning these views by generating them dynamically, on-the-\ufb02y,\nfrom a Single Underlying Model (SUM) using model-based\ntransformations and (c) that it is feasible to provide an in-\ntuitive metaphor for navigating around these many views\nby adapting the orthographic projection technique under-\npinning the CAD tools used in other engineering disciplines.\nFigure 1: Orthographic Projection.\nAs shown in Figure 1, the main advantages of using the\nidea of orthographic projection to de\ufb01ne the views used\nto visualize and described a system are that they (a) can\nbe organized according to a simple and easy-to-understand\nmetaphor and (b) collectively represent all the properties of\na system with minimal overlap and redundancy. In practice\nthis translates into a set of \u201cdimensions\u201d, each containing\nwell de\ufb01ned choices (or so called \u201cdimension elements\u201d) that\ncan be used to select individuals views.\nAs shown in Figure 2, the main advantage of making the\nartifacts used to describe a software system views of a SUM\nis that the number of pairwise coherence relationships that\nhave to be maintained is reduced and new views can be in-\ntroduced by simply de\ufb01ning their relationship to the SUM.\nMoreover, the importance of this advantage grows quickly\nas the size of the system and the complexity of the deployed\ndevelopment methodology increase. Another important ad-\nvantage is that the dominance of one particular kind of view\nover the development process (e.g. code) at the expense of\nother kinds of views (e.g. graphical models) is reduced so\nthat any appropriate type of views can be used to enrich\nthe underlying description of the system, depending on the\nneeds and skills of the stakeholder involved. This makes it\npossible to subsume all view types under the same, overarch-\nSUM\nSUM / View Centric Environment\nArtifact / Tools Centric Environment\nFigure 2: Consistency Dependencies in Artifact-oriented versus View-oriented Environments.\ning development process and methodology (e.g. agile-driven,\nfocusing on small development cycles, or model-driven de-\nvelopment, based on transformations between abstraction\nlevels). Although the details of how the views are created\nfrom the SUM and how the SUM is updated from the views\nare not central to the approach, a natural implementation\nis to use the visualization and transformation technologies\no\ufb00ered by model driven software engineering (MDSE).\nTo explore the validity of these hypotheses at the Uni-\nversity of Mannheim we have been developing a prototype\nOSM modeling environment based on an enhanced version\nof the KobrA method for model-driven, component-oriented\ndevelopment, KobrA 2.0 [1]. This was chosen as a basis for\nthe prototype, known as the Open, Adaptable, Orthographic\nModeling Environment (nAOMi) [13] because its views were\ndesigned with the precise goals of being (a) genuine pro-\njections of a subject containing carefully selected subsets\nof information about that subject, (b) minimalistic in the\nsense that they should overlap to the smallest extent possible\nand contain the minimum necessary models elements, and\n(c) selectable via a set of independent \u201cdimensions\u201d which\nre\ufb02ect di\ufb00erent fundamental concerns of development (i.e.\nabstraction levels, composition or variants). In other words,\nKobrA already provided one of the \u201cmost orthogonal\u201d sets\nof views for visualizing software systems of any contempo-\nrary method. More details about the actual views and di-\nmensions de\ufb01ned in KobrA are presented in the following\nsections. More information on OSM can be found in [2] and\n[3].\nnAOMi is implemented as an Eclipse plugin using the\nEclipse Modeling Framework (EMF) as the underlying mod-\neling platform and UML 2.0 tools [4] to generate and edit\nviews.\nThe KobrA 2.0 metamodel on which the current\nversion of nAOMi is based is a specialization of the UML\nmetamodel composed of three separate packages \u2014 one for\nthe SUM, one for the views and one for the transformations\n(Figure 3). The UML was chosen as the base language be-\ncause of its maturity and widespread acceptance, making the\nenvironment usable to the largest possible body of develop-\ners. UML elements not needed in KobrA 2.0 are excluded\nusing OCL constraints while new elements or properties are\nKobrA2\nTransformation\nSUM\nViews\nFigure 3: KobrA 2.0 Top Level Packages.\nintroduced by specializing existing elements.\nThe unique contribution of this paper is to elaborate on\nthe structure of the KobrA 2.0 metamodel and how it is used\nto drive nAOMi. The three following sections each focus on\none of the three main components of the metamodel \u2014 the\nSUM, the views and the transformations . This is followed\nby a brief overview of the OSM navigation paradigm in Sec-\ntion 5 before a small example of the approach is presented in\nSection 6. Section 7 then concludes the paper with related\nand future work.\n2.\nSUM PACKAGE\nFigure 4 depicts the internal structure of the SUM pack-\nage which is based on the UML metamodel. There are three\nmain subpackages, two containing the structural and behav-\nioral constructs respectively, and one containing the con-\nstraints that ensure that the metaclasses are used according\nto the KobrA conventions and rules.\nThe Classes subpackage of the Structure package contains\nsome of the most fundamental elements of the KobrA meta-\nmodel, such as Class and ComponentClass.\nThe internal\nstructure of this package is illustrated in Figure 5. Com-\nponentClass represents objects with complex and reusable\nbehaviors, while Class captures simple \u201cdata type\u201d objects\nthat have only very simple or non-reusable behaviors. The\nmodeler has to decide whether it is necessary to model a\nspeci\ufb01c part of the system as a ComponentClass and include\nstate charts and activity diagrams, or whether it is su\ufb03cient\nto use a Class (which is limited to using OCL constraints).\nComponentClass inherits (indirectly via Class) from Com-\nmunications so it also has the isActive attribute. This makes\nKobrA2::SUM::Constraint::Behavioral\nKobrA2::SUM::Constraint::Structural\nKobrA2::SUM::Constraint\nKobrA2::SUM::Constraint::Common\nKobrA2::SUM::Behavior::ProtocolStateMachines\nKobrA2::SUM::Behavior::Common\nKobrA2::SUM::Behavior::Activities\nKobrA2::SUM::Behavior::Actions\nKobrA2::SUM::Behavior\nKobrA2::SUM::Structure::Classes\nKobrA2::SUM::Structure::Types\nKobrA2::SUM::Structure::Instances\nKobrA2::SUM::Structure::Elements\nKobrA2::SUM::Structure\nKobrA2::SUM::Constraint::OclExpressions\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\nFigure 4: KobrA 2.0 SUM Package.\nit possible to model whether its instances are active or pas-\nsive. Active objects, which can be used to model threads and\nprocesses ([8] p. 438), start to execute their behavior as soon\nas they are created and perform operations spontaneously.\nA ComponentClass may exhibit complex behavior. In Ko-\nbrA, this behavior may be speci\ufb01ed in the form of\nUML\nState Diagrams (de\ufb01ning acceptable operation invocation\nsequences), and in the form of Activities (de\ufb01ning algorithms\nof operations). UML Interaction elements (in sequence dia-\ngrams) can be derived from the activity elements and thus\nare not included in the SUM. As KobrA aims to facilitate\nautomatic checking of allowed sequences of operation calls,\nProtocol State Machines are supported instead of general\nstate machines. Since the latter include a large variety of\nelements not needed for specifying acceptable operation se-\nquences or automatic checking, OCL constraints are used to\nprohibit the use of unwanted features.\ncontext\nComponentClass\n-- only\nallow\nActivity\nelements\nor\nProtocolStateMachines\ninv: ownedBehavior ->forAll( oclIsKindOf( Actitivity) or\noclIsKindOf ( ProtocolStateMachine ))\nFor example, since KobrA has no concept of roles for com-\nponents, the use of role also needs to be prohibited. The part\nassociation refers to owned properties of components whose\nattribute isComposite is true. As KobrA uses associations\nlike nests and creates for components, part, required and\nprovided are not needed. Connectors (i.e. delegation and\nassembly) are not used in KobrA either so ownedConnector\nis excluded.\nClass\nKobrA2::SUM::Structure::Classes\nGeneralizationSet\nAssociationClass\nComponentClass\nProperty\nUsage\nAssociation\nOperation\nPackageable\nElement\nParameter\nAcquires\nCreates\nNests\nUML::Component::PackagingComponents::Component\nUML::CommonBehaviors::Communications::Class\n+ownedOperation\n*\n+class\n0..1\n+supplier\n1..*\n{subsets supplierDependency}\n+supplierUsage\n*\n+client\n1..*\n{subsets clientDependency}\n+clientUsage\n*\n+ownedAttribute\n*\n+class\n0..1\n+powertype\n0..1\n+powertypeExtent\n*\n+packagedElement\n*\n{subsets component}\n+componentClass\n0..1\n+/superClass\nFigure 5: KobrA 2.0 Classes Package.\ncontext\nComponentClass\ninv: role ->union(part)->union( ownedConnector )\n->union( collaborationUse )-> union( representation )\n->union( realization)->union(required)\n->union(provided)->isEmpty ()\n3.\nVIEWS PACKAGE\nThe structure of the Views package is illustrated in Figure\n6. Again, since most of the views de\ufb01ned in KobrA 2.0 are\nbased on UML diagrams, the view metamodels have similar\nelements to the SUM metamodel. The big di\ufb00erence to the\nSUM is that there are no restrictions on the use of the view\nmetamodel elements.\nFor instance, views for a particular\npurpose such as supporting model checkers can be supported\nby adding elements unrelated to the UML.\nThe substructure of the Views package re\ufb02ects the types\nand organization of the KobrA views according to the view\n\u201cdimensions\u201d supported in nAOMi (cf. example in Section\n6). At the top level, the Views package is thus decomposed\ninto the Speci\ufb01cation and Realization options of the encap-\nsulation dimension.\nThese, in turn are both decomposed\ninto the Structural, Behavioral and Operational options of\nthe Projection dimension.\nFinally, with the exception of\nthe behavioral option, these are also all subdivided into the\nService and Type options of the granularity dimension. This\ndimension, with its two options, is an addition to the original\nversion of KobrA.\nThe Service view shows the direct, publicly visible rela-\ntionships of the subject ComponentClass to other Compo-\nnentClasses, while the Type view shows the publicly visi-\nble relationships of the subject to simple Classes. As with\nthe SUM, constraints have been de\ufb01ned to control what can\ngo into each view and when they are well formed. For ev-\nery view, a constraint enumerates all allowed elements (not\nshown in this paper).\nIn the following, some of the other constraints for the\nService view are elaborated. Since this view is a black-box\nview, the internals of ComponentClasses (nestedClassi\ufb01er)\nare not shown.\ncontext\nComponentClass\n-- no nested\nclassifiers , no\nprotocol\ninv: nestedClassifier ->union(protocol)->isEmpty ()\nClasses are only allowed if they are generalizations of Com-\nponentClasses, (or any of its superclasses, since a Compo-\nnentClass may inherit from a class as shown in the con-\nstraints with context Class. The following invariants ensure\nthat only publicly visible attributes and operations are in\nthis view, for both classes and ComponentClasses (which\ninherit from Class).\nClass\nService\nType\nInstance\nService\nType\nStructural\nSpecification\nOperational\nService\nType\nProtocol\nBehavioral\nKobrA2::Views::Derived\nComponentClassDependencies\nOperationDependencies\nInstance\nService\nType\nClass\nService\nType\nStructural\nRealization\nOperational\nService\nType\nBehavioral\nAlgorithm\nViews\nConcreteSyntax\nSubject\n<<import>>\n<<merge>>\n<<merge>>\n<<import>>\n<<merge>>\n<<import>>\nFigure 6: KobrA 2.0 Views package nesting.\ncontext\nClass\n-- only\nallow\nclasses\nthat\nare\ndirect or\nindirect\ngeneralizations\nof\nComponentClasses\nin this\nview\ndef: ccGeneralization : generalization .specific ->\nexists( oclIsKindOf ( ComponentClass ))\ninv:\ngeneralization .specific ->select( oclIsTypeOf (\nClass))->exists(s|s. ccGeneralization )\nor\nccGeneralization\n-- only\npublic\nattributes\nin this\nview\ninv: ownedAttribute ->forAll(visibility =# public)\n-- only\npublic\nOperations\nare\nallowed\nin the\nspecification\ninv: ownedOperation ->forAll(visibility =# public)\nOnly operation signatures are shown in this view, so pre-,\npost- and bodyconditions, as well as activities are omitted,\nwhich is re\ufb02ected in the last constraint.\ncontext\nOperation\n-- only\nthe\nsignature\nof the\nOperation\nis shown , not\nits\nbehavior (role\nname \"method\" refers to the\nActivities\nof the\noperation), or\ndependencies\ninv: method ->union( precondition )->union(body)->union(\npostcondition )->isEmpty ()\n4.\nTRANSFORMATIONS PACKAGE\nThe package AllViews provides the foundation for speci-\nfying the transformations between the SUM and the views\nin both directions. Part of the package\u2019s contents are shown\nin Figure 7.\nThe Abstraction concept (which is in fact a\nKobrA2::Transformation::Common::AllViews\nAbstraction\nTransformationExpression\nViewElement\nSumElement\nView\nKobrA2::SUM::Structure::Elements::Element\nKobrA2::Views::ConcreteSyntax::Element\nKobrA2::SUM::Constraint::Behavioral::Exp\nressionInOcl\nKobrA2::Views::Subject::View\n{subsets mapping}\n0..1\n0..1\n{subsets clientDependency}\n+abstraction 1\n{subsets client}\n+ve 1\n1..*\n1\n{subsets supplier}\n+se 1\n{subsets supplierDependency}\n+abstraction 1..*\nFigure 7: Transformation abstractions.\ndependency reused from the UML but with additional con-\nstraints) plays the key role in relating elements from the\nSUM to elements of a view. Abstraction is actually mapped\nto ExpressionInOcl.\nWhen appearing in transformations,\nthe equals sign links elements in the SUM to the respective\nelements in the view, and vice versa. For instance, equal-\nity of the general meta-association of a Generalization in\na transformation invariant means that, when following gen-\neral, there must be an element in the SUM and in the view\nfor which similar transformation expressions are speci\ufb01ed.\nIn the case of KobrA 2.0, which has many projections that\njust select a subset of elements using one-to-one abstrac-\ntions, this allows concise declarative TransformationExpres-\nsions. Together with the view constraints, a CASE tool can\nbe implemented which uses a transformation language of the\nimplementor\u2019s choice, for instance the Atlas Transformation\nLanguage (ATL) [11] or QVT [9]. The role names se and ve\nare short for SumElement and ViewElement, respectively.\nThese roles subset the client and supplier roles from the\nUML.\nSUM elements are translated into UML elements with\nstereotypes, so that the views are easy to manage for de-\nvelopers familiar with the UML. The bidirectional mappings\nbetween stereotyped view elements and non-stereotyped SUM\nelements are expressed in the constraints of the Association-\nAbstraction, a subclass of the Abstraction from the AllViews\npackage. This is also an example of a transformation which\nis reused in other views.\ncontext\nAssociationAbstraction\ninv: ve.memberEnd = se.memberEnd\ninv: ve.ownedEnd = se.ownedEnd\nivn: ve. navigableOwnedEnd = se. navigableOwnedEnd\ninv: se. oclIsKindOf(Acquires) implies ve.\nhasStereotype (\u2019acquires \u2019)\ninv: ve. hasStereotype (\u2019acquires \u2019)\nimplies\nse.\noclIsKindOf (Aquires)\ninv: se. oclIsKindOf(Nests) implies\nve. hasStereotype (\u2019\nnests \u2019)\ninv: ve. hasStereotype (\u2019nests \u2019)\nimplies se. oclIsKindOf\n(Nests)\ninv: se. oclIsKindOf (Creates) implies\nve. hasStereotype\n(\u2019creates \u2019)\ninv: ve. hasStereotype (\u2019creates \u2019)\nimplies se.\noclIsKindOf (Creates)\nFigure 8 shows the main elements involved in the trans-\nformation of the black box structural view for Component-\nClasses. The \ufb01rst transformation constraint is on the view\nand declares the starting point for the transformation. It\nstates that the subject ComponentClass and its generaliza-\ntions (using a SUM utility function, superClosure) are in the\nview.\nThe following transformation rules illustrate how to create\nthe output (i.e. view) elements from the input (i.e. SUM) el-\nements, such as the publicly visible attributes and operations\nof the ComponentClass and the acquired ComponentClasses.\nThe \ufb01rst constraint for ComponentClassAbstraction states\nthat references to potential general classes (and Component-\nClasses) of ComponentClasses are mirrored in the view. In\naddition, ComponentClasses will be shown with the corre-\nsponding stereotypes.\nThe ComponentClass owns various\ntypes of associations, so in this view only the acquires asso-\nciations are selected (whose transformation rules are cov-\nered in the common transformation packages).For classes\nand ComponentClasses, only publicly visible attributes and\noperations appear in the view.\nClass invariants are also\ncopied. Classes that may appear in this view (e.g. as gener-\nalizations of ComponentClasses) may have a powertype (role\nname powertypeExtent) which will be displayed.\nThe last transformation statement copies the class refer-\nences of operations. As with all views, the transformation\nrules, the common transformation statements (which also\ncover operations) and the view constraints serve as a speci-\n\ufb01cation for the implementation of a view. Individual CASE\ntools can use di\ufb00erent implementation techniques as long as\nthey conform to the semantics of these rules and constraints.\nKobrA2::Transformation::Specification::Structural::Class::Service\nComponentClassAbstraction\nKobrA2::Transformation::Common::Feature::OperationAbstraction\nKobrA2::Transformation::Common::AllViews::Abstraction\nKobrA2::SUM::Structure::Classes::ComponentClass\nKobrA2::SUM::Structure::Classes::Operation\nKobrA2::SUM::Structure::Classes::Class\nOperationAbstraction\nClassAbstraction\n+se\n1\n1..*\n+se\n1\n1..*\n+se\n1\n1..*\nFigure 8: Transformation to the Speci\ufb01cation Structural Service View.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassService\ninv: ownedMember ->select( oclIsKindOf(Class)) =\nsubject.superClosure ->union(subject.acquires.\nsuperClosure )\ncontext\nComponentClassAbstraction\ninv: ve.superClass = se. superClass\ninv: ve. hasStereotype (\u2019ComponentClass \u2019)\ninv: se.isSubject\nimplies (ve. hasStereotype (\u2019subject\n\u2019) and ve.ownedMember ->select( oclIsKindOf (\nAssociation )) = se.ownedMember ->select(\noclIsKindOf (Acquires)))\ncontext\nClassAbstraction\ninv: ve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\ninv: ve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public)\ninv: ve.\u2018inv \u2019 = se.\u2018inv \u2019\n-- copy\npowertypeExtent\nthat is only\nallowed\nfor\nclass\ninv: ve. powertypeExtent = se. powertypeExtent\ncontext\nOperationAbstraction\ninv: ve.class = se.class\nFor the black box type view, only publicly visible at-\ntributes and operations of classes (as opposed to Compo-\nnentClasses) used by the subject can be seen. This is spec-\ni\ufb01ed in the \ufb01rst rule which de\ufb01nes owned members of the\nview and thus serves as the starting point of the transfor-\nmation. cbbTypes is a utility function de\ufb01ned in the SUM\nwhich computes the black box types by selecting the types\nof the subject\u2019s public attributes and parameter types of its\npublic operations.\nClass invariants and potential powertypes and connections\nto the classes in this view are shown as well. There may\nalso be Enumerations, for which the EnumerationLiterals\nare displayed.\nThe transformation rules for this view are almost the same\nas the realization transformation constraints from the pack-\nage Transformation::Realization::Structural::Class::Type. The\ndi\ufb00erences are the select(visibility=#public) statements for\noperations and attributes.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassType\ninv: ownedMember ->select( oclIsKindOf(Class) or\noclIsKindOf(\u2018Enumeration \u2019) or\noclIsKindOf (\nAssociation)) = subject ->union(subject.cbbTypes)\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nClassAbstraction\ninv: not se.oclIsKindOf ( ComponentClass ) implies (\nve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\nve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public))\ninv: ve. powertypeExtent = se. powertypeExtent\ninv: ve. superClass = se.superClass\ninv: \u2018ve.inv \u2019 = \u2018se.inv \u2019\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nEnumerationAbstraction\ninv: ve. ownedLiteral = se. ownedLiteral\ncontext\nEnumerationLiteralAbstraction\ninv: ve. specification = se. specification .\nstringInSignature\n5.\nNAVIGATION\nMost of today\u2019s tools use some combination of trees to\norganize the content of models as well as the views used to\nvisualize a software system or component. In an any envi-\nronment incorporating a number of di\ufb00erent tools there is\ninvariably a large number of di\ufb00erent trees storing a het-\nerogeneous mix of artifacts including model elements (e.g.\nclasses, instances, associations), diagrams (e.g.\nclass dia-\ngrams, state diagrams) and other artifact types (source code,\nXML \ufb01les, con\ufb01guration \ufb01les ). To work with all the views in\na traditional development environment, therefore, engineers\ntypically have to learn about the organization structures of\nall the incorporated tools.\nIn contrast to conventional paradigms for organizing and\nnavigating the many views used to visualize a system, OSM\nemploys the metaphor of a multi-dimensional cube. More\nspeci\ufb01cally, as illustrated in Figure 9, OSM regards dimen-\nsion of the underlying methodology as representing a di\ufb00er-\nent dimension of the cube, and each independently variable\naspect of that dimension is a selectable dimension element.\nSelecting a view thus simply corresponds to selecting a single\ncell within the cube. In general, three types of dimensions\nare supported: static dimensions in which the number of\nFigure 9: Dimension-based navigation.\nselectable elements (i.e. coordinates) is \ufb01xed, dynamic di-\nmensions in which the number of elements is dynamic (i.e.\nderived from the SUM), and mixed dimensions which have\nboth static and dynamic elements.\nTo support the OSM dimension based navigation metaphor\nfor KobrA, we de\ufb01ned the seven dimensions indicated on the\nleft hand side of Figure 10 which is a sceenshot of nAOMI.\nThe Abstraction dimension (not expanded here), which has\nthree static dimension elements, PIM (platform independent\nmodel), PSM (platform speci\ufb01c model) and Code, captures\nthe model-driven development concern of KobrA. The ver-\nsion dimension captures the state of the modeled system at\nspeci\ufb01c points in time. The Component dimension, which\nhas dynamic dimension elements de\ufb01ned by instances of the\nclass ComponentClass in the SUM, captures the component-\nbased development concern of KobrA.\nThe Encapsulation dimension, which has two \ufb01xed ele-\nments, supports the distinction between Speci\ufb01cation (black\nbox) and Realization (white box) views of components, while\nthe Projection dimension with the \ufb01xed elements Structural,\nOperational and Behavioral covers the di\ufb00erent information\ntypes. The Granularity dimension provides a \ufb01ner grained\ndistinction between views describing the types used by com-\nponents (Type granularity) and views describing the required\nand provided interfaces (Service granularity). The Opera-\ntion dimension allows a selection of individual operations.\nIn the ideal case, when all views are truly orthogonal, the\nchoices that can be made in each dimensions are completely\nindependent.\nHowever, this is very di\ufb03cult to achieve in\nsoftware engineering. The approach still works if the views\nare not completely orthogonal, but dependencies then occur\nbetween di\ufb00erent choices in di\ufb00erent dimensions, so that the\ndecisions made in one dimensions may a\ufb00ect choices possi-\nble in another dimension. This is best handled by giving\ndimensions a precedence ranking determined by the order\nin which they appear (the top being the highest). When an\nelement in a dimension is selected, the tool automatically\nmakes default selections for dimensions of lower precedence\n(i.e.\ndimensions lower down) and disables selections that\nwould navigate to cells (i.e. views) which are not (yet) de-\n\ufb01ned by the method at hand.\n6.\nSHOPPING CART EXAMPLE\nTo show how a software system can be speci\ufb01ed using\nnAOMi, this section presents a case study based on a shop-\nping cart system. A ShoppingCart component collects and\nFigure 10: Speci\ufb01cation Structural View.\nmanages the products selected by users and supports pay-\nment via a credit card.\nFigure 10 illustrates a structural\nview of the component.\nIn the dimension navigator on the left hand side, PIM\nwas chosen for the \u201cAbstraction Level\u201d (not expanded in the\nscreenshot). The second dimension is the state of the soft-\nware system at a certain point in time. The picture shows\nthat the latest available version was chosen. As with every\nchoice in a dimension, it may in\ufb02uence the options in lower\nranked dimensions. The component under consideration is\nthe ShoppingCart, for which a black box view is selected\nin the next dimension. After the user selects the structural\nprojection option and the service level granularity, the tool\nautomatically chooses the option for all operations in the\nlast dimension, as there is no editor registered for the other\noptions.\nThe component under development is presented with the\nstereotype subject and its relationship to other components\nand classes is shown in the view, which corresponds to a cell\nof the multi-dimensional navigation cube, and is generated\non-the-\ufb02y from the SUM when it is selected. The classes\nProduct and CreditCard can be used as data types in the\noperations of the component.\nFigure 11 illustrates the operational view in which an\noperation can be formalized using pre- and postconditions.\nThe precondition corresponds to the assumes clause in and\nthe postcondition corresponds to the result clause. As in the\nUML, the precondition of an operation must be true when\nthe operation is invoked and the postcondition must be true\nwhen the operation is \ufb01nished. The operation addProduct\nin Figure 11 must be in state CollectingProducts or Empty\nwhen invoked. This is also visible in the behavioral view,\nFigure 11: addProduct() Operation Speci\ufb01cation.\nsince there are only two transitions with the operation ad-\ndProduct. Both leads to the state CollectingProducts which\nis also a postcondition of the operation. The second post-\ncondition is that the cost attribute of the component must\nbe increased by the price of the added product. The pre- and\npostcondition can be expressed using the OCL. The proper-\nties of the component, states and operation parameters can\nbe used to formalise the constraints like as in this example.\nFigure 12 shows the publicly visible behaviour of the Shop-\npingCart component with states and transitions. The condi-\ntional transitions map to operations of the component. Like\nevery view, this view is also synchronized with the SUM so\nthat it is guaranteed that its operations, states and proper-\nties are consistent with those in the structural view.\nFigure 12: Speci\ufb01cation Behavioral Model.\nAlthough the operational view seems to be similar to the\nbehavioral view because of the overlapping information within\nthem, there are signi\ufb01cant di\ufb00erences. The focus of the op-\nerational view is on a precise formal de\ufb01nition of an opera-\ntion of a component. The operations can be enriched by pre-\nand postconditions which can be de\ufb01ned using complex OCL\nstatements, that formalize the complete behavior of an op-\neration. The additional information in the OCL statements\ncan be used for code generation and documentation.\n7.\nCONCLUSION\nAt the beginning of the paper we identi\ufb01ed three funda-\nmental hypothesis upon which the notion of OSM is based\n\u2014 (a) that it is feasible to integrate the many di\ufb00erent kinds\nof artifacts used in contemporary software engineering meth-\nods within a single coherent methodology in which they are\ntreated as views, (b) that it is feasible to create an e\ufb03-\ncient and scalable way of supporting these views by gener-\nating them dynamically, on-the-\ufb02y, from a Single Underly-\ning Model (SUM) using model-based transformations and\n(c) that it is feasible to provide an intuitive metaphor for\nnavigating around these many views by adapting the ortho-\ngraphic projection technique underpinning the CAD tools\nused in other engineering disciplines.\nThe prototype tool, nAOMi, described in this paper rep-\nresents the \ufb01rst step towards demonstrating the validity of\nthese hypotheses and showing that OSM is a viable approach\nto software engineering. Of the three hypotheses, (a) and (c)\nare most convincingly demonstrated by the prototype, since\nit shows that it is indeed possible to support all the views\nof the KobrA method within a single navigation metaphor.\nThe prototype tool does not demonstrate the validity of hy-\npothesis (b) to the same extent as the others due to its\nsmall size. Although it demonstrates the feasibility of gen-\nerating views from the SUM and vice-versa, the question of\nwhether such an approach scales up to large environments\nis still open.\nAlthough nOAMi is the only tool developed with the spe-\nci\ufb01c aim of supporting KobrA-based OSM, several other\ntools and methods have similar properties or aims.\nFor\nexample, Glinz et al.\n[10] describe a tool with a \ufb01sheye\nzooming algorithm which lets the user view a model with\nvarying amounts of detail depending on the context. It has\nto be investigated whether it is possible to combine the \ufb01sh-\neye zooming concept with the dimension-based navigation\nparadigm. While the KobrA 2.0 implementation of nAOMi\nheavily uses UML diagrams for developers, Glinz et al. use\ncustom diagram types, e.g.\nfor structural and behavioral\nviews.\nAn approach which also emphasizes the description of for-\nmal consistency rules (correspondences) between views is\nRM-ODP [5][6].\nHowever, this approach does not explic-\nitly mention the notion of a SUM and thus implies that\nconsistency rules should be de\ufb01ned in a pairwise fashion be-\ntween individual pairs of views. ArchiMate [7], which com-\nplements TOGAF [12], is an enterprise architecture mod-\neling language which o\ufb00ers two orthogonal \u201ddimensions\u201d for\nmodeling, (business, architecture, and technology) layers and\n(informational, behavioral and structural) aspects and also\nsuggests two more dimensions, purpose and abstraction level.\nHowever, as many of these views span multiple choices of a\nsingle\u201cdimension\u201d, the intuitive dimension-based navigation\nmetaphor of OSM can not be easily applied. There are also\nmore general approaches for view-based modeling but they\nare less speci\ufb01c in terms of consistency rules between views\nand provide little guidance on how to manage and navigate\nviews, for example the Zachman Framework [14].\nRegarding the practical use of OSM environments in the\nfuture, the biggest challenge is developing appropriate SUM\nmetamodels which can accommodate all the types of views\nand services that software engineers are accustomed to to-\nday. For this \ufb01rst prototypical SUM-based environment sup-\nporting the OSM approach we had a method at our disposal\n(KobrA) that already de\ufb01ned a full set of orthogonal UML-\nbased views. This allowed us to model the required SUM\nand view metamodels by simply adapting the UML meta-\nmodels, removing and adding model elements as needed.\nIn doing so we were able to manually ensure that the meta-\nmodels ful\ufb01lled the two core requirements of SUM-based en-\nvironments \u2014 (1) being minimalistic and (2) redundancy\nfree. If SUM-based software engineering environments are\nto take o\ufb00, and to be introduced into existing, heteroge-\nneous environments, more sophisticated ways of integrating\nexisting metamodels into a single uni\ufb01ed metamodel will be\nrequired.\n8.\nREFERENCES\n[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,\nO. Laitenberger, R. Laqua, D. Muthig, B. Paech,\nJ. W\u00a8ust, and J. Zettel. Component-Based Product Line\nEngineering with UML. Addison Wesley, Reading,\nMassachusetts, USA, 1st edition, November 2001.\n[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic\nSoftware Modeling: A Practical Approach to\nView-Based Development. In Evaluation of Novel\nApproaches to Software Engineering, volume 69 of\nCommunications in Computer and Information\nScience, pages 206\u2013219. Springer Berlin Heidelberg,\n2010.\n[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic\nService Modeling. In Proceedings of 15th IEEE EDOC\nConference Workshops (EDOCW), Helsinki, Finland,\n2011.\n[4] Eclipse Foundation. UML2Tools.\nhttp://wiki.eclipse.org/MDT-UML2Tools, 2013.\n[5] ISO/IEC and ITU-T. The Reference Model of Open\nDistributed Processing. RM-ODP, ITU-T Rec.\nX.901-X.904 / ISO/IEC 10746.\nhttp://standards.iso.org/\nittf/PubliclyAvailableStandards/index.html,\n1998.\n[6] J. I. J. Jose Raul Romero and A. Vallecillo. Realizing\nCorrespondences in MultiViewpoint Speci\ufb01cations. In\nProceedings of the Thirteenth IEEE International\nEDOC Conference, 1 - 4 September 2009, Auckland,\nNew Zealand, September 2009.\n[7] M. Lankhorst. Enterprise Architecture at Work.\nSpringer Berlin Heidelberg, 2009.\n[8] Object Management Group (OMG). OMG Uni\ufb01ed\nModeling Language (OMG UML), Superstructure,\nV2.1.2.\nhttp://www.omg.org/cgi-bin/doc?formal/07-11-02,\nNovember 2007.\n[9] Object Management Group (OMG). Meta Object\nFacility (MOF) 2.0 Query/View/Transformation, v1.0.\nhttp://www.omg.org/spec/QVT/1.0/PDF/, April 2008.\n[10] C. Seybold, M. Glinz, S. Meier, and N. Merlo-Schett.\nAn e\ufb00ective layout adaptation technique for a\ngraphical modeling tool. In Proceedings of the 2003\nInternational Conference on Software Engineering,\nPortland, 2003.\n[11] The Atlas Transformation Language (ATL). O\ufb03cial\nWebsite. http://www.eclipse.org/atl/, 2013.\n[12] The Open Group. TOGAF Version 9 - The Open\nGroup Architecture Framework.\nhttp://www.opengroup.org/architecture/\ntogaf9-doc/arch/index.html, Feb 2009.\n[13] University of Mannheim - Software Engineering\nGroup. nAOMi - opeN, Adaptable, Orthographic\nModeling EnvIronment.\nhttp://eclipselabs.org/p/naomi.\n[14] J. A. Zachman. The Zachman Framework: A Primer\nfor Enterprise Engineering and Manufacturing.\nhttp://www.zachmaninternational.com, 2009.\n",
    "pdf_url": "",
    "references": [
      "[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,",
      "O. Laitenberger, R. Laqua, D. Muthig, B. Paech,",
      "J. W\u00a8ust, and J. Zettel. Component-Based Product Line",
      "Engineering with UML. Addison Wesley, Reading,",
      "Massachusetts, USA, 1st edition, November 2001.",
      "[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic",
      "Software Modeling: A Practical Approach to",
      "View-Based Development. In Evaluation of Novel",
      "Approaches to Software Engineering, volume 69 of",
      "Communications in Computer and Information",
      "Science, pages 206\u2013219. Springer Berlin Heidelberg,",
      "2010.",
      "[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "University of Kent",
      "uage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).Addison-Wesley Professional."
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "A Prototype Implementation of an Orthographic Software Modeling Environment",
    "resume": "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
    "auteurs": [
      "Colin Atkinson",
      "Dietmar Stoll",
      "Jacques Robin",
      "Recife",
      "Brasil",
      "D.2.2"
    ],
    "institutions": [
      "Dietmar Stoll University of Mannheim, TunjicUniversity of Mannheim,",
      "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
      "Colin Atkinson University of Mannheim,"
    ],
    "mots_cles": [
      " Orthographic Software Modeling",
      " View-based Modeling "
    ],
    "texte_integral": "A Prototype Implementation of an Orthographic Software\nModeling Environment\nColin Atkinson\nUniversity of Mannheim,\nGermany\natkinson@informatik.uni-\nmannheim.de\nDietmar Stoll\nUniversity of Mannheim,\nGermany\nstoll@informatik.uni-\nmannheim.de\nChristian Tunjic\nUniversity of Mannheim,\nGermany\ntunjic@informatik.uni-\nmannheim.de\nJacques Robin\nUniversidade Federal de\nPernambuco, Recife, Brasil\njr@cin.ufpe.br\nABSTRACT\nOrthographic Software Modeling (OSM) is a view-centric\nsoftware engineering approach that aims to leverage the or-\nthographic projection metaphor used in the visualization of\nphysical objects to visualize software systems. Although the\ngeneral concept of OSM does not prescribe speci\ufb01c sets of\nviews, a concrete OSM environment has to be speci\ufb01c about\nthe particular views to be used in a particular project. At\nthe University of Mannheim we are developing a prototype\nOSM environment, nAOMi, that supports the views de\ufb01ned\nby the KobrA 2.0 method, a version of KobrA adapted for\nOSM. In this paper we provide an overview of the KobrA 2.0\nmetamodel underpinning nAOMi and give a small example\nof its use to model a software system.\nCategories and Subject Descriptors\nD.1.7 [Programming Techniques]: Visual Programming;\nD.2.2 [Design Tools and Techniques]: Computer-aided\nsoftware engineering (CASE); D.2.6 [Software Engineer-\ning]: Programming Environments\u2014Graphical environments\nKeywords\nOrthographic Software Modeling, View-based Modeling\n1.\nINTRODUCTION\nOrthographic Software Modeling (OSM) is based on three\nfundamental hypotheses \u2014 (a) that it is feasible to inte-\ngrate the many di\ufb00erent kinds of artifacts used in contempo-\nrary software engineering methods within a single coherent\nmethodology in which they are treated as views, (b) that it\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for pro\ufb01t or commercial advantage and that copies\nbear this notice and the full citation on the \ufb01rst page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior speci\ufb01c\npermission and/or a fee.\nVAO \u201913, July 2, 2013, Montpellier, France\nCopyright 2013 ACM 978-1-4503-2041-2 ...$15.00.\nis feasible to create an e\ufb03cient and scalable way of support-\ning these views by generating them dynamically, on-the-\ufb02y,\nfrom a Single Underlying Model (SUM) using model-based\ntransformations and (c) that it is feasible to provide an in-\ntuitive metaphor for navigating around these many views\nby adapting the orthographic projection technique under-\npinning the CAD tools used in other engineering disciplines.\nFigure 1: Orthographic Projection.\nAs shown in Figure 1, the main advantages of using the\nidea of orthographic projection to de\ufb01ne the views used\nto visualize and described a system are that they (a) can\nbe organized according to a simple and easy-to-understand\nmetaphor and (b) collectively represent all the properties of\na system with minimal overlap and redundancy. In practice\nthis translates into a set of \u201cdimensions\u201d, each containing\nwell de\ufb01ned choices (or so called \u201cdimension elements\u201d) that\ncan be used to select individuals views.\nAs shown in Figure 2, the main advantage of making the\nartifacts used to describe a software system views of a SUM\nis that the number of pairwise coherence relationships that\nhave to be maintained is reduced and new views can be in-\ntroduced by simply de\ufb01ning their relationship to the SUM.\nMoreover, the importance of this advantage grows quickly\nas the size of the system and the complexity of the deployed\ndevelopment methodology increase. Another important ad-\nvantage is that the dominance of one particular kind of view\nover the development process (e.g. code) at the expense of\nother kinds of views (e.g. graphical models) is reduced so\nthat any appropriate type of views can be used to enrich\nthe underlying description of the system, depending on the\nneeds and skills of the stakeholder involved. This makes it\npossible to subsume all view types under the same, overarch-\nSUM\nSUM / View Centric Environment\nArtifact / Tools Centric Environment\nFigure 2: Consistency Dependencies in Artifact-oriented versus View-oriented Environments.\ning development process and methodology (e.g. agile-driven,\nfocusing on small development cycles, or model-driven de-\nvelopment, based on transformations between abstraction\nlevels). Although the details of how the views are created\nfrom the SUM and how the SUM is updated from the views\nare not central to the approach, a natural implementation\nis to use the visualization and transformation technologies\no\ufb00ered by model driven software engineering (MDSE).\nTo explore the validity of these hypotheses at the Uni-\nversity of Mannheim we have been developing a prototype\nOSM modeling environment based on an enhanced version\nof the KobrA method for model-driven, component-oriented\ndevelopment, KobrA 2.0 [1]. This was chosen as a basis for\nthe prototype, known as the Open, Adaptable, Orthographic\nModeling Environment (nAOMi) [13] because its views were\ndesigned with the precise goals of being (a) genuine pro-\njections of a subject containing carefully selected subsets\nof information about that subject, (b) minimalistic in the\nsense that they should overlap to the smallest extent possible\nand contain the minimum necessary models elements, and\n(c) selectable via a set of independent \u201cdimensions\u201d which\nre\ufb02ect di\ufb00erent fundamental concerns of development (i.e.\nabstraction levels, composition or variants). In other words,\nKobrA already provided one of the \u201cmost orthogonal\u201d sets\nof views for visualizing software systems of any contempo-\nrary method. More details about the actual views and di-\nmensions de\ufb01ned in KobrA are presented in the following\nsections. More information on OSM can be found in [2] and\n[3].\nnAOMi is implemented as an Eclipse plugin using the\nEclipse Modeling Framework (EMF) as the underlying mod-\neling platform and UML 2.0 tools [4] to generate and edit\nviews.\nThe KobrA 2.0 metamodel on which the current\nversion of nAOMi is based is a specialization of the UML\nmetamodel composed of three separate packages \u2014 one for\nthe SUM, one for the views and one for the transformations\n(Figure 3). The UML was chosen as the base language be-\ncause of its maturity and widespread acceptance, making the\nenvironment usable to the largest possible body of develop-\ners. UML elements not needed in KobrA 2.0 are excluded\nusing OCL constraints while new elements or properties are\nKobrA2\nTransformation\nSUM\nViews\nFigure 3: KobrA 2.0 Top Level Packages.\nintroduced by specializing existing elements.\nThe unique contribution of this paper is to elaborate on\nthe structure of the KobrA 2.0 metamodel and how it is used\nto drive nAOMi. The three following sections each focus on\none of the three main components of the metamodel \u2014 the\nSUM, the views and the transformations . This is followed\nby a brief overview of the OSM navigation paradigm in Sec-\ntion 5 before a small example of the approach is presented in\nSection 6. Section 7 then concludes the paper with related\nand future work.\n2.\nSUM PACKAGE\nFigure 4 depicts the internal structure of the SUM pack-\nage which is based on the UML metamodel. There are three\nmain subpackages, two containing the structural and behav-\nioral constructs respectively, and one containing the con-\nstraints that ensure that the metaclasses are used according\nto the KobrA conventions and rules.\nThe Classes subpackage of the Structure package contains\nsome of the most fundamental elements of the KobrA meta-\nmodel, such as Class and ComponentClass.\nThe internal\nstructure of this package is illustrated in Figure 5. Com-\nponentClass represents objects with complex and reusable\nbehaviors, while Class captures simple \u201cdata type\u201d objects\nthat have only very simple or non-reusable behaviors. The\nmodeler has to decide whether it is necessary to model a\nspeci\ufb01c part of the system as a ComponentClass and include\nstate charts and activity diagrams, or whether it is su\ufb03cient\nto use a Class (which is limited to using OCL constraints).\nComponentClass inherits (indirectly via Class) from Com-\nmunications so it also has the isActive attribute. This makes\nKobrA2::SUM::Constraint::Behavioral\nKobrA2::SUM::Constraint::Structural\nKobrA2::SUM::Constraint\nKobrA2::SUM::Constraint::Common\nKobrA2::SUM::Behavior::ProtocolStateMachines\nKobrA2::SUM::Behavior::Common\nKobrA2::SUM::Behavior::Activities\nKobrA2::SUM::Behavior::Actions\nKobrA2::SUM::Behavior\nKobrA2::SUM::Structure::Classes\nKobrA2::SUM::Structure::Types\nKobrA2::SUM::Structure::Instances\nKobrA2::SUM::Structure::Elements\nKobrA2::SUM::Structure\nKobrA2::SUM::Constraint::OclExpressions\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\nFigure 4: KobrA 2.0 SUM Package.\nit possible to model whether its instances are active or pas-\nsive. Active objects, which can be used to model threads and\nprocesses ([8] p. 438), start to execute their behavior as soon\nas they are created and perform operations spontaneously.\nA ComponentClass may exhibit complex behavior. In Ko-\nbrA, this behavior may be speci\ufb01ed in the form of\nUML\nState Diagrams (de\ufb01ning acceptable operation invocation\nsequences), and in the form of Activities (de\ufb01ning algorithms\nof operations). UML Interaction elements (in sequence dia-\ngrams) can be derived from the activity elements and thus\nare not included in the SUM. As KobrA aims to facilitate\nautomatic checking of allowed sequences of operation calls,\nProtocol State Machines are supported instead of general\nstate machines. Since the latter include a large variety of\nelements not needed for specifying acceptable operation se-\nquences or automatic checking, OCL constraints are used to\nprohibit the use of unwanted features.\ncontext\nComponentClass\n-- only\nallow\nActivity\nelements\nor\nProtocolStateMachines\ninv: ownedBehavior ->forAll( oclIsKindOf( Actitivity) or\noclIsKindOf ( ProtocolStateMachine ))\nFor example, since KobrA has no concept of roles for com-\nponents, the use of role also needs to be prohibited. The part\nassociation refers to owned properties of components whose\nattribute isComposite is true. As KobrA uses associations\nlike nests and creates for components, part, required and\nprovided are not needed. Connectors (i.e. delegation and\nassembly) are not used in KobrA either so ownedConnector\nis excluded.\nClass\nKobrA2::SUM::Structure::Classes\nGeneralizationSet\nAssociationClass\nComponentClass\nProperty\nUsage\nAssociation\nOperation\nPackageable\nElement\nParameter\nAcquires\nCreates\nNests\nUML::Component::PackagingComponents::Component\nUML::CommonBehaviors::Communications::Class\n+ownedOperation\n*\n+class\n0..1\n+supplier\n1..*\n{subsets supplierDependency}\n+supplierUsage\n*\n+client\n1..*\n{subsets clientDependency}\n+clientUsage\n*\n+ownedAttribute\n*\n+class\n0..1\n+powertype\n0..1\n+powertypeExtent\n*\n+packagedElement\n*\n{subsets component}\n+componentClass\n0..1\n+/superClass\nFigure 5: KobrA 2.0 Classes Package.\ncontext\nComponentClass\ninv: role ->union(part)->union( ownedConnector )\n->union( collaborationUse )-> union( representation )\n->union( realization)->union(required)\n->union(provided)->isEmpty ()\n3.\nVIEWS PACKAGE\nThe structure of the Views package is illustrated in Figure\n6. Again, since most of the views de\ufb01ned in KobrA 2.0 are\nbased on UML diagrams, the view metamodels have similar\nelements to the SUM metamodel. The big di\ufb00erence to the\nSUM is that there are no restrictions on the use of the view\nmetamodel elements.\nFor instance, views for a particular\npurpose such as supporting model checkers can be supported\nby adding elements unrelated to the UML.\nThe substructure of the Views package re\ufb02ects the types\nand organization of the KobrA views according to the view\n\u201cdimensions\u201d supported in nAOMi (cf. example in Section\n6). At the top level, the Views package is thus decomposed\ninto the Speci\ufb01cation and Realization options of the encap-\nsulation dimension.\nThese, in turn are both decomposed\ninto the Structural, Behavioral and Operational options of\nthe Projection dimension.\nFinally, with the exception of\nthe behavioral option, these are also all subdivided into the\nService and Type options of the granularity dimension. This\ndimension, with its two options, is an addition to the original\nversion of KobrA.\nThe Service view shows the direct, publicly visible rela-\ntionships of the subject ComponentClass to other Compo-\nnentClasses, while the Type view shows the publicly visi-\nble relationships of the subject to simple Classes. As with\nthe SUM, constraints have been de\ufb01ned to control what can\ngo into each view and when they are well formed. For ev-\nery view, a constraint enumerates all allowed elements (not\nshown in this paper).\nIn the following, some of the other constraints for the\nService view are elaborated. Since this view is a black-box\nview, the internals of ComponentClasses (nestedClassi\ufb01er)\nare not shown.\ncontext\nComponentClass\n-- no nested\nclassifiers , no\nprotocol\ninv: nestedClassifier ->union(protocol)->isEmpty ()\nClasses are only allowed if they are generalizations of Com-\nponentClasses, (or any of its superclasses, since a Compo-\nnentClass may inherit from a class as shown in the con-\nstraints with context Class. The following invariants ensure\nthat only publicly visible attributes and operations are in\nthis view, for both classes and ComponentClasses (which\ninherit from Class).\nClass\nService\nType\nInstance\nService\nType\nStructural\nSpecification\nOperational\nService\nType\nProtocol\nBehavioral\nKobrA2::Views::Derived\nComponentClassDependencies\nOperationDependencies\nInstance\nService\nType\nClass\nService\nType\nStructural\nRealization\nOperational\nService\nType\nBehavioral\nAlgorithm\nViews\nConcreteSyntax\nSubject\n<<import>>\n<<merge>>\n<<merge>>\n<<import>>\n<<merge>>\n<<import>>\nFigure 6: KobrA 2.0 Views package nesting.\ncontext\nClass\n-- only\nallow\nclasses\nthat\nare\ndirect or\nindirect\ngeneralizations\nof\nComponentClasses\nin this\nview\ndef: ccGeneralization : generalization .specific ->\nexists( oclIsKindOf ( ComponentClass ))\ninv:\ngeneralization .specific ->select( oclIsTypeOf (\nClass))->exists(s|s. ccGeneralization )\nor\nccGeneralization\n-- only\npublic\nattributes\nin this\nview\ninv: ownedAttribute ->forAll(visibility =# public)\n-- only\npublic\nOperations\nare\nallowed\nin the\nspecification\ninv: ownedOperation ->forAll(visibility =# public)\nOnly operation signatures are shown in this view, so pre-,\npost- and bodyconditions, as well as activities are omitted,\nwhich is re\ufb02ected in the last constraint.\ncontext\nOperation\n-- only\nthe\nsignature\nof the\nOperation\nis shown , not\nits\nbehavior (role\nname \"method\" refers to the\nActivities\nof the\noperation), or\ndependencies\ninv: method ->union( precondition )->union(body)->union(\npostcondition )->isEmpty ()\n4.\nTRANSFORMATIONS PACKAGE\nThe package AllViews provides the foundation for speci-\nfying the transformations between the SUM and the views\nin both directions. Part of the package\u2019s contents are shown\nin Figure 7.\nThe Abstraction concept (which is in fact a\nKobrA2::Transformation::Common::AllViews\nAbstraction\nTransformationExpression\nViewElement\nSumElement\nView\nKobrA2::SUM::Structure::Elements::Element\nKobrA2::Views::ConcreteSyntax::Element\nKobrA2::SUM::Constraint::Behavioral::Exp\nressionInOcl\nKobrA2::Views::Subject::View\n{subsets mapping}\n0..1\n0..1\n{subsets clientDependency}\n+abstraction 1\n{subsets client}\n+ve 1\n1..*\n1\n{subsets supplier}\n+se 1\n{subsets supplierDependency}\n+abstraction 1..*\nFigure 7: Transformation abstractions.\ndependency reused from the UML but with additional con-\nstraints) plays the key role in relating elements from the\nSUM to elements of a view. Abstraction is actually mapped\nto ExpressionInOcl.\nWhen appearing in transformations,\nthe equals sign links elements in the SUM to the respective\nelements in the view, and vice versa. For instance, equal-\nity of the general meta-association of a Generalization in\na transformation invariant means that, when following gen-\neral, there must be an element in the SUM and in the view\nfor which similar transformation expressions are speci\ufb01ed.\nIn the case of KobrA 2.0, which has many projections that\njust select a subset of elements using one-to-one abstrac-\ntions, this allows concise declarative TransformationExpres-\nsions. Together with the view constraints, a CASE tool can\nbe implemented which uses a transformation language of the\nimplementor\u2019s choice, for instance the Atlas Transformation\nLanguage (ATL) [11] or QVT [9]. The role names se and ve\nare short for SumElement and ViewElement, respectively.\nThese roles subset the client and supplier roles from the\nUML.\nSUM elements are translated into UML elements with\nstereotypes, so that the views are easy to manage for de-\nvelopers familiar with the UML. The bidirectional mappings\nbetween stereotyped view elements and non-stereotyped SUM\nelements are expressed in the constraints of the Association-\nAbstraction, a subclass of the Abstraction from the AllViews\npackage. This is also an example of a transformation which\nis reused in other views.\ncontext\nAssociationAbstraction\ninv: ve.memberEnd = se.memberEnd\ninv: ve.ownedEnd = se.ownedEnd\nivn: ve. navigableOwnedEnd = se. navigableOwnedEnd\ninv: se. oclIsKindOf(Acquires) implies ve.\nhasStereotype (\u2019acquires \u2019)\ninv: ve. hasStereotype (\u2019acquires \u2019)\nimplies\nse.\noclIsKindOf (Aquires)\ninv: se. oclIsKindOf(Nests) implies\nve. hasStereotype (\u2019\nnests \u2019)\ninv: ve. hasStereotype (\u2019nests \u2019)\nimplies se. oclIsKindOf\n(Nests)\ninv: se. oclIsKindOf (Creates) implies\nve. hasStereotype\n(\u2019creates \u2019)\ninv: ve. hasStereotype (\u2019creates \u2019)\nimplies se.\noclIsKindOf (Creates)\nFigure 8 shows the main elements involved in the trans-\nformation of the black box structural view for Component-\nClasses. The \ufb01rst transformation constraint is on the view\nand declares the starting point for the transformation. It\nstates that the subject ComponentClass and its generaliza-\ntions (using a SUM utility function, superClosure) are in the\nview.\nThe following transformation rules illustrate how to create\nthe output (i.e. view) elements from the input (i.e. SUM) el-\nements, such as the publicly visible attributes and operations\nof the ComponentClass and the acquired ComponentClasses.\nThe \ufb01rst constraint for ComponentClassAbstraction states\nthat references to potential general classes (and Component-\nClasses) of ComponentClasses are mirrored in the view. In\naddition, ComponentClasses will be shown with the corre-\nsponding stereotypes.\nThe ComponentClass owns various\ntypes of associations, so in this view only the acquires asso-\nciations are selected (whose transformation rules are cov-\nered in the common transformation packages).For classes\nand ComponentClasses, only publicly visible attributes and\noperations appear in the view.\nClass invariants are also\ncopied. Classes that may appear in this view (e.g. as gener-\nalizations of ComponentClasses) may have a powertype (role\nname powertypeExtent) which will be displayed.\nThe last transformation statement copies the class refer-\nences of operations. As with all views, the transformation\nrules, the common transformation statements (which also\ncover operations) and the view constraints serve as a speci-\n\ufb01cation for the implementation of a view. Individual CASE\ntools can use di\ufb00erent implementation techniques as long as\nthey conform to the semantics of these rules and constraints.\nKobrA2::Transformation::Specification::Structural::Class::Service\nComponentClassAbstraction\nKobrA2::Transformation::Common::Feature::OperationAbstraction\nKobrA2::Transformation::Common::AllViews::Abstraction\nKobrA2::SUM::Structure::Classes::ComponentClass\nKobrA2::SUM::Structure::Classes::Operation\nKobrA2::SUM::Structure::Classes::Class\nOperationAbstraction\nClassAbstraction\n+se\n1\n1..*\n+se\n1\n1..*\n+se\n1\n1..*\nFigure 8: Transformation to the Speci\ufb01cation Structural Service View.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassService\ninv: ownedMember ->select( oclIsKindOf(Class)) =\nsubject.superClosure ->union(subject.acquires.\nsuperClosure )\ncontext\nComponentClassAbstraction\ninv: ve.superClass = se. superClass\ninv: ve. hasStereotype (\u2019ComponentClass \u2019)\ninv: se.isSubject\nimplies (ve. hasStereotype (\u2019subject\n\u2019) and ve.ownedMember ->select( oclIsKindOf (\nAssociation )) = se.ownedMember ->select(\noclIsKindOf (Acquires)))\ncontext\nClassAbstraction\ninv: ve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\ninv: ve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public)\ninv: ve.\u2018inv \u2019 = se.\u2018inv \u2019\n-- copy\npowertypeExtent\nthat is only\nallowed\nfor\nclass\ninv: ve. powertypeExtent = se. powertypeExtent\ncontext\nOperationAbstraction\ninv: ve.class = se.class\nFor the black box type view, only publicly visible at-\ntributes and operations of classes (as opposed to Compo-\nnentClasses) used by the subject can be seen. This is spec-\ni\ufb01ed in the \ufb01rst rule which de\ufb01nes owned members of the\nview and thus serves as the starting point of the transfor-\nmation. cbbTypes is a utility function de\ufb01ned in the SUM\nwhich computes the black box types by selecting the types\nof the subject\u2019s public attributes and parameter types of its\npublic operations.\nClass invariants and potential powertypes and connections\nto the classes in this view are shown as well. There may\nalso be Enumerations, for which the EnumerationLiterals\nare displayed.\nThe transformation rules for this view are almost the same\nas the realization transformation constraints from the pack-\nage Transformation::Realization::Structural::Class::Type. The\ndi\ufb00erences are the select(visibility=#public) statements for\noperations and attributes.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassType\ninv: ownedMember ->select( oclIsKindOf(Class) or\noclIsKindOf(\u2018Enumeration \u2019) or\noclIsKindOf (\nAssociation)) = subject ->union(subject.cbbTypes)\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nClassAbstraction\ninv: not se.oclIsKindOf ( ComponentClass ) implies (\nve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\nve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public))\ninv: ve. powertypeExtent = se. powertypeExtent\ninv: ve. superClass = se.superClass\ninv: \u2018ve.inv \u2019 = \u2018se.inv \u2019\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nEnumerationAbstraction\ninv: ve. ownedLiteral = se. ownedLiteral\ncontext\nEnumerationLiteralAbstraction\ninv: ve. specification = se. specification .\nstringInSignature\n5.\nNAVIGATION\nMost of today\u2019s tools use some combination of trees to\norganize the content of models as well as the views used to\nvisualize a software system or component. In an any envi-\nronment incorporating a number of di\ufb00erent tools there is\ninvariably a large number of di\ufb00erent trees storing a het-\nerogeneous mix of artifacts including model elements (e.g.\nclasses, instances, associations), diagrams (e.g.\nclass dia-\ngrams, state diagrams) and other artifact types (source code,\nXML \ufb01les, con\ufb01guration \ufb01les ). To work with all the views in\na traditional development environment, therefore, engineers\ntypically have to learn about the organization structures of\nall the incorporated tools.\nIn contrast to conventional paradigms for organizing and\nnavigating the many views used to visualize a system, OSM\nemploys the metaphor of a multi-dimensional cube. More\nspeci\ufb01cally, as illustrated in Figure 9, OSM regards dimen-\nsion of the underlying methodology as representing a di\ufb00er-\nent dimension of the cube, and each independently variable\naspect of that dimension is a selectable dimension element.\nSelecting a view thus simply corresponds to selecting a single\ncell within the cube. In general, three types of dimensions\nare supported: static dimensions in which the number of\nFigure 9: Dimension-based navigation.\nselectable elements (i.e. coordinates) is \ufb01xed, dynamic di-\nmensions in which the number of elements is dynamic (i.e.\nderived from the SUM), and mixed dimensions which have\nboth static and dynamic elements.\nTo support the OSM dimension based navigation metaphor\nfor KobrA, we de\ufb01ned the seven dimensions indicated on the\nleft hand side of Figure 10 which is a sceenshot of nAOMI.\nThe Abstraction dimension (not expanded here), which has\nthree static dimension elements, PIM (platform independent\nmodel), PSM (platform speci\ufb01c model) and Code, captures\nthe model-driven development concern of KobrA. The ver-\nsion dimension captures the state of the modeled system at\nspeci\ufb01c points in time. The Component dimension, which\nhas dynamic dimension elements de\ufb01ned by instances of the\nclass ComponentClass in the SUM, captures the component-\nbased development concern of KobrA.\nThe Encapsulation dimension, which has two \ufb01xed ele-\nments, supports the distinction between Speci\ufb01cation (black\nbox) and Realization (white box) views of components, while\nthe Projection dimension with the \ufb01xed elements Structural,\nOperational and Behavioral covers the di\ufb00erent information\ntypes. The Granularity dimension provides a \ufb01ner grained\ndistinction between views describing the types used by com-\nponents (Type granularity) and views describing the required\nand provided interfaces (Service granularity). The Opera-\ntion dimension allows a selection of individual operations.\nIn the ideal case, when all views are truly orthogonal, the\nchoices that can be made in each dimensions are completely\nindependent.\nHowever, this is very di\ufb03cult to achieve in\nsoftware engineering. The approach still works if the views\nare not completely orthogonal, but dependencies then occur\nbetween di\ufb00erent choices in di\ufb00erent dimensions, so that the\ndecisions made in one dimensions may a\ufb00ect choices possi-\nble in another dimension. This is best handled by giving\ndimensions a precedence ranking determined by the order\nin which they appear (the top being the highest). When an\nelement in a dimension is selected, the tool automatically\nmakes default selections for dimensions of lower precedence\n(i.e.\ndimensions lower down) and disables selections that\nwould navigate to cells (i.e. views) which are not (yet) de-\n\ufb01ned by the method at hand.\n6.\nSHOPPING CART EXAMPLE\nTo show how a software system can be speci\ufb01ed using\nnAOMi, this section presents a case study based on a shop-\nping cart system. A ShoppingCart component collects and\nFigure 10: Speci\ufb01cation Structural View.\nmanages the products selected by users and supports pay-\nment via a credit card.\nFigure 10 illustrates a structural\nview of the component.\nIn the dimension navigator on the left hand side, PIM\nwas chosen for the \u201cAbstraction Level\u201d (not expanded in the\nscreenshot). The second dimension is the state of the soft-\nware system at a certain point in time. The picture shows\nthat the latest available version was chosen. As with every\nchoice in a dimension, it may in\ufb02uence the options in lower\nranked dimensions. The component under consideration is\nthe ShoppingCart, for which a black box view is selected\nin the next dimension. After the user selects the structural\nprojection option and the service level granularity, the tool\nautomatically chooses the option for all operations in the\nlast dimension, as there is no editor registered for the other\noptions.\nThe component under development is presented with the\nstereotype subject and its relationship to other components\nand classes is shown in the view, which corresponds to a cell\nof the multi-dimensional navigation cube, and is generated\non-the-\ufb02y from the SUM when it is selected. The classes\nProduct and CreditCard can be used as data types in the\noperations of the component.\nFigure 11 illustrates the operational view in which an\noperation can be formalized using pre- and postconditions.\nThe precondition corresponds to the assumes clause in and\nthe postcondition corresponds to the result clause. As in the\nUML, the precondition of an operation must be true when\nthe operation is invoked and the postcondition must be true\nwhen the operation is \ufb01nished. The operation addProduct\nin Figure 11 must be in state CollectingProducts or Empty\nwhen invoked. This is also visible in the behavioral view,\nFigure 11: addProduct() Operation Speci\ufb01cation.\nsince there are only two transitions with the operation ad-\ndProduct. Both leads to the state CollectingProducts which\nis also a postcondition of the operation. The second post-\ncondition is that the cost attribute of the component must\nbe increased by the price of the added product. The pre- and\npostcondition can be expressed using the OCL. The proper-\nties of the component, states and operation parameters can\nbe used to formalise the constraints like as in this example.\nFigure 12 shows the publicly visible behaviour of the Shop-\npingCart component with states and transitions. The condi-\ntional transitions map to operations of the component. Like\nevery view, this view is also synchronized with the SUM so\nthat it is guaranteed that its operations, states and proper-\nties are consistent with those in the structural view.\nFigure 12: Speci\ufb01cation Behavioral Model.\nAlthough the operational view seems to be similar to the\nbehavioral view because of the overlapping information within\nthem, there are signi\ufb01cant di\ufb00erences. The focus of the op-\nerational view is on a precise formal de\ufb01nition of an opera-\ntion of a component. The operations can be enriched by pre-\nand postconditions which can be de\ufb01ned using complex OCL\nstatements, that formalize the complete behavior of an op-\neration. The additional information in the OCL statements\ncan be used for code generation and documentation.\n7.\nCONCLUSION\nAt the beginning of the paper we identi\ufb01ed three funda-\nmental hypothesis upon which the notion of OSM is based\n\u2014 (a) that it is feasible to integrate the many di\ufb00erent kinds\nof artifacts used in contemporary software engineering meth-\nods within a single coherent methodology in which they are\ntreated as views, (b) that it is feasible to create an e\ufb03-\ncient and scalable way of supporting these views by gener-\nating them dynamically, on-the-\ufb02y, from a Single Underly-\ning Model (SUM) using model-based transformations and\n(c) that it is feasible to provide an intuitive metaphor for\nnavigating around these many views by adapting the ortho-\ngraphic projection technique underpinning the CAD tools\nused in other engineering disciplines.\nThe prototype tool, nAOMi, described in this paper rep-\nresents the \ufb01rst step towards demonstrating the validity of\nthese hypotheses and showing that OSM is a viable approach\nto software engineering. Of the three hypotheses, (a) and (c)\nare most convincingly demonstrated by the prototype, since\nit shows that it is indeed possible to support all the views\nof the KobrA method within a single navigation metaphor.\nThe prototype tool does not demonstrate the validity of hy-\npothesis (b) to the same extent as the others due to its\nsmall size. Although it demonstrates the feasibility of gen-\nerating views from the SUM and vice-versa, the question of\nwhether such an approach scales up to large environments\nis still open.\nAlthough nOAMi is the only tool developed with the spe-\nci\ufb01c aim of supporting KobrA-based OSM, several other\ntools and methods have similar properties or aims.\nFor\nexample, Glinz et al.\n[10] describe a tool with a \ufb01sheye\nzooming algorithm which lets the user view a model with\nvarying amounts of detail depending on the context. It has\nto be investigated whether it is possible to combine the \ufb01sh-\neye zooming concept with the dimension-based navigation\nparadigm. While the KobrA 2.0 implementation of nAOMi\nheavily uses UML diagrams for developers, Glinz et al. use\ncustom diagram types, e.g.\nfor structural and behavioral\nviews.\nAn approach which also emphasizes the description of for-\nmal consistency rules (correspondences) between views is\nRM-ODP [5][6].\nHowever, this approach does not explic-\nitly mention the notion of a SUM and thus implies that\nconsistency rules should be de\ufb01ned in a pairwise fashion be-\ntween individual pairs of views. ArchiMate [7], which com-\nplements TOGAF [12], is an enterprise architecture mod-\neling language which o\ufb00ers two orthogonal \u201ddimensions\u201d for\nmodeling, (business, architecture, and technology) layers and\n(informational, behavioral and structural) aspects and also\nsuggests two more dimensions, purpose and abstraction level.\nHowever, as many of these views span multiple choices of a\nsingle\u201cdimension\u201d, the intuitive dimension-based navigation\nmetaphor of OSM can not be easily applied. There are also\nmore general approaches for view-based modeling but they\nare less speci\ufb01c in terms of consistency rules between views\nand provide little guidance on how to manage and navigate\nviews, for example the Zachman Framework [14].\nRegarding the practical use of OSM environments in the\nfuture, the biggest challenge is developing appropriate SUM\nmetamodels which can accommodate all the types of views\nand services that software engineers are accustomed to to-\nday. For this \ufb01rst prototypical SUM-based environment sup-\nporting the OSM approach we had a method at our disposal\n(KobrA) that already de\ufb01ned a full set of orthogonal UML-\nbased views. This allowed us to model the required SUM\nand view metamodels by simply adapting the UML meta-\nmodels, removing and adding model elements as needed.\nIn doing so we were able to manually ensure that the meta-\nmodels ful\ufb01lled the two core requirements of SUM-based en-\nvironments \u2014 (1) being minimalistic and (2) redundancy\nfree. If SUM-based software engineering environments are\nto take o\ufb00, and to be introduced into existing, heteroge-\nneous environments, more sophisticated ways of integrating\nexisting metamodels into a single uni\ufb01ed metamodel will be\nrequired.\n8.\nREFERENCES\n[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,\nO. Laitenberger, R. Laqua, D. Muthig, B. Paech,\nJ. W\u00a8ust, and J. Zettel. Component-Based Product Line\nEngineering with UML. Addison Wesley, Reading,\nMassachusetts, USA, 1st edition, November 2001.\n[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic\nSoftware Modeling: A Practical Approach to\nView-Based Development. In Evaluation of Novel\nApproaches to Software Engineering, volume 69 of\nCommunications in Computer and Information\nScience, pages 206\u2013219. Springer Berlin Heidelberg,\n2010.\n[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic\nService Modeling. In Proceedings of 15th IEEE EDOC\nConference Workshops (EDOCW), Helsinki, Finland,\n2011.\n[4] Eclipse Foundation. UML2Tools.\nhttp://wiki.eclipse.org/MDT-UML2Tools, 2013.\n[5] ISO/IEC and ITU-T. The Reference Model of Open\nDistributed Processing. RM-ODP, ITU-T Rec.\nX.901-X.904 / ISO/IEC 10746.\nhttp://standards.iso.org/\nittf/PubliclyAvailableStandards/index.html,\n1998.\n[6] J. I. J. Jose Raul Romero and A. Vallecillo. Realizing\nCorrespondences in MultiViewpoint Speci\ufb01cations. In\nProceedings of the Thirteenth IEEE International\nEDOC Conference, 1 - 4 September 2009, Auckland,\nNew Zealand, September 2009.\n[7] M. Lankhorst. Enterprise Architecture at Work.\nSpringer Berlin Heidelberg, 2009.\n[8] Object Management Group (OMG). OMG Uni\ufb01ed\nModeling Language (OMG UML), Superstructure,\nV2.1.2.\nhttp://www.omg.org/cgi-bin/doc?formal/07-11-02,\nNovember 2007.\n[9] Object Management Group (OMG). Meta Object\nFacility (MOF) 2.0 Query/View/Transformation, v1.0.\nhttp://www.omg.org/spec/QVT/1.0/PDF/, April 2008.\n[10] C. Seybold, M. Glinz, S. Meier, and N. Merlo-Schett.\nAn e\ufb00ective layout adaptation technique for a\ngraphical modeling tool. In Proceedings of the 2003\nInternational Conference on Software Engineering,\nPortland, 2003.\n[11] The Atlas Transformation Language (ATL). O\ufb03cial\nWebsite. http://www.eclipse.org/atl/, 2013.\n[12] The Open Group. TOGAF Version 9 - The Open\nGroup Architecture Framework.\nhttp://www.opengroup.org/architecture/\ntogaf9-doc/arch/index.html, Feb 2009.\n[13] University of Mannheim - Software Engineering\nGroup. nAOMi - opeN, Adaptable, Orthographic\nModeling EnvIronment.\nhttp://eclipselabs.org/p/naomi.\n[14] J. A. Zachman. The Zachman Framework: A Primer\nfor Enterprise Engineering and Manufacturing.\nhttp://www.zachmaninternational.com, 2009.\n",
    "pdf_url": "",
    "references": [
      "[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,",
      "O. Laitenberger, R. Laqua, D. Muthig, B. Paech,",
      "J. W\u00a8ust, and J. Zettel. Component-Based Product Line",
      "Engineering with UML. Addison Wesley, Reading,",
      "Massachusetts, USA, 1st edition, November 2001.",
      "[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic",
      "Software Modeling: A Practical Approach to",
      "View-Based Development. In Evaluation of Novel",
      "Approaches to Software Engineering, volume 69 of",
      "Communications in Computer and Information",
      "Science, pages 206\u2013219. Springer Berlin Heidelberg,",
      "2010.",
      "[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "University of Kent",
      "uage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).Addison-Wesley Professional."
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "A Prototype Implementation of an Orthographic Software Modeling Environment",
    "resume": "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
    "auteurs": [
      "Colin Atkinson",
      "Dietmar Stoll",
      "Jacques Robin",
      "Recife",
      "Brasil",
      "D.2.2"
    ],
    "institutions": [
      "Dietmar Stoll University of Mannheim, TunjicUniversity of Mannheim,",
      "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
      "Colin Atkinson University of Mannheim,"
    ],
    "mots_cles": [
      " Orthographic Software Modeling",
      " View-based Modeling "
    ],
    "texte_integral": "A Prototype Implementation of an Orthographic Software\nModeling Environment\nColin Atkinson\nUniversity of Mannheim,\nGermany\natkinson@informatik.uni-\nmannheim.de\nDietmar Stoll\nUniversity of Mannheim,\nGermany\nstoll@informatik.uni-\nmannheim.de\nChristian Tunjic\nUniversity of Mannheim,\nGermany\ntunjic@informatik.uni-\nmannheim.de\nJacques Robin\nUniversidade Federal de\nPernambuco, Recife, Brasil\njr@cin.ufpe.br\nABSTRACT\nOrthographic Software Modeling (OSM) is a view-centric\nsoftware engineering approach that aims to leverage the or-\nthographic projection metaphor used in the visualization of\nphysical objects to visualize software systems. Although the\ngeneral concept of OSM does not prescribe speci\ufb01c sets of\nviews, a concrete OSM environment has to be speci\ufb01c about\nthe particular views to be used in a particular project. At\nthe University of Mannheim we are developing a prototype\nOSM environment, nAOMi, that supports the views de\ufb01ned\nby the KobrA 2.0 method, a version of KobrA adapted for\nOSM. In this paper we provide an overview of the KobrA 2.0\nmetamodel underpinning nAOMi and give a small example\nof its use to model a software system.\nCategories and Subject Descriptors\nD.1.7 [Programming Techniques]: Visual Programming;\nD.2.2 [Design Tools and Techniques]: Computer-aided\nsoftware engineering (CASE); D.2.6 [Software Engineer-\ning]: Programming Environments\u2014Graphical environments\nKeywords\nOrthographic Software Modeling, View-based Modeling\n1.\nINTRODUCTION\nOrthographic Software Modeling (OSM) is based on three\nfundamental hypotheses \u2014 (a) that it is feasible to inte-\ngrate the many di\ufb00erent kinds of artifacts used in contempo-\nrary software engineering methods within a single coherent\nmethodology in which they are treated as views, (b) that it\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for pro\ufb01t or commercial advantage and that copies\nbear this notice and the full citation on the \ufb01rst page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior speci\ufb01c\npermission and/or a fee.\nVAO \u201913, July 2, 2013, Montpellier, France\nCopyright 2013 ACM 978-1-4503-2041-2 ...$15.00.\nis feasible to create an e\ufb03cient and scalable way of support-\ning these views by generating them dynamically, on-the-\ufb02y,\nfrom a Single Underlying Model (SUM) using model-based\ntransformations and (c) that it is feasible to provide an in-\ntuitive metaphor for navigating around these many views\nby adapting the orthographic projection technique under-\npinning the CAD tools used in other engineering disciplines.\nFigure 1: Orthographic Projection.\nAs shown in Figure 1, the main advantages of using the\nidea of orthographic projection to de\ufb01ne the views used\nto visualize and described a system are that they (a) can\nbe organized according to a simple and easy-to-understand\nmetaphor and (b) collectively represent all the properties of\na system with minimal overlap and redundancy. In practice\nthis translates into a set of \u201cdimensions\u201d, each containing\nwell de\ufb01ned choices (or so called \u201cdimension elements\u201d) that\ncan be used to select individuals views.\nAs shown in Figure 2, the main advantage of making the\nartifacts used to describe a software system views of a SUM\nis that the number of pairwise coherence relationships that\nhave to be maintained is reduced and new views can be in-\ntroduced by simply de\ufb01ning their relationship to the SUM.\nMoreover, the importance of this advantage grows quickly\nas the size of the system and the complexity of the deployed\ndevelopment methodology increase. Another important ad-\nvantage is that the dominance of one particular kind of view\nover the development process (e.g. code) at the expense of\nother kinds of views (e.g. graphical models) is reduced so\nthat any appropriate type of views can be used to enrich\nthe underlying description of the system, depending on the\nneeds and skills of the stakeholder involved. This makes it\npossible to subsume all view types under the same, overarch-\nSUM\nSUM / View Centric Environment\nArtifact / Tools Centric Environment\nFigure 2: Consistency Dependencies in Artifact-oriented versus View-oriented Environments.\ning development process and methodology (e.g. agile-driven,\nfocusing on small development cycles, or model-driven de-\nvelopment, based on transformations between abstraction\nlevels). Although the details of how the views are created\nfrom the SUM and how the SUM is updated from the views\nare not central to the approach, a natural implementation\nis to use the visualization and transformation technologies\no\ufb00ered by model driven software engineering (MDSE).\nTo explore the validity of these hypotheses at the Uni-\nversity of Mannheim we have been developing a prototype\nOSM modeling environment based on an enhanced version\nof the KobrA method for model-driven, component-oriented\ndevelopment, KobrA 2.0 [1]. This was chosen as a basis for\nthe prototype, known as the Open, Adaptable, Orthographic\nModeling Environment (nAOMi) [13] because its views were\ndesigned with the precise goals of being (a) genuine pro-\njections of a subject containing carefully selected subsets\nof information about that subject, (b) minimalistic in the\nsense that they should overlap to the smallest extent possible\nand contain the minimum necessary models elements, and\n(c) selectable via a set of independent \u201cdimensions\u201d which\nre\ufb02ect di\ufb00erent fundamental concerns of development (i.e.\nabstraction levels, composition or variants). In other words,\nKobrA already provided one of the \u201cmost orthogonal\u201d sets\nof views for visualizing software systems of any contempo-\nrary method. More details about the actual views and di-\nmensions de\ufb01ned in KobrA are presented in the following\nsections. More information on OSM can be found in [2] and\n[3].\nnAOMi is implemented as an Eclipse plugin using the\nEclipse Modeling Framework (EMF) as the underlying mod-\neling platform and UML 2.0 tools [4] to generate and edit\nviews.\nThe KobrA 2.0 metamodel on which the current\nversion of nAOMi is based is a specialization of the UML\nmetamodel composed of three separate packages \u2014 one for\nthe SUM, one for the views and one for the transformations\n(Figure 3). The UML was chosen as the base language be-\ncause of its maturity and widespread acceptance, making the\nenvironment usable to the largest possible body of develop-\ners. UML elements not needed in KobrA 2.0 are excluded\nusing OCL constraints while new elements or properties are\nKobrA2\nTransformation\nSUM\nViews\nFigure 3: KobrA 2.0 Top Level Packages.\nintroduced by specializing existing elements.\nThe unique contribution of this paper is to elaborate on\nthe structure of the KobrA 2.0 metamodel and how it is used\nto drive nAOMi. The three following sections each focus on\none of the three main components of the metamodel \u2014 the\nSUM, the views and the transformations . This is followed\nby a brief overview of the OSM navigation paradigm in Sec-\ntion 5 before a small example of the approach is presented in\nSection 6. Section 7 then concludes the paper with related\nand future work.\n2.\nSUM PACKAGE\nFigure 4 depicts the internal structure of the SUM pack-\nage which is based on the UML metamodel. There are three\nmain subpackages, two containing the structural and behav-\nioral constructs respectively, and one containing the con-\nstraints that ensure that the metaclasses are used according\nto the KobrA conventions and rules.\nThe Classes subpackage of the Structure package contains\nsome of the most fundamental elements of the KobrA meta-\nmodel, such as Class and ComponentClass.\nThe internal\nstructure of this package is illustrated in Figure 5. Com-\nponentClass represents objects with complex and reusable\nbehaviors, while Class captures simple \u201cdata type\u201d objects\nthat have only very simple or non-reusable behaviors. The\nmodeler has to decide whether it is necessary to model a\nspeci\ufb01c part of the system as a ComponentClass and include\nstate charts and activity diagrams, or whether it is su\ufb03cient\nto use a Class (which is limited to using OCL constraints).\nComponentClass inherits (indirectly via Class) from Com-\nmunications so it also has the isActive attribute. This makes\nKobrA2::SUM::Constraint::Behavioral\nKobrA2::SUM::Constraint::Structural\nKobrA2::SUM::Constraint\nKobrA2::SUM::Constraint::Common\nKobrA2::SUM::Behavior::ProtocolStateMachines\nKobrA2::SUM::Behavior::Common\nKobrA2::SUM::Behavior::Activities\nKobrA2::SUM::Behavior::Actions\nKobrA2::SUM::Behavior\nKobrA2::SUM::Structure::Classes\nKobrA2::SUM::Structure::Types\nKobrA2::SUM::Structure::Instances\nKobrA2::SUM::Structure::Elements\nKobrA2::SUM::Structure\nKobrA2::SUM::Constraint::OclExpressions\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\nFigure 4: KobrA 2.0 SUM Package.\nit possible to model whether its instances are active or pas-\nsive. Active objects, which can be used to model threads and\nprocesses ([8] p. 438), start to execute their behavior as soon\nas they are created and perform operations spontaneously.\nA ComponentClass may exhibit complex behavior. In Ko-\nbrA, this behavior may be speci\ufb01ed in the form of\nUML\nState Diagrams (de\ufb01ning acceptable operation invocation\nsequences), and in the form of Activities (de\ufb01ning algorithms\nof operations). UML Interaction elements (in sequence dia-\ngrams) can be derived from the activity elements and thus\nare not included in the SUM. As KobrA aims to facilitate\nautomatic checking of allowed sequences of operation calls,\nProtocol State Machines are supported instead of general\nstate machines. Since the latter include a large variety of\nelements not needed for specifying acceptable operation se-\nquences or automatic checking, OCL constraints are used to\nprohibit the use of unwanted features.\ncontext\nComponentClass\n-- only\nallow\nActivity\nelements\nor\nProtocolStateMachines\ninv: ownedBehavior ->forAll( oclIsKindOf( Actitivity) or\noclIsKindOf ( ProtocolStateMachine ))\nFor example, since KobrA has no concept of roles for com-\nponents, the use of role also needs to be prohibited. The part\nassociation refers to owned properties of components whose\nattribute isComposite is true. As KobrA uses associations\nlike nests and creates for components, part, required and\nprovided are not needed. Connectors (i.e. delegation and\nassembly) are not used in KobrA either so ownedConnector\nis excluded.\nClass\nKobrA2::SUM::Structure::Classes\nGeneralizationSet\nAssociationClass\nComponentClass\nProperty\nUsage\nAssociation\nOperation\nPackageable\nElement\nParameter\nAcquires\nCreates\nNests\nUML::Component::PackagingComponents::Component\nUML::CommonBehaviors::Communications::Class\n+ownedOperation\n*\n+class\n0..1\n+supplier\n1..*\n{subsets supplierDependency}\n+supplierUsage\n*\n+client\n1..*\n{subsets clientDependency}\n+clientUsage\n*\n+ownedAttribute\n*\n+class\n0..1\n+powertype\n0..1\n+powertypeExtent\n*\n+packagedElement\n*\n{subsets component}\n+componentClass\n0..1\n+/superClass\nFigure 5: KobrA 2.0 Classes Package.\ncontext\nComponentClass\ninv: role ->union(part)->union( ownedConnector )\n->union( collaborationUse )-> union( representation )\n->union( realization)->union(required)\n->union(provided)->isEmpty ()\n3.\nVIEWS PACKAGE\nThe structure of the Views package is illustrated in Figure\n6. Again, since most of the views de\ufb01ned in KobrA 2.0 are\nbased on UML diagrams, the view metamodels have similar\nelements to the SUM metamodel. The big di\ufb00erence to the\nSUM is that there are no restrictions on the use of the view\nmetamodel elements.\nFor instance, views for a particular\npurpose such as supporting model checkers can be supported\nby adding elements unrelated to the UML.\nThe substructure of the Views package re\ufb02ects the types\nand organization of the KobrA views according to the view\n\u201cdimensions\u201d supported in nAOMi (cf. example in Section\n6). At the top level, the Views package is thus decomposed\ninto the Speci\ufb01cation and Realization options of the encap-\nsulation dimension.\nThese, in turn are both decomposed\ninto the Structural, Behavioral and Operational options of\nthe Projection dimension.\nFinally, with the exception of\nthe behavioral option, these are also all subdivided into the\nService and Type options of the granularity dimension. This\ndimension, with its two options, is an addition to the original\nversion of KobrA.\nThe Service view shows the direct, publicly visible rela-\ntionships of the subject ComponentClass to other Compo-\nnentClasses, while the Type view shows the publicly visi-\nble relationships of the subject to simple Classes. As with\nthe SUM, constraints have been de\ufb01ned to control what can\ngo into each view and when they are well formed. For ev-\nery view, a constraint enumerates all allowed elements (not\nshown in this paper).\nIn the following, some of the other constraints for the\nService view are elaborated. Since this view is a black-box\nview, the internals of ComponentClasses (nestedClassi\ufb01er)\nare not shown.\ncontext\nComponentClass\n-- no nested\nclassifiers , no\nprotocol\ninv: nestedClassifier ->union(protocol)->isEmpty ()\nClasses are only allowed if they are generalizations of Com-\nponentClasses, (or any of its superclasses, since a Compo-\nnentClass may inherit from a class as shown in the con-\nstraints with context Class. The following invariants ensure\nthat only publicly visible attributes and operations are in\nthis view, for both classes and ComponentClasses (which\ninherit from Class).\nClass\nService\nType\nInstance\nService\nType\nStructural\nSpecification\nOperational\nService\nType\nProtocol\nBehavioral\nKobrA2::Views::Derived\nComponentClassDependencies\nOperationDependencies\nInstance\nService\nType\nClass\nService\nType\nStructural\nRealization\nOperational\nService\nType\nBehavioral\nAlgorithm\nViews\nConcreteSyntax\nSubject\n<<import>>\n<<merge>>\n<<merge>>\n<<import>>\n<<merge>>\n<<import>>\nFigure 6: KobrA 2.0 Views package nesting.\ncontext\nClass\n-- only\nallow\nclasses\nthat\nare\ndirect or\nindirect\ngeneralizations\nof\nComponentClasses\nin this\nview\ndef: ccGeneralization : generalization .specific ->\nexists( oclIsKindOf ( ComponentClass ))\ninv:\ngeneralization .specific ->select( oclIsTypeOf (\nClass))->exists(s|s. ccGeneralization )\nor\nccGeneralization\n-- only\npublic\nattributes\nin this\nview\ninv: ownedAttribute ->forAll(visibility =# public)\n-- only\npublic\nOperations\nare\nallowed\nin the\nspecification\ninv: ownedOperation ->forAll(visibility =# public)\nOnly operation signatures are shown in this view, so pre-,\npost- and bodyconditions, as well as activities are omitted,\nwhich is re\ufb02ected in the last constraint.\ncontext\nOperation\n-- only\nthe\nsignature\nof the\nOperation\nis shown , not\nits\nbehavior (role\nname \"method\" refers to the\nActivities\nof the\noperation), or\ndependencies\ninv: method ->union( precondition )->union(body)->union(\npostcondition )->isEmpty ()\n4.\nTRANSFORMATIONS PACKAGE\nThe package AllViews provides the foundation for speci-\nfying the transformations between the SUM and the views\nin both directions. Part of the package\u2019s contents are shown\nin Figure 7.\nThe Abstraction concept (which is in fact a\nKobrA2::Transformation::Common::AllViews\nAbstraction\nTransformationExpression\nViewElement\nSumElement\nView\nKobrA2::SUM::Structure::Elements::Element\nKobrA2::Views::ConcreteSyntax::Element\nKobrA2::SUM::Constraint::Behavioral::Exp\nressionInOcl\nKobrA2::Views::Subject::View\n{subsets mapping}\n0..1\n0..1\n{subsets clientDependency}\n+abstraction 1\n{subsets client}\n+ve 1\n1..*\n1\n{subsets supplier}\n+se 1\n{subsets supplierDependency}\n+abstraction 1..*\nFigure 7: Transformation abstractions.\ndependency reused from the UML but with additional con-\nstraints) plays the key role in relating elements from the\nSUM to elements of a view. Abstraction is actually mapped\nto ExpressionInOcl.\nWhen appearing in transformations,\nthe equals sign links elements in the SUM to the respective\nelements in the view, and vice versa. For instance, equal-\nity of the general meta-association of a Generalization in\na transformation invariant means that, when following gen-\neral, there must be an element in the SUM and in the view\nfor which similar transformation expressions are speci\ufb01ed.\nIn the case of KobrA 2.0, which has many projections that\njust select a subset of elements using one-to-one abstrac-\ntions, this allows concise declarative TransformationExpres-\nsions. Together with the view constraints, a CASE tool can\nbe implemented which uses a transformation language of the\nimplementor\u2019s choice, for instance the Atlas Transformation\nLanguage (ATL) [11] or QVT [9]. The role names se and ve\nare short for SumElement and ViewElement, respectively.\nThese roles subset the client and supplier roles from the\nUML.\nSUM elements are translated into UML elements with\nstereotypes, so that the views are easy to manage for de-\nvelopers familiar with the UML. The bidirectional mappings\nbetween stereotyped view elements and non-stereotyped SUM\nelements are expressed in the constraints of the Association-\nAbstraction, a subclass of the Abstraction from the AllViews\npackage. This is also an example of a transformation which\nis reused in other views.\ncontext\nAssociationAbstraction\ninv: ve.memberEnd = se.memberEnd\ninv: ve.ownedEnd = se.ownedEnd\nivn: ve. navigableOwnedEnd = se. navigableOwnedEnd\ninv: se. oclIsKindOf(Acquires) implies ve.\nhasStereotype (\u2019acquires \u2019)\ninv: ve. hasStereotype (\u2019acquires \u2019)\nimplies\nse.\noclIsKindOf (Aquires)\ninv: se. oclIsKindOf(Nests) implies\nve. hasStereotype (\u2019\nnests \u2019)\ninv: ve. hasStereotype (\u2019nests \u2019)\nimplies se. oclIsKindOf\n(Nests)\ninv: se. oclIsKindOf (Creates) implies\nve. hasStereotype\n(\u2019creates \u2019)\ninv: ve. hasStereotype (\u2019creates \u2019)\nimplies se.\noclIsKindOf (Creates)\nFigure 8 shows the main elements involved in the trans-\nformation of the black box structural view for Component-\nClasses. The \ufb01rst transformation constraint is on the view\nand declares the starting point for the transformation. It\nstates that the subject ComponentClass and its generaliza-\ntions (using a SUM utility function, superClosure) are in the\nview.\nThe following transformation rules illustrate how to create\nthe output (i.e. view) elements from the input (i.e. SUM) el-\nements, such as the publicly visible attributes and operations\nof the ComponentClass and the acquired ComponentClasses.\nThe \ufb01rst constraint for ComponentClassAbstraction states\nthat references to potential general classes (and Component-\nClasses) of ComponentClasses are mirrored in the view. In\naddition, ComponentClasses will be shown with the corre-\nsponding stereotypes.\nThe ComponentClass owns various\ntypes of associations, so in this view only the acquires asso-\nciations are selected (whose transformation rules are cov-\nered in the common transformation packages).For classes\nand ComponentClasses, only publicly visible attributes and\noperations appear in the view.\nClass invariants are also\ncopied. Classes that may appear in this view (e.g. as gener-\nalizations of ComponentClasses) may have a powertype (role\nname powertypeExtent) which will be displayed.\nThe last transformation statement copies the class refer-\nences of operations. As with all views, the transformation\nrules, the common transformation statements (which also\ncover operations) and the view constraints serve as a speci-\n\ufb01cation for the implementation of a view. Individual CASE\ntools can use di\ufb00erent implementation techniques as long as\nthey conform to the semantics of these rules and constraints.\nKobrA2::Transformation::Specification::Structural::Class::Service\nComponentClassAbstraction\nKobrA2::Transformation::Common::Feature::OperationAbstraction\nKobrA2::Transformation::Common::AllViews::Abstraction\nKobrA2::SUM::Structure::Classes::ComponentClass\nKobrA2::SUM::Structure::Classes::Operation\nKobrA2::SUM::Structure::Classes::Class\nOperationAbstraction\nClassAbstraction\n+se\n1\n1..*\n+se\n1\n1..*\n+se\n1\n1..*\nFigure 8: Transformation to the Speci\ufb01cation Structural Service View.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassService\ninv: ownedMember ->select( oclIsKindOf(Class)) =\nsubject.superClosure ->union(subject.acquires.\nsuperClosure )\ncontext\nComponentClassAbstraction\ninv: ve.superClass = se. superClass\ninv: ve. hasStereotype (\u2019ComponentClass \u2019)\ninv: se.isSubject\nimplies (ve. hasStereotype (\u2019subject\n\u2019) and ve.ownedMember ->select( oclIsKindOf (\nAssociation )) = se.ownedMember ->select(\noclIsKindOf (Acquires)))\ncontext\nClassAbstraction\ninv: ve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\ninv: ve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public)\ninv: ve.\u2018inv \u2019 = se.\u2018inv \u2019\n-- copy\npowertypeExtent\nthat is only\nallowed\nfor\nclass\ninv: ve. powertypeExtent = se. powertypeExtent\ncontext\nOperationAbstraction\ninv: ve.class = se.class\nFor the black box type view, only publicly visible at-\ntributes and operations of classes (as opposed to Compo-\nnentClasses) used by the subject can be seen. This is spec-\ni\ufb01ed in the \ufb01rst rule which de\ufb01nes owned members of the\nview and thus serves as the starting point of the transfor-\nmation. cbbTypes is a utility function de\ufb01ned in the SUM\nwhich computes the black box types by selecting the types\nof the subject\u2019s public attributes and parameter types of its\npublic operations.\nClass invariants and potential powertypes and connections\nto the classes in this view are shown as well. There may\nalso be Enumerations, for which the EnumerationLiterals\nare displayed.\nThe transformation rules for this view are almost the same\nas the realization transformation constraints from the pack-\nage Transformation::Realization::Structural::Class::Type. The\ndi\ufb00erences are the select(visibility=#public) statements for\noperations and attributes.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassType\ninv: ownedMember ->select( oclIsKindOf(Class) or\noclIsKindOf(\u2018Enumeration \u2019) or\noclIsKindOf (\nAssociation)) = subject ->union(subject.cbbTypes)\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nClassAbstraction\ninv: not se.oclIsKindOf ( ComponentClass ) implies (\nve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\nve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public))\ninv: ve. powertypeExtent = se. powertypeExtent\ninv: ve. superClass = se.superClass\ninv: \u2018ve.inv \u2019 = \u2018se.inv \u2019\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nEnumerationAbstraction\ninv: ve. ownedLiteral = se. ownedLiteral\ncontext\nEnumerationLiteralAbstraction\ninv: ve. specification = se. specification .\nstringInSignature\n5.\nNAVIGATION\nMost of today\u2019s tools use some combination of trees to\norganize the content of models as well as the views used to\nvisualize a software system or component. In an any envi-\nronment incorporating a number of di\ufb00erent tools there is\ninvariably a large number of di\ufb00erent trees storing a het-\nerogeneous mix of artifacts including model elements (e.g.\nclasses, instances, associations), diagrams (e.g.\nclass dia-\ngrams, state diagrams) and other artifact types (source code,\nXML \ufb01les, con\ufb01guration \ufb01les ). To work with all the views in\na traditional development environment, therefore, engineers\ntypically have to learn about the organization structures of\nall the incorporated tools.\nIn contrast to conventional paradigms for organizing and\nnavigating the many views used to visualize a system, OSM\nemploys the metaphor of a multi-dimensional cube. More\nspeci\ufb01cally, as illustrated in Figure 9, OSM regards dimen-\nsion of the underlying methodology as representing a di\ufb00er-\nent dimension of the cube, and each independently variable\naspect of that dimension is a selectable dimension element.\nSelecting a view thus simply corresponds to selecting a single\ncell within the cube. In general, three types of dimensions\nare supported: static dimensions in which the number of\nFigure 9: Dimension-based navigation.\nselectable elements (i.e. coordinates) is \ufb01xed, dynamic di-\nmensions in which the number of elements is dynamic (i.e.\nderived from the SUM), and mixed dimensions which have\nboth static and dynamic elements.\nTo support the OSM dimension based navigation metaphor\nfor KobrA, we de\ufb01ned the seven dimensions indicated on the\nleft hand side of Figure 10 which is a sceenshot of nAOMI.\nThe Abstraction dimension (not expanded here), which has\nthree static dimension elements, PIM (platform independent\nmodel), PSM (platform speci\ufb01c model) and Code, captures\nthe model-driven development concern of KobrA. The ver-\nsion dimension captures the state of the modeled system at\nspeci\ufb01c points in time. The Component dimension, which\nhas dynamic dimension elements de\ufb01ned by instances of the\nclass ComponentClass in the SUM, captures the component-\nbased development concern of KobrA.\nThe Encapsulation dimension, which has two \ufb01xed ele-\nments, supports the distinction between Speci\ufb01cation (black\nbox) and Realization (white box) views of components, while\nthe Projection dimension with the \ufb01xed elements Structural,\nOperational and Behavioral covers the di\ufb00erent information\ntypes. The Granularity dimension provides a \ufb01ner grained\ndistinction between views describing the types used by com-\nponents (Type granularity) and views describing the required\nand provided interfaces (Service granularity). The Opera-\ntion dimension allows a selection of individual operations.\nIn the ideal case, when all views are truly orthogonal, the\nchoices that can be made in each dimensions are completely\nindependent.\nHowever, this is very di\ufb03cult to achieve in\nsoftware engineering. The approach still works if the views\nare not completely orthogonal, but dependencies then occur\nbetween di\ufb00erent choices in di\ufb00erent dimensions, so that the\ndecisions made in one dimensions may a\ufb00ect choices possi-\nble in another dimension. This is best handled by giving\ndimensions a precedence ranking determined by the order\nin which they appear (the top being the highest). When an\nelement in a dimension is selected, the tool automatically\nmakes default selections for dimensions of lower precedence\n(i.e.\ndimensions lower down) and disables selections that\nwould navigate to cells (i.e. views) which are not (yet) de-\n\ufb01ned by the method at hand.\n6.\nSHOPPING CART EXAMPLE\nTo show how a software system can be speci\ufb01ed using\nnAOMi, this section presents a case study based on a shop-\nping cart system. A ShoppingCart component collects and\nFigure 10: Speci\ufb01cation Structural View.\nmanages the products selected by users and supports pay-\nment via a credit card.\nFigure 10 illustrates a structural\nview of the component.\nIn the dimension navigator on the left hand side, PIM\nwas chosen for the \u201cAbstraction Level\u201d (not expanded in the\nscreenshot). The second dimension is the state of the soft-\nware system at a certain point in time. The picture shows\nthat the latest available version was chosen. As with every\nchoice in a dimension, it may in\ufb02uence the options in lower\nranked dimensions. The component under consideration is\nthe ShoppingCart, for which a black box view is selected\nin the next dimension. After the user selects the structural\nprojection option and the service level granularity, the tool\nautomatically chooses the option for all operations in the\nlast dimension, as there is no editor registered for the other\noptions.\nThe component under development is presented with the\nstereotype subject and its relationship to other components\nand classes is shown in the view, which corresponds to a cell\nof the multi-dimensional navigation cube, and is generated\non-the-\ufb02y from the SUM when it is selected. The classes\nProduct and CreditCard can be used as data types in the\noperations of the component.\nFigure 11 illustrates the operational view in which an\noperation can be formalized using pre- and postconditions.\nThe precondition corresponds to the assumes clause in and\nthe postcondition corresponds to the result clause. As in the\nUML, the precondition of an operation must be true when\nthe operation is invoked and the postcondition must be true\nwhen the operation is \ufb01nished. The operation addProduct\nin Figure 11 must be in state CollectingProducts or Empty\nwhen invoked. This is also visible in the behavioral view,\nFigure 11: addProduct() Operation Speci\ufb01cation.\nsince there are only two transitions with the operation ad-\ndProduct. Both leads to the state CollectingProducts which\nis also a postcondition of the operation. The second post-\ncondition is that the cost attribute of the component must\nbe increased by the price of the added product. The pre- and\npostcondition can be expressed using the OCL. The proper-\nties of the component, states and operation parameters can\nbe used to formalise the constraints like as in this example.\nFigure 12 shows the publicly visible behaviour of the Shop-\npingCart component with states and transitions. The condi-\ntional transitions map to operations of the component. Like\nevery view, this view is also synchronized with the SUM so\nthat it is guaranteed that its operations, states and proper-\nties are consistent with those in the structural view.\nFigure 12: Speci\ufb01cation Behavioral Model.\nAlthough the operational view seems to be similar to the\nbehavioral view because of the overlapping information within\nthem, there are signi\ufb01cant di\ufb00erences. The focus of the op-\nerational view is on a precise formal de\ufb01nition of an opera-\ntion of a component. The operations can be enriched by pre-\nand postconditions which can be de\ufb01ned using complex OCL\nstatements, that formalize the complete behavior of an op-\neration. The additional information in the OCL statements\ncan be used for code generation and documentation.\n7.\nCONCLUSION\nAt the beginning of the paper we identi\ufb01ed three funda-\nmental hypothesis upon which the notion of OSM is based\n\u2014 (a) that it is feasible to integrate the many di\ufb00erent kinds\nof artifacts used in contemporary software engineering meth-\nods within a single coherent methodology in which they are\ntreated as views, (b) that it is feasible to create an e\ufb03-\ncient and scalable way of supporting these views by gener-\nating them dynamically, on-the-\ufb02y, from a Single Underly-\ning Model (SUM) using model-based transformations and\n(c) that it is feasible to provide an intuitive metaphor for\nnavigating around these many views by adapting the ortho-\ngraphic projection technique underpinning the CAD tools\nused in other engineering disciplines.\nThe prototype tool, nAOMi, described in this paper rep-\nresents the \ufb01rst step towards demonstrating the validity of\nthese hypotheses and showing that OSM is a viable approach\nto software engineering. Of the three hypotheses, (a) and (c)\nare most convincingly demonstrated by the prototype, since\nit shows that it is indeed possible to support all the views\nof the KobrA method within a single navigation metaphor.\nThe prototype tool does not demonstrate the validity of hy-\npothesis (b) to the same extent as the others due to its\nsmall size. Although it demonstrates the feasibility of gen-\nerating views from the SUM and vice-versa, the question of\nwhether such an approach scales up to large environments\nis still open.\nAlthough nOAMi is the only tool developed with the spe-\nci\ufb01c aim of supporting KobrA-based OSM, several other\ntools and methods have similar properties or aims.\nFor\nexample, Glinz et al.\n[10] describe a tool with a \ufb01sheye\nzooming algorithm which lets the user view a model with\nvarying amounts of detail depending on the context. It has\nto be investigated whether it is possible to combine the \ufb01sh-\neye zooming concept with the dimension-based navigation\nparadigm. While the KobrA 2.0 implementation of nAOMi\nheavily uses UML diagrams for developers, Glinz et al. use\ncustom diagram types, e.g.\nfor structural and behavioral\nviews.\nAn approach which also emphasizes the description of for-\nmal consistency rules (correspondences) between views is\nRM-ODP [5][6].\nHowever, this approach does not explic-\nitly mention the notion of a SUM and thus implies that\nconsistency rules should be de\ufb01ned in a pairwise fashion be-\ntween individual pairs of views. ArchiMate [7], which com-\nplements TOGAF [12], is an enterprise architecture mod-\neling language which o\ufb00ers two orthogonal \u201ddimensions\u201d for\nmodeling, (business, architecture, and technology) layers and\n(informational, behavioral and structural) aspects and also\nsuggests two more dimensions, purpose and abstraction level.\nHowever, as many of these views span multiple choices of a\nsingle\u201cdimension\u201d, the intuitive dimension-based navigation\nmetaphor of OSM can not be easily applied. There are also\nmore general approaches for view-based modeling but they\nare less speci\ufb01c in terms of consistency rules between views\nand provide little guidance on how to manage and navigate\nviews, for example the Zachman Framework [14].\nRegarding the practical use of OSM environments in the\nfuture, the biggest challenge is developing appropriate SUM\nmetamodels which can accommodate all the types of views\nand services that software engineers are accustomed to to-\nday. For this \ufb01rst prototypical SUM-based environment sup-\nporting the OSM approach we had a method at our disposal\n(KobrA) that already de\ufb01ned a full set of orthogonal UML-\nbased views. This allowed us to model the required SUM\nand view metamodels by simply adapting the UML meta-\nmodels, removing and adding model elements as needed.\nIn doing so we were able to manually ensure that the meta-\nmodels ful\ufb01lled the two core requirements of SUM-based en-\nvironments \u2014 (1) being minimalistic and (2) redundancy\nfree. If SUM-based software engineering environments are\nto take o\ufb00, and to be introduced into existing, heteroge-\nneous environments, more sophisticated ways of integrating\nexisting metamodels into a single uni\ufb01ed metamodel will be\nrequired.\n8.\nREFERENCES\n[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,\nO. Laitenberger, R. Laqua, D. Muthig, B. Paech,\nJ. W\u00a8ust, and J. Zettel. Component-Based Product Line\nEngineering with UML. Addison Wesley, Reading,\nMassachusetts, USA, 1st edition, November 2001.\n[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic\nSoftware Modeling: A Practical Approach to\nView-Based Development. In Evaluation of Novel\nApproaches to Software Engineering, volume 69 of\nCommunications in Computer and Information\nScience, pages 206\u2013219. Springer Berlin Heidelberg,\n2010.\n[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic\nService Modeling. In Proceedings of 15th IEEE EDOC\nConference Workshops (EDOCW), Helsinki, Finland,\n2011.\n[4] Eclipse Foundation. UML2Tools.\nhttp://wiki.eclipse.org/MDT-UML2Tools, 2013.\n[5] ISO/IEC and ITU-T. The Reference Model of Open\nDistributed Processing. RM-ODP, ITU-T Rec.\nX.901-X.904 / ISO/IEC 10746.\nhttp://standards.iso.org/\nittf/PubliclyAvailableStandards/index.html,\n1998.\n[6] J. I. J. Jose Raul Romero and A. Vallecillo. Realizing\nCorrespondences in MultiViewpoint Speci\ufb01cations. In\nProceedings of the Thirteenth IEEE International\nEDOC Conference, 1 - 4 September 2009, Auckland,\nNew Zealand, September 2009.\n[7] M. Lankhorst. Enterprise Architecture at Work.\nSpringer Berlin Heidelberg, 2009.\n[8] Object Management Group (OMG). OMG Uni\ufb01ed\nModeling Language (OMG UML), Superstructure,\nV2.1.2.\nhttp://www.omg.org/cgi-bin/doc?formal/07-11-02,\nNovember 2007.\n[9] Object Management Group (OMG). Meta Object\nFacility (MOF) 2.0 Query/View/Transformation, v1.0.\nhttp://www.omg.org/spec/QVT/1.0/PDF/, April 2008.\n[10] C. Seybold, M. Glinz, S. Meier, and N. Merlo-Schett.\nAn e\ufb00ective layout adaptation technique for a\ngraphical modeling tool. In Proceedings of the 2003\nInternational Conference on Software Engineering,\nPortland, 2003.\n[11] The Atlas Transformation Language (ATL). O\ufb03cial\nWebsite. http://www.eclipse.org/atl/, 2013.\n[12] The Open Group. TOGAF Version 9 - The Open\nGroup Architecture Framework.\nhttp://www.opengroup.org/architecture/\ntogaf9-doc/arch/index.html, Feb 2009.\n[13] University of Mannheim - Software Engineering\nGroup. nAOMi - opeN, Adaptable, Orthographic\nModeling EnvIronment.\nhttp://eclipselabs.org/p/naomi.\n[14] J. A. Zachman. The Zachman Framework: A Primer\nfor Enterprise Engineering and Manufacturing.\nhttp://www.zachmaninternational.com, 2009.\n",
    "pdf_url": "",
    "references": [
      "[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,",
      "O. Laitenberger, R. Laqua, D. Muthig, B. Paech,",
      "J. W\u00a8ust, and J. Zettel. Component-Based Product Line",
      "Engineering with UML. Addison Wesley, Reading,",
      "Massachusetts, USA, 1st edition, November 2001.",
      "[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic",
      "Software Modeling: A Practical Approach to",
      "View-Based Development. In Evaluation of Novel",
      "Approaches to Software Engineering, volume 69 of",
      "Communications in Computer and Information",
      "Science, pages 206\u2013219. Springer Berlin Heidelberg,",
      "2010.",
      "[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "uage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).Addison-Wesley Professional.",
      "University of Kent"
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "A Prototype Implementation of an Orthographic Software Modeling Environment",
    "resume": "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
    "auteurs": [
      "Colin Atkinson",
      "Dietmar Stoll",
      "Jacques Robin",
      "Recife",
      "Brasil",
      "D.2.2"
    ],
    "institutions": [
      "Colin Atkinson University of Mannheim,",
      "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
      "Dietmar Stoll University of Mannheim, TunjicUniversity of Mannheim,"
    ],
    "mots_cles": [
      " Orthographic Software Modeling",
      " View-based Modeling "
    ],
    "texte_integral": "A Prototype Implementation of an Orthographic Software\nModeling Environment\nColin Atkinson\nUniversity of Mannheim,\nGermany\natkinson@informatik.uni-\nmannheim.de\nDietmar Stoll\nUniversity of Mannheim,\nGermany\nstoll@informatik.uni-\nmannheim.de\nChristian Tunjic\nUniversity of Mannheim,\nGermany\ntunjic@informatik.uni-\nmannheim.de\nJacques Robin\nUniversidade Federal de\nPernambuco, Recife, Brasil\njr@cin.ufpe.br\nABSTRACT\nOrthographic Software Modeling (OSM) is a view-centric\nsoftware engineering approach that aims to leverage the or-\nthographic projection metaphor used in the visualization of\nphysical objects to visualize software systems. Although the\ngeneral concept of OSM does not prescribe speci\ufb01c sets of\nviews, a concrete OSM environment has to be speci\ufb01c about\nthe particular views to be used in a particular project. At\nthe University of Mannheim we are developing a prototype\nOSM environment, nAOMi, that supports the views de\ufb01ned\nby the KobrA 2.0 method, a version of KobrA adapted for\nOSM. In this paper we provide an overview of the KobrA 2.0\nmetamodel underpinning nAOMi and give a small example\nof its use to model a software system.\nCategories and Subject Descriptors\nD.1.7 [Programming Techniques]: Visual Programming;\nD.2.2 [Design Tools and Techniques]: Computer-aided\nsoftware engineering (CASE); D.2.6 [Software Engineer-\ning]: Programming Environments\u2014Graphical environments\nKeywords\nOrthographic Software Modeling, View-based Modeling\n1.\nINTRODUCTION\nOrthographic Software Modeling (OSM) is based on three\nfundamental hypotheses \u2014 (a) that it is feasible to inte-\ngrate the many di\ufb00erent kinds of artifacts used in contempo-\nrary software engineering methods within a single coherent\nmethodology in which they are treated as views, (b) that it\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for pro\ufb01t or commercial advantage and that copies\nbear this notice and the full citation on the \ufb01rst page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior speci\ufb01c\npermission and/or a fee.\nVAO \u201913, July 2, 2013, Montpellier, France\nCopyright 2013 ACM 978-1-4503-2041-2 ...$15.00.\nis feasible to create an e\ufb03cient and scalable way of support-\ning these views by generating them dynamically, on-the-\ufb02y,\nfrom a Single Underlying Model (SUM) using model-based\ntransformations and (c) that it is feasible to provide an in-\ntuitive metaphor for navigating around these many views\nby adapting the orthographic projection technique under-\npinning the CAD tools used in other engineering disciplines.\nFigure 1: Orthographic Projection.\nAs shown in Figure 1, the main advantages of using the\nidea of orthographic projection to de\ufb01ne the views used\nto visualize and described a system are that they (a) can\nbe organized according to a simple and easy-to-understand\nmetaphor and (b) collectively represent all the properties of\na system with minimal overlap and redundancy. In practice\nthis translates into a set of \u201cdimensions\u201d, each containing\nwell de\ufb01ned choices (or so called \u201cdimension elements\u201d) that\ncan be used to select individuals views.\nAs shown in Figure 2, the main advantage of making the\nartifacts used to describe a software system views of a SUM\nis that the number of pairwise coherence relationships that\nhave to be maintained is reduced and new views can be in-\ntroduced by simply de\ufb01ning their relationship to the SUM.\nMoreover, the importance of this advantage grows quickly\nas the size of the system and the complexity of the deployed\ndevelopment methodology increase. Another important ad-\nvantage is that the dominance of one particular kind of view\nover the development process (e.g. code) at the expense of\nother kinds of views (e.g. graphical models) is reduced so\nthat any appropriate type of views can be used to enrich\nthe underlying description of the system, depending on the\nneeds and skills of the stakeholder involved. This makes it\npossible to subsume all view types under the same, overarch-\nSUM\nSUM / View Centric Environment\nArtifact / Tools Centric Environment\nFigure 2: Consistency Dependencies in Artifact-oriented versus View-oriented Environments.\ning development process and methodology (e.g. agile-driven,\nfocusing on small development cycles, or model-driven de-\nvelopment, based on transformations between abstraction\nlevels). Although the details of how the views are created\nfrom the SUM and how the SUM is updated from the views\nare not central to the approach, a natural implementation\nis to use the visualization and transformation technologies\no\ufb00ered by model driven software engineering (MDSE).\nTo explore the validity of these hypotheses at the Uni-\nversity of Mannheim we have been developing a prototype\nOSM modeling environment based on an enhanced version\nof the KobrA method for model-driven, component-oriented\ndevelopment, KobrA 2.0 [1]. This was chosen as a basis for\nthe prototype, known as the Open, Adaptable, Orthographic\nModeling Environment (nAOMi) [13] because its views were\ndesigned with the precise goals of being (a) genuine pro-\njections of a subject containing carefully selected subsets\nof information about that subject, (b) minimalistic in the\nsense that they should overlap to the smallest extent possible\nand contain the minimum necessary models elements, and\n(c) selectable via a set of independent \u201cdimensions\u201d which\nre\ufb02ect di\ufb00erent fundamental concerns of development (i.e.\nabstraction levels, composition or variants). In other words,\nKobrA already provided one of the \u201cmost orthogonal\u201d sets\nof views for visualizing software systems of any contempo-\nrary method. More details about the actual views and di-\nmensions de\ufb01ned in KobrA are presented in the following\nsections. More information on OSM can be found in [2] and\n[3].\nnAOMi is implemented as an Eclipse plugin using the\nEclipse Modeling Framework (EMF) as the underlying mod-\neling platform and UML 2.0 tools [4] to generate and edit\nviews.\nThe KobrA 2.0 metamodel on which the current\nversion of nAOMi is based is a specialization of the UML\nmetamodel composed of three separate packages \u2014 one for\nthe SUM, one for the views and one for the transformations\n(Figure 3). The UML was chosen as the base language be-\ncause of its maturity and widespread acceptance, making the\nenvironment usable to the largest possible body of develop-\ners. UML elements not needed in KobrA 2.0 are excluded\nusing OCL constraints while new elements or properties are\nKobrA2\nTransformation\nSUM\nViews\nFigure 3: KobrA 2.0 Top Level Packages.\nintroduced by specializing existing elements.\nThe unique contribution of this paper is to elaborate on\nthe structure of the KobrA 2.0 metamodel and how it is used\nto drive nAOMi. The three following sections each focus on\none of the three main components of the metamodel \u2014 the\nSUM, the views and the transformations . This is followed\nby a brief overview of the OSM navigation paradigm in Sec-\ntion 5 before a small example of the approach is presented in\nSection 6. Section 7 then concludes the paper with related\nand future work.\n2.\nSUM PACKAGE\nFigure 4 depicts the internal structure of the SUM pack-\nage which is based on the UML metamodel. There are three\nmain subpackages, two containing the structural and behav-\nioral constructs respectively, and one containing the con-\nstraints that ensure that the metaclasses are used according\nto the KobrA conventions and rules.\nThe Classes subpackage of the Structure package contains\nsome of the most fundamental elements of the KobrA meta-\nmodel, such as Class and ComponentClass.\nThe internal\nstructure of this package is illustrated in Figure 5. Com-\nponentClass represents objects with complex and reusable\nbehaviors, while Class captures simple \u201cdata type\u201d objects\nthat have only very simple or non-reusable behaviors. The\nmodeler has to decide whether it is necessary to model a\nspeci\ufb01c part of the system as a ComponentClass and include\nstate charts and activity diagrams, or whether it is su\ufb03cient\nto use a Class (which is limited to using OCL constraints).\nComponentClass inherits (indirectly via Class) from Com-\nmunications so it also has the isActive attribute. This makes\nKobrA2::SUM::Constraint::Behavioral\nKobrA2::SUM::Constraint::Structural\nKobrA2::SUM::Constraint\nKobrA2::SUM::Constraint::Common\nKobrA2::SUM::Behavior::ProtocolStateMachines\nKobrA2::SUM::Behavior::Common\nKobrA2::SUM::Behavior::Activities\nKobrA2::SUM::Behavior::Actions\nKobrA2::SUM::Behavior\nKobrA2::SUM::Structure::Classes\nKobrA2::SUM::Structure::Types\nKobrA2::SUM::Structure::Instances\nKobrA2::SUM::Structure::Elements\nKobrA2::SUM::Structure\nKobrA2::SUM::Constraint::OclExpressions\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\nFigure 4: KobrA 2.0 SUM Package.\nit possible to model whether its instances are active or pas-\nsive. Active objects, which can be used to model threads and\nprocesses ([8] p. 438), start to execute their behavior as soon\nas they are created and perform operations spontaneously.\nA ComponentClass may exhibit complex behavior. In Ko-\nbrA, this behavior may be speci\ufb01ed in the form of\nUML\nState Diagrams (de\ufb01ning acceptable operation invocation\nsequences), and in the form of Activities (de\ufb01ning algorithms\nof operations). UML Interaction elements (in sequence dia-\ngrams) can be derived from the activity elements and thus\nare not included in the SUM. As KobrA aims to facilitate\nautomatic checking of allowed sequences of operation calls,\nProtocol State Machines are supported instead of general\nstate machines. Since the latter include a large variety of\nelements not needed for specifying acceptable operation se-\nquences or automatic checking, OCL constraints are used to\nprohibit the use of unwanted features.\ncontext\nComponentClass\n-- only\nallow\nActivity\nelements\nor\nProtocolStateMachines\ninv: ownedBehavior ->forAll( oclIsKindOf( Actitivity) or\noclIsKindOf ( ProtocolStateMachine ))\nFor example, since KobrA has no concept of roles for com-\nponents, the use of role also needs to be prohibited. The part\nassociation refers to owned properties of components whose\nattribute isComposite is true. As KobrA uses associations\nlike nests and creates for components, part, required and\nprovided are not needed. Connectors (i.e. delegation and\nassembly) are not used in KobrA either so ownedConnector\nis excluded.\nClass\nKobrA2::SUM::Structure::Classes\nGeneralizationSet\nAssociationClass\nComponentClass\nProperty\nUsage\nAssociation\nOperation\nPackageable\nElement\nParameter\nAcquires\nCreates\nNests\nUML::Component::PackagingComponents::Component\nUML::CommonBehaviors::Communications::Class\n+ownedOperation\n*\n+class\n0..1\n+supplier\n1..*\n{subsets supplierDependency}\n+supplierUsage\n*\n+client\n1..*\n{subsets clientDependency}\n+clientUsage\n*\n+ownedAttribute\n*\n+class\n0..1\n+powertype\n0..1\n+powertypeExtent\n*\n+packagedElement\n*\n{subsets component}\n+componentClass\n0..1\n+/superClass\nFigure 5: KobrA 2.0 Classes Package.\ncontext\nComponentClass\ninv: role ->union(part)->union( ownedConnector )\n->union( collaborationUse )-> union( representation )\n->union( realization)->union(required)\n->union(provided)->isEmpty ()\n3.\nVIEWS PACKAGE\nThe structure of the Views package is illustrated in Figure\n6. Again, since most of the views de\ufb01ned in KobrA 2.0 are\nbased on UML diagrams, the view metamodels have similar\nelements to the SUM metamodel. The big di\ufb00erence to the\nSUM is that there are no restrictions on the use of the view\nmetamodel elements.\nFor instance, views for a particular\npurpose such as supporting model checkers can be supported\nby adding elements unrelated to the UML.\nThe substructure of the Views package re\ufb02ects the types\nand organization of the KobrA views according to the view\n\u201cdimensions\u201d supported in nAOMi (cf. example in Section\n6). At the top level, the Views package is thus decomposed\ninto the Speci\ufb01cation and Realization options of the encap-\nsulation dimension.\nThese, in turn are both decomposed\ninto the Structural, Behavioral and Operational options of\nthe Projection dimension.\nFinally, with the exception of\nthe behavioral option, these are also all subdivided into the\nService and Type options of the granularity dimension. This\ndimension, with its two options, is an addition to the original\nversion of KobrA.\nThe Service view shows the direct, publicly visible rela-\ntionships of the subject ComponentClass to other Compo-\nnentClasses, while the Type view shows the publicly visi-\nble relationships of the subject to simple Classes. As with\nthe SUM, constraints have been de\ufb01ned to control what can\ngo into each view and when they are well formed. For ev-\nery view, a constraint enumerates all allowed elements (not\nshown in this paper).\nIn the following, some of the other constraints for the\nService view are elaborated. Since this view is a black-box\nview, the internals of ComponentClasses (nestedClassi\ufb01er)\nare not shown.\ncontext\nComponentClass\n-- no nested\nclassifiers , no\nprotocol\ninv: nestedClassifier ->union(protocol)->isEmpty ()\nClasses are only allowed if they are generalizations of Com-\nponentClasses, (or any of its superclasses, since a Compo-\nnentClass may inherit from a class as shown in the con-\nstraints with context Class. The following invariants ensure\nthat only publicly visible attributes and operations are in\nthis view, for both classes and ComponentClasses (which\ninherit from Class).\nClass\nService\nType\nInstance\nService\nType\nStructural\nSpecification\nOperational\nService\nType\nProtocol\nBehavioral\nKobrA2::Views::Derived\nComponentClassDependencies\nOperationDependencies\nInstance\nService\nType\nClass\nService\nType\nStructural\nRealization\nOperational\nService\nType\nBehavioral\nAlgorithm\nViews\nConcreteSyntax\nSubject\n<<import>>\n<<merge>>\n<<merge>>\n<<import>>\n<<merge>>\n<<import>>\nFigure 6: KobrA 2.0 Views package nesting.\ncontext\nClass\n-- only\nallow\nclasses\nthat\nare\ndirect or\nindirect\ngeneralizations\nof\nComponentClasses\nin this\nview\ndef: ccGeneralization : generalization .specific ->\nexists( oclIsKindOf ( ComponentClass ))\ninv:\ngeneralization .specific ->select( oclIsTypeOf (\nClass))->exists(s|s. ccGeneralization )\nor\nccGeneralization\n-- only\npublic\nattributes\nin this\nview\ninv: ownedAttribute ->forAll(visibility =# public)\n-- only\npublic\nOperations\nare\nallowed\nin the\nspecification\ninv: ownedOperation ->forAll(visibility =# public)\nOnly operation signatures are shown in this view, so pre-,\npost- and bodyconditions, as well as activities are omitted,\nwhich is re\ufb02ected in the last constraint.\ncontext\nOperation\n-- only\nthe\nsignature\nof the\nOperation\nis shown , not\nits\nbehavior (role\nname \"method\" refers to the\nActivities\nof the\noperation), or\ndependencies\ninv: method ->union( precondition )->union(body)->union(\npostcondition )->isEmpty ()\n4.\nTRANSFORMATIONS PACKAGE\nThe package AllViews provides the foundation for speci-\nfying the transformations between the SUM and the views\nin both directions. Part of the package\u2019s contents are shown\nin Figure 7.\nThe Abstraction concept (which is in fact a\nKobrA2::Transformation::Common::AllViews\nAbstraction\nTransformationExpression\nViewElement\nSumElement\nView\nKobrA2::SUM::Structure::Elements::Element\nKobrA2::Views::ConcreteSyntax::Element\nKobrA2::SUM::Constraint::Behavioral::Exp\nressionInOcl\nKobrA2::Views::Subject::View\n{subsets mapping}\n0..1\n0..1\n{subsets clientDependency}\n+abstraction 1\n{subsets client}\n+ve 1\n1..*\n1\n{subsets supplier}\n+se 1\n{subsets supplierDependency}\n+abstraction 1..*\nFigure 7: Transformation abstractions.\ndependency reused from the UML but with additional con-\nstraints) plays the key role in relating elements from the\nSUM to elements of a view. Abstraction is actually mapped\nto ExpressionInOcl.\nWhen appearing in transformations,\nthe equals sign links elements in the SUM to the respective\nelements in the view, and vice versa. For instance, equal-\nity of the general meta-association of a Generalization in\na transformation invariant means that, when following gen-\neral, there must be an element in the SUM and in the view\nfor which similar transformation expressions are speci\ufb01ed.\nIn the case of KobrA 2.0, which has many projections that\njust select a subset of elements using one-to-one abstrac-\ntions, this allows concise declarative TransformationExpres-\nsions. Together with the view constraints, a CASE tool can\nbe implemented which uses a transformation language of the\nimplementor\u2019s choice, for instance the Atlas Transformation\nLanguage (ATL) [11] or QVT [9]. The role names se and ve\nare short for SumElement and ViewElement, respectively.\nThese roles subset the client and supplier roles from the\nUML.\nSUM elements are translated into UML elements with\nstereotypes, so that the views are easy to manage for de-\nvelopers familiar with the UML. The bidirectional mappings\nbetween stereotyped view elements and non-stereotyped SUM\nelements are expressed in the constraints of the Association-\nAbstraction, a subclass of the Abstraction from the AllViews\npackage. This is also an example of a transformation which\nis reused in other views.\ncontext\nAssociationAbstraction\ninv: ve.memberEnd = se.memberEnd\ninv: ve.ownedEnd = se.ownedEnd\nivn: ve. navigableOwnedEnd = se. navigableOwnedEnd\ninv: se. oclIsKindOf(Acquires) implies ve.\nhasStereotype (\u2019acquires \u2019)\ninv: ve. hasStereotype (\u2019acquires \u2019)\nimplies\nse.\noclIsKindOf (Aquires)\ninv: se. oclIsKindOf(Nests) implies\nve. hasStereotype (\u2019\nnests \u2019)\ninv: ve. hasStereotype (\u2019nests \u2019)\nimplies se. oclIsKindOf\n(Nests)\ninv: se. oclIsKindOf (Creates) implies\nve. hasStereotype\n(\u2019creates \u2019)\ninv: ve. hasStereotype (\u2019creates \u2019)\nimplies se.\noclIsKindOf (Creates)\nFigure 8 shows the main elements involved in the trans-\nformation of the black box structural view for Component-\nClasses. The \ufb01rst transformation constraint is on the view\nand declares the starting point for the transformation. It\nstates that the subject ComponentClass and its generaliza-\ntions (using a SUM utility function, superClosure) are in the\nview.\nThe following transformation rules illustrate how to create\nthe output (i.e. view) elements from the input (i.e. SUM) el-\nements, such as the publicly visible attributes and operations\nof the ComponentClass and the acquired ComponentClasses.\nThe \ufb01rst constraint for ComponentClassAbstraction states\nthat references to potential general classes (and Component-\nClasses) of ComponentClasses are mirrored in the view. In\naddition, ComponentClasses will be shown with the corre-\nsponding stereotypes.\nThe ComponentClass owns various\ntypes of associations, so in this view only the acquires asso-\nciations are selected (whose transformation rules are cov-\nered in the common transformation packages).For classes\nand ComponentClasses, only publicly visible attributes and\noperations appear in the view.\nClass invariants are also\ncopied. Classes that may appear in this view (e.g. as gener-\nalizations of ComponentClasses) may have a powertype (role\nname powertypeExtent) which will be displayed.\nThe last transformation statement copies the class refer-\nences of operations. As with all views, the transformation\nrules, the common transformation statements (which also\ncover operations) and the view constraints serve as a speci-\n\ufb01cation for the implementation of a view. Individual CASE\ntools can use di\ufb00erent implementation techniques as long as\nthey conform to the semantics of these rules and constraints.\nKobrA2::Transformation::Specification::Structural::Class::Service\nComponentClassAbstraction\nKobrA2::Transformation::Common::Feature::OperationAbstraction\nKobrA2::Transformation::Common::AllViews::Abstraction\nKobrA2::SUM::Structure::Classes::ComponentClass\nKobrA2::SUM::Structure::Classes::Operation\nKobrA2::SUM::Structure::Classes::Class\nOperationAbstraction\nClassAbstraction\n+se\n1\n1..*\n+se\n1\n1..*\n+se\n1\n1..*\nFigure 8: Transformation to the Speci\ufb01cation Structural Service View.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassService\ninv: ownedMember ->select( oclIsKindOf(Class)) =\nsubject.superClosure ->union(subject.acquires.\nsuperClosure )\ncontext\nComponentClassAbstraction\ninv: ve.superClass = se. superClass\ninv: ve. hasStereotype (\u2019ComponentClass \u2019)\ninv: se.isSubject\nimplies (ve. hasStereotype (\u2019subject\n\u2019) and ve.ownedMember ->select( oclIsKindOf (\nAssociation )) = se.ownedMember ->select(\noclIsKindOf (Acquires)))\ncontext\nClassAbstraction\ninv: ve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\ninv: ve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public)\ninv: ve.\u2018inv \u2019 = se.\u2018inv \u2019\n-- copy\npowertypeExtent\nthat is only\nallowed\nfor\nclass\ninv: ve. powertypeExtent = se. powertypeExtent\ncontext\nOperationAbstraction\ninv: ve.class = se.class\nFor the black box type view, only publicly visible at-\ntributes and operations of classes (as opposed to Compo-\nnentClasses) used by the subject can be seen. This is spec-\ni\ufb01ed in the \ufb01rst rule which de\ufb01nes owned members of the\nview and thus serves as the starting point of the transfor-\nmation. cbbTypes is a utility function de\ufb01ned in the SUM\nwhich computes the black box types by selecting the types\nof the subject\u2019s public attributes and parameter types of its\npublic operations.\nClass invariants and potential powertypes and connections\nto the classes in this view are shown as well. There may\nalso be Enumerations, for which the EnumerationLiterals\nare displayed.\nThe transformation rules for this view are almost the same\nas the realization transformation constraints from the pack-\nage Transformation::Realization::Structural::Class::Type. The\ndi\ufb00erences are the select(visibility=#public) statements for\noperations and attributes.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassType\ninv: ownedMember ->select( oclIsKindOf(Class) or\noclIsKindOf(\u2018Enumeration \u2019) or\noclIsKindOf (\nAssociation)) = subject ->union(subject.cbbTypes)\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nClassAbstraction\ninv: not se.oclIsKindOf ( ComponentClass ) implies (\nve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\nve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public))\ninv: ve. powertypeExtent = se. powertypeExtent\ninv: ve. superClass = se.superClass\ninv: \u2018ve.inv \u2019 = \u2018se.inv \u2019\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nEnumerationAbstraction\ninv: ve. ownedLiteral = se. ownedLiteral\ncontext\nEnumerationLiteralAbstraction\ninv: ve. specification = se. specification .\nstringInSignature\n5.\nNAVIGATION\nMost of today\u2019s tools use some combination of trees to\norganize the content of models as well as the views used to\nvisualize a software system or component. In an any envi-\nronment incorporating a number of di\ufb00erent tools there is\ninvariably a large number of di\ufb00erent trees storing a het-\nerogeneous mix of artifacts including model elements (e.g.\nclasses, instances, associations), diagrams (e.g.\nclass dia-\ngrams, state diagrams) and other artifact types (source code,\nXML \ufb01les, con\ufb01guration \ufb01les ). To work with all the views in\na traditional development environment, therefore, engineers\ntypically have to learn about the organization structures of\nall the incorporated tools.\nIn contrast to conventional paradigms for organizing and\nnavigating the many views used to visualize a system, OSM\nemploys the metaphor of a multi-dimensional cube. More\nspeci\ufb01cally, as illustrated in Figure 9, OSM regards dimen-\nsion of the underlying methodology as representing a di\ufb00er-\nent dimension of the cube, and each independently variable\naspect of that dimension is a selectable dimension element.\nSelecting a view thus simply corresponds to selecting a single\ncell within the cube. In general, three types of dimensions\nare supported: static dimensions in which the number of\nFigure 9: Dimension-based navigation.\nselectable elements (i.e. coordinates) is \ufb01xed, dynamic di-\nmensions in which the number of elements is dynamic (i.e.\nderived from the SUM), and mixed dimensions which have\nboth static and dynamic elements.\nTo support the OSM dimension based navigation metaphor\nfor KobrA, we de\ufb01ned the seven dimensions indicated on the\nleft hand side of Figure 10 which is a sceenshot of nAOMI.\nThe Abstraction dimension (not expanded here), which has\nthree static dimension elements, PIM (platform independent\nmodel), PSM (platform speci\ufb01c model) and Code, captures\nthe model-driven development concern of KobrA. The ver-\nsion dimension captures the state of the modeled system at\nspeci\ufb01c points in time. The Component dimension, which\nhas dynamic dimension elements de\ufb01ned by instances of the\nclass ComponentClass in the SUM, captures the component-\nbased development concern of KobrA.\nThe Encapsulation dimension, which has two \ufb01xed ele-\nments, supports the distinction between Speci\ufb01cation (black\nbox) and Realization (white box) views of components, while\nthe Projection dimension with the \ufb01xed elements Structural,\nOperational and Behavioral covers the di\ufb00erent information\ntypes. The Granularity dimension provides a \ufb01ner grained\ndistinction between views describing the types used by com-\nponents (Type granularity) and views describing the required\nand provided interfaces (Service granularity). The Opera-\ntion dimension allows a selection of individual operations.\nIn the ideal case, when all views are truly orthogonal, the\nchoices that can be made in each dimensions are completely\nindependent.\nHowever, this is very di\ufb03cult to achieve in\nsoftware engineering. The approach still works if the views\nare not completely orthogonal, but dependencies then occur\nbetween di\ufb00erent choices in di\ufb00erent dimensions, so that the\ndecisions made in one dimensions may a\ufb00ect choices possi-\nble in another dimension. This is best handled by giving\ndimensions a precedence ranking determined by the order\nin which they appear (the top being the highest). When an\nelement in a dimension is selected, the tool automatically\nmakes default selections for dimensions of lower precedence\n(i.e.\ndimensions lower down) and disables selections that\nwould navigate to cells (i.e. views) which are not (yet) de-\n\ufb01ned by the method at hand.\n6.\nSHOPPING CART EXAMPLE\nTo show how a software system can be speci\ufb01ed using\nnAOMi, this section presents a case study based on a shop-\nping cart system. A ShoppingCart component collects and\nFigure 10: Speci\ufb01cation Structural View.\nmanages the products selected by users and supports pay-\nment via a credit card.\nFigure 10 illustrates a structural\nview of the component.\nIn the dimension navigator on the left hand side, PIM\nwas chosen for the \u201cAbstraction Level\u201d (not expanded in the\nscreenshot). The second dimension is the state of the soft-\nware system at a certain point in time. The picture shows\nthat the latest available version was chosen. As with every\nchoice in a dimension, it may in\ufb02uence the options in lower\nranked dimensions. The component under consideration is\nthe ShoppingCart, for which a black box view is selected\nin the next dimension. After the user selects the structural\nprojection option and the service level granularity, the tool\nautomatically chooses the option for all operations in the\nlast dimension, as there is no editor registered for the other\noptions.\nThe component under development is presented with the\nstereotype subject and its relationship to other components\nand classes is shown in the view, which corresponds to a cell\nof the multi-dimensional navigation cube, and is generated\non-the-\ufb02y from the SUM when it is selected. The classes\nProduct and CreditCard can be used as data types in the\noperations of the component.\nFigure 11 illustrates the operational view in which an\noperation can be formalized using pre- and postconditions.\nThe precondition corresponds to the assumes clause in and\nthe postcondition corresponds to the result clause. As in the\nUML, the precondition of an operation must be true when\nthe operation is invoked and the postcondition must be true\nwhen the operation is \ufb01nished. The operation addProduct\nin Figure 11 must be in state CollectingProducts or Empty\nwhen invoked. This is also visible in the behavioral view,\nFigure 11: addProduct() Operation Speci\ufb01cation.\nsince there are only two transitions with the operation ad-\ndProduct. Both leads to the state CollectingProducts which\nis also a postcondition of the operation. The second post-\ncondition is that the cost attribute of the component must\nbe increased by the price of the added product. The pre- and\npostcondition can be expressed using the OCL. The proper-\nties of the component, states and operation parameters can\nbe used to formalise the constraints like as in this example.\nFigure 12 shows the publicly visible behaviour of the Shop-\npingCart component with states and transitions. The condi-\ntional transitions map to operations of the component. Like\nevery view, this view is also synchronized with the SUM so\nthat it is guaranteed that its operations, states and proper-\nties are consistent with those in the structural view.\nFigure 12: Speci\ufb01cation Behavioral Model.\nAlthough the operational view seems to be similar to the\nbehavioral view because of the overlapping information within\nthem, there are signi\ufb01cant di\ufb00erences. The focus of the op-\nerational view is on a precise formal de\ufb01nition of an opera-\ntion of a component. The operations can be enriched by pre-\nand postconditions which can be de\ufb01ned using complex OCL\nstatements, that formalize the complete behavior of an op-\neration. The additional information in the OCL statements\ncan be used for code generation and documentation.\n7.\nCONCLUSION\nAt the beginning of the paper we identi\ufb01ed three funda-\nmental hypothesis upon which the notion of OSM is based\n\u2014 (a) that it is feasible to integrate the many di\ufb00erent kinds\nof artifacts used in contemporary software engineering meth-\nods within a single coherent methodology in which they are\ntreated as views, (b) that it is feasible to create an e\ufb03-\ncient and scalable way of supporting these views by gener-\nating them dynamically, on-the-\ufb02y, from a Single Underly-\ning Model (SUM) using model-based transformations and\n(c) that it is feasible to provide an intuitive metaphor for\nnavigating around these many views by adapting the ortho-\ngraphic projection technique underpinning the CAD tools\nused in other engineering disciplines.\nThe prototype tool, nAOMi, described in this paper rep-\nresents the \ufb01rst step towards demonstrating the validity of\nthese hypotheses and showing that OSM is a viable approach\nto software engineering. Of the three hypotheses, (a) and (c)\nare most convincingly demonstrated by the prototype, since\nit shows that it is indeed possible to support all the views\nof the KobrA method within a single navigation metaphor.\nThe prototype tool does not demonstrate the validity of hy-\npothesis (b) to the same extent as the others due to its\nsmall size. Although it demonstrates the feasibility of gen-\nerating views from the SUM and vice-versa, the question of\nwhether such an approach scales up to large environments\nis still open.\nAlthough nOAMi is the only tool developed with the spe-\nci\ufb01c aim of supporting KobrA-based OSM, several other\ntools and methods have similar properties or aims.\nFor\nexample, Glinz et al.\n[10] describe a tool with a \ufb01sheye\nzooming algorithm which lets the user view a model with\nvarying amounts of detail depending on the context. It has\nto be investigated whether it is possible to combine the \ufb01sh-\neye zooming concept with the dimension-based navigation\nparadigm. While the KobrA 2.0 implementation of nAOMi\nheavily uses UML diagrams for developers, Glinz et al. use\ncustom diagram types, e.g.\nfor structural and behavioral\nviews.\nAn approach which also emphasizes the description of for-\nmal consistency rules (correspondences) between views is\nRM-ODP [5][6].\nHowever, this approach does not explic-\nitly mention the notion of a SUM and thus implies that\nconsistency rules should be de\ufb01ned in a pairwise fashion be-\ntween individual pairs of views. ArchiMate [7], which com-\nplements TOGAF [12], is an enterprise architecture mod-\neling language which o\ufb00ers two orthogonal \u201ddimensions\u201d for\nmodeling, (business, architecture, and technology) layers and\n(informational, behavioral and structural) aspects and also\nsuggests two more dimensions, purpose and abstraction level.\nHowever, as many of these views span multiple choices of a\nsingle\u201cdimension\u201d, the intuitive dimension-based navigation\nmetaphor of OSM can not be easily applied. There are also\nmore general approaches for view-based modeling but they\nare less speci\ufb01c in terms of consistency rules between views\nand provide little guidance on how to manage and navigate\nviews, for example the Zachman Framework [14].\nRegarding the practical use of OSM environments in the\nfuture, the biggest challenge is developing appropriate SUM\nmetamodels which can accommodate all the types of views\nand services that software engineers are accustomed to to-\nday. For this \ufb01rst prototypical SUM-based environment sup-\nporting the OSM approach we had a method at our disposal\n(KobrA) that already de\ufb01ned a full set of orthogonal UML-\nbased views. This allowed us to model the required SUM\nand view metamodels by simply adapting the UML meta-\nmodels, removing and adding model elements as needed.\nIn doing so we were able to manually ensure that the meta-\nmodels ful\ufb01lled the two core requirements of SUM-based en-\nvironments \u2014 (1) being minimalistic and (2) redundancy\nfree. If SUM-based software engineering environments are\nto take o\ufb00, and to be introduced into existing, heteroge-\nneous environments, more sophisticated ways of integrating\nexisting metamodels into a single uni\ufb01ed metamodel will be\nrequired.\n8.\nREFERENCES\n[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,\nO. Laitenberger, R. Laqua, D. Muthig, B. Paech,\nJ. W\u00a8ust, and J. Zettel. Component-Based Product Line\nEngineering with UML. Addison Wesley, Reading,\nMassachusetts, USA, 1st edition, November 2001.\n[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic\nSoftware Modeling: A Practical Approach to\nView-Based Development. In Evaluation of Novel\nApproaches to Software Engineering, volume 69 of\nCommunications in Computer and Information\nScience, pages 206\u2013219. Springer Berlin Heidelberg,\n2010.\n[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic\nService Modeling. In Proceedings of 15th IEEE EDOC\nConference Workshops (EDOCW), Helsinki, Finland,\n2011.\n[4] Eclipse Foundation. UML2Tools.\nhttp://wiki.eclipse.org/MDT-UML2Tools, 2013.\n[5] ISO/IEC and ITU-T. The Reference Model of Open\nDistributed Processing. RM-ODP, ITU-T Rec.\nX.901-X.904 / ISO/IEC 10746.\nhttp://standards.iso.org/\nittf/PubliclyAvailableStandards/index.html,\n1998.\n[6] J. I. J. Jose Raul Romero and A. Vallecillo. Realizing\nCorrespondences in MultiViewpoint Speci\ufb01cations. In\nProceedings of the Thirteenth IEEE International\nEDOC Conference, 1 - 4 September 2009, Auckland,\nNew Zealand, September 2009.\n[7] M. Lankhorst. Enterprise Architecture at Work.\nSpringer Berlin Heidelberg, 2009.\n[8] Object Management Group (OMG). OMG Uni\ufb01ed\nModeling Language (OMG UML), Superstructure,\nV2.1.2.\nhttp://www.omg.org/cgi-bin/doc?formal/07-11-02,\nNovember 2007.\n[9] Object Management Group (OMG). Meta Object\nFacility (MOF) 2.0 Query/View/Transformation, v1.0.\nhttp://www.omg.org/spec/QVT/1.0/PDF/, April 2008.\n[10] C. Seybold, M. Glinz, S. Meier, and N. Merlo-Schett.\nAn e\ufb00ective layout adaptation technique for a\ngraphical modeling tool. In Proceedings of the 2003\nInternational Conference on Software Engineering,\nPortland, 2003.\n[11] The Atlas Transformation Language (ATL). O\ufb03cial\nWebsite. http://www.eclipse.org/atl/, 2013.\n[12] The Open Group. TOGAF Version 9 - The Open\nGroup Architecture Framework.\nhttp://www.opengroup.org/architecture/\ntogaf9-doc/arch/index.html, Feb 2009.\n[13] University of Mannheim - Software Engineering\nGroup. nAOMi - opeN, Adaptable, Orthographic\nModeling EnvIronment.\nhttp://eclipselabs.org/p/naomi.\n[14] J. A. Zachman. The Zachman Framework: A Primer\nfor Enterprise Engineering and Manufacturing.\nhttp://www.zachmaninternational.com, 2009.\n",
    "pdf_url": "",
    "references": [
      "[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,",
      "O. Laitenberger, R. Laqua, D. Muthig, B. Paech,",
      "J. W\u00a8ust, and J. Zettel. Component-Based Product Line",
      "Engineering with UML. Addison Wesley, Reading,",
      "Massachusetts, USA, 1st edition, November 2001.",
      "[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic",
      "Software Modeling: A Practical Approach to",
      "View-Based Development. In Evaluation of Novel",
      "Approaches to Software Engineering, volume 69 of",
      "Communications in Computer and Information",
      "Science, pages 206\u2013219. Springer Berlin Heidelberg,",
      "2010.",
      "[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "University of Kent"
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "A Prototype Implementation of an Orthographic Software Modeling Environment",
    "resume": "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
    "auteurs": [
      "Colin Atkinson",
      "Dietmar Stoll",
      "Jacques Robin",
      "Recife",
      "Brasil",
      "D.2.2"
    ],
    "institutions": [
      "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
      "Colin Atkinson University of Mannheim,",
      "Dietmar Stoll University of Mannheim, TunjicUniversity of Mannheim,"
    ],
    "mots_cles": [
      " Orthographic Software Modeling",
      " View-based Modeling "
    ],
    "texte_integral": "A Prototype Implementation of an Orthographic Software\nModeling Environment\nColin Atkinson\nUniversity of Mannheim,\nGermany\natkinson@informatik.uni-\nmannheim.de\nDietmar Stoll\nUniversity of Mannheim,\nGermany\nstoll@informatik.uni-\nmannheim.de\nChristian Tunjic\nUniversity of Mannheim,\nGermany\ntunjic@informatik.uni-\nmannheim.de\nJacques Robin\nUniversidade Federal de\nPernambuco, Recife, Brasil\njr@cin.ufpe.br\nABSTRACT\nOrthographic Software Modeling (OSM) is a view-centric\nsoftware engineering approach that aims to leverage the or-\nthographic projection metaphor used in the visualization of\nphysical objects to visualize software systems. Although the\ngeneral concept of OSM does not prescribe speci\ufb01c sets of\nviews, a concrete OSM environment has to be speci\ufb01c about\nthe particular views to be used in a particular project. At\nthe University of Mannheim we are developing a prototype\nOSM environment, nAOMi, that supports the views de\ufb01ned\nby the KobrA 2.0 method, a version of KobrA adapted for\nOSM. In this paper we provide an overview of the KobrA 2.0\nmetamodel underpinning nAOMi and give a small example\nof its use to model a software system.\nCategories and Subject Descriptors\nD.1.7 [Programming Techniques]: Visual Programming;\nD.2.2 [Design Tools and Techniques]: Computer-aided\nsoftware engineering (CASE); D.2.6 [Software Engineer-\ning]: Programming Environments\u2014Graphical environments\nKeywords\nOrthographic Software Modeling, View-based Modeling\n1.\nINTRODUCTION\nOrthographic Software Modeling (OSM) is based on three\nfundamental hypotheses \u2014 (a) that it is feasible to inte-\ngrate the many di\ufb00erent kinds of artifacts used in contempo-\nrary software engineering methods within a single coherent\nmethodology in which they are treated as views, (b) that it\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for pro\ufb01t or commercial advantage and that copies\nbear this notice and the full citation on the \ufb01rst page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior speci\ufb01c\npermission and/or a fee.\nVAO \u201913, July 2, 2013, Montpellier, France\nCopyright 2013 ACM 978-1-4503-2041-2 ...$15.00.\nis feasible to create an e\ufb03cient and scalable way of support-\ning these views by generating them dynamically, on-the-\ufb02y,\nfrom a Single Underlying Model (SUM) using model-based\ntransformations and (c) that it is feasible to provide an in-\ntuitive metaphor for navigating around these many views\nby adapting the orthographic projection technique under-\npinning the CAD tools used in other engineering disciplines.\nFigure 1: Orthographic Projection.\nAs shown in Figure 1, the main advantages of using the\nidea of orthographic projection to de\ufb01ne the views used\nto visualize and described a system are that they (a) can\nbe organized according to a simple and easy-to-understand\nmetaphor and (b) collectively represent all the properties of\na system with minimal overlap and redundancy. In practice\nthis translates into a set of \u201cdimensions\u201d, each containing\nwell de\ufb01ned choices (or so called \u201cdimension elements\u201d) that\ncan be used to select individuals views.\nAs shown in Figure 2, the main advantage of making the\nartifacts used to describe a software system views of a SUM\nis that the number of pairwise coherence relationships that\nhave to be maintained is reduced and new views can be in-\ntroduced by simply de\ufb01ning their relationship to the SUM.\nMoreover, the importance of this advantage grows quickly\nas the size of the system and the complexity of the deployed\ndevelopment methodology increase. Another important ad-\nvantage is that the dominance of one particular kind of view\nover the development process (e.g. code) at the expense of\nother kinds of views (e.g. graphical models) is reduced so\nthat any appropriate type of views can be used to enrich\nthe underlying description of the system, depending on the\nneeds and skills of the stakeholder involved. This makes it\npossible to subsume all view types under the same, overarch-\nSUM\nSUM / View Centric Environment\nArtifact / Tools Centric Environment\nFigure 2: Consistency Dependencies in Artifact-oriented versus View-oriented Environments.\ning development process and methodology (e.g. agile-driven,\nfocusing on small development cycles, or model-driven de-\nvelopment, based on transformations between abstraction\nlevels). Although the details of how the views are created\nfrom the SUM and how the SUM is updated from the views\nare not central to the approach, a natural implementation\nis to use the visualization and transformation technologies\no\ufb00ered by model driven software engineering (MDSE).\nTo explore the validity of these hypotheses at the Uni-\nversity of Mannheim we have been developing a prototype\nOSM modeling environment based on an enhanced version\nof the KobrA method for model-driven, component-oriented\ndevelopment, KobrA 2.0 [1]. This was chosen as a basis for\nthe prototype, known as the Open, Adaptable, Orthographic\nModeling Environment (nAOMi) [13] because its views were\ndesigned with the precise goals of being (a) genuine pro-\njections of a subject containing carefully selected subsets\nof information about that subject, (b) minimalistic in the\nsense that they should overlap to the smallest extent possible\nand contain the minimum necessary models elements, and\n(c) selectable via a set of independent \u201cdimensions\u201d which\nre\ufb02ect di\ufb00erent fundamental concerns of development (i.e.\nabstraction levels, composition or variants). In other words,\nKobrA already provided one of the \u201cmost orthogonal\u201d sets\nof views for visualizing software systems of any contempo-\nrary method. More details about the actual views and di-\nmensions de\ufb01ned in KobrA are presented in the following\nsections. More information on OSM can be found in [2] and\n[3].\nnAOMi is implemented as an Eclipse plugin using the\nEclipse Modeling Framework (EMF) as the underlying mod-\neling platform and UML 2.0 tools [4] to generate and edit\nviews.\nThe KobrA 2.0 metamodel on which the current\nversion of nAOMi is based is a specialization of the UML\nmetamodel composed of three separate packages \u2014 one for\nthe SUM, one for the views and one for the transformations\n(Figure 3). The UML was chosen as the base language be-\ncause of its maturity and widespread acceptance, making the\nenvironment usable to the largest possible body of develop-\ners. UML elements not needed in KobrA 2.0 are excluded\nusing OCL constraints while new elements or properties are\nKobrA2\nTransformation\nSUM\nViews\nFigure 3: KobrA 2.0 Top Level Packages.\nintroduced by specializing existing elements.\nThe unique contribution of this paper is to elaborate on\nthe structure of the KobrA 2.0 metamodel and how it is used\nto drive nAOMi. The three following sections each focus on\none of the three main components of the metamodel \u2014 the\nSUM, the views and the transformations . This is followed\nby a brief overview of the OSM navigation paradigm in Sec-\ntion 5 before a small example of the approach is presented in\nSection 6. Section 7 then concludes the paper with related\nand future work.\n2.\nSUM PACKAGE\nFigure 4 depicts the internal structure of the SUM pack-\nage which is based on the UML metamodel. There are three\nmain subpackages, two containing the structural and behav-\nioral constructs respectively, and one containing the con-\nstraints that ensure that the metaclasses are used according\nto the KobrA conventions and rules.\nThe Classes subpackage of the Structure package contains\nsome of the most fundamental elements of the KobrA meta-\nmodel, such as Class and ComponentClass.\nThe internal\nstructure of this package is illustrated in Figure 5. Com-\nponentClass represents objects with complex and reusable\nbehaviors, while Class captures simple \u201cdata type\u201d objects\nthat have only very simple or non-reusable behaviors. The\nmodeler has to decide whether it is necessary to model a\nspeci\ufb01c part of the system as a ComponentClass and include\nstate charts and activity diagrams, or whether it is su\ufb03cient\nto use a Class (which is limited to using OCL constraints).\nComponentClass inherits (indirectly via Class) from Com-\nmunications so it also has the isActive attribute. This makes\nKobrA2::SUM::Constraint::Behavioral\nKobrA2::SUM::Constraint::Structural\nKobrA2::SUM::Constraint\nKobrA2::SUM::Constraint::Common\nKobrA2::SUM::Behavior::ProtocolStateMachines\nKobrA2::SUM::Behavior::Common\nKobrA2::SUM::Behavior::Activities\nKobrA2::SUM::Behavior::Actions\nKobrA2::SUM::Behavior\nKobrA2::SUM::Structure::Classes\nKobrA2::SUM::Structure::Types\nKobrA2::SUM::Structure::Instances\nKobrA2::SUM::Structure::Elements\nKobrA2::SUM::Structure\nKobrA2::SUM::Constraint::OclExpressions\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\nFigure 4: KobrA 2.0 SUM Package.\nit possible to model whether its instances are active or pas-\nsive. Active objects, which can be used to model threads and\nprocesses ([8] p. 438), start to execute their behavior as soon\nas they are created and perform operations spontaneously.\nA ComponentClass may exhibit complex behavior. In Ko-\nbrA, this behavior may be speci\ufb01ed in the form of\nUML\nState Diagrams (de\ufb01ning acceptable operation invocation\nsequences), and in the form of Activities (de\ufb01ning algorithms\nof operations). UML Interaction elements (in sequence dia-\ngrams) can be derived from the activity elements and thus\nare not included in the SUM. As KobrA aims to facilitate\nautomatic checking of allowed sequences of operation calls,\nProtocol State Machines are supported instead of general\nstate machines. Since the latter include a large variety of\nelements not needed for specifying acceptable operation se-\nquences or automatic checking, OCL constraints are used to\nprohibit the use of unwanted features.\ncontext\nComponentClass\n-- only\nallow\nActivity\nelements\nor\nProtocolStateMachines\ninv: ownedBehavior ->forAll( oclIsKindOf( Actitivity) or\noclIsKindOf ( ProtocolStateMachine ))\nFor example, since KobrA has no concept of roles for com-\nponents, the use of role also needs to be prohibited. The part\nassociation refers to owned properties of components whose\nattribute isComposite is true. As KobrA uses associations\nlike nests and creates for components, part, required and\nprovided are not needed. Connectors (i.e. delegation and\nassembly) are not used in KobrA either so ownedConnector\nis excluded.\nClass\nKobrA2::SUM::Structure::Classes\nGeneralizationSet\nAssociationClass\nComponentClass\nProperty\nUsage\nAssociation\nOperation\nPackageable\nElement\nParameter\nAcquires\nCreates\nNests\nUML::Component::PackagingComponents::Component\nUML::CommonBehaviors::Communications::Class\n+ownedOperation\n*\n+class\n0..1\n+supplier\n1..*\n{subsets supplierDependency}\n+supplierUsage\n*\n+client\n1..*\n{subsets clientDependency}\n+clientUsage\n*\n+ownedAttribute\n*\n+class\n0..1\n+powertype\n0..1\n+powertypeExtent\n*\n+packagedElement\n*\n{subsets component}\n+componentClass\n0..1\n+/superClass\nFigure 5: KobrA 2.0 Classes Package.\ncontext\nComponentClass\ninv: role ->union(part)->union( ownedConnector )\n->union( collaborationUse )-> union( representation )\n->union( realization)->union(required)\n->union(provided)->isEmpty ()\n3.\nVIEWS PACKAGE\nThe structure of the Views package is illustrated in Figure\n6. Again, since most of the views de\ufb01ned in KobrA 2.0 are\nbased on UML diagrams, the view metamodels have similar\nelements to the SUM metamodel. The big di\ufb00erence to the\nSUM is that there are no restrictions on the use of the view\nmetamodel elements.\nFor instance, views for a particular\npurpose such as supporting model checkers can be supported\nby adding elements unrelated to the UML.\nThe substructure of the Views package re\ufb02ects the types\nand organization of the KobrA views according to the view\n\u201cdimensions\u201d supported in nAOMi (cf. example in Section\n6). At the top level, the Views package is thus decomposed\ninto the Speci\ufb01cation and Realization options of the encap-\nsulation dimension.\nThese, in turn are both decomposed\ninto the Structural, Behavioral and Operational options of\nthe Projection dimension.\nFinally, with the exception of\nthe behavioral option, these are also all subdivided into the\nService and Type options of the granularity dimension. This\ndimension, with its two options, is an addition to the original\nversion of KobrA.\nThe Service view shows the direct, publicly visible rela-\ntionships of the subject ComponentClass to other Compo-\nnentClasses, while the Type view shows the publicly visi-\nble relationships of the subject to simple Classes. As with\nthe SUM, constraints have been de\ufb01ned to control what can\ngo into each view and when they are well formed. For ev-\nery view, a constraint enumerates all allowed elements (not\nshown in this paper).\nIn the following, some of the other constraints for the\nService view are elaborated. Since this view is a black-box\nview, the internals of ComponentClasses (nestedClassi\ufb01er)\nare not shown.\ncontext\nComponentClass\n-- no nested\nclassifiers , no\nprotocol\ninv: nestedClassifier ->union(protocol)->isEmpty ()\nClasses are only allowed if they are generalizations of Com-\nponentClasses, (or any of its superclasses, since a Compo-\nnentClass may inherit from a class as shown in the con-\nstraints with context Class. The following invariants ensure\nthat only publicly visible attributes and operations are in\nthis view, for both classes and ComponentClasses (which\ninherit from Class).\nClass\nService\nType\nInstance\nService\nType\nStructural\nSpecification\nOperational\nService\nType\nProtocol\nBehavioral\nKobrA2::Views::Derived\nComponentClassDependencies\nOperationDependencies\nInstance\nService\nType\nClass\nService\nType\nStructural\nRealization\nOperational\nService\nType\nBehavioral\nAlgorithm\nViews\nConcreteSyntax\nSubject\n<<import>>\n<<merge>>\n<<merge>>\n<<import>>\n<<merge>>\n<<import>>\nFigure 6: KobrA 2.0 Views package nesting.\ncontext\nClass\n-- only\nallow\nclasses\nthat\nare\ndirect or\nindirect\ngeneralizations\nof\nComponentClasses\nin this\nview\ndef: ccGeneralization : generalization .specific ->\nexists( oclIsKindOf ( ComponentClass ))\ninv:\ngeneralization .specific ->select( oclIsTypeOf (\nClass))->exists(s|s. ccGeneralization )\nor\nccGeneralization\n-- only\npublic\nattributes\nin this\nview\ninv: ownedAttribute ->forAll(visibility =# public)\n-- only\npublic\nOperations\nare\nallowed\nin the\nspecification\ninv: ownedOperation ->forAll(visibility =# public)\nOnly operation signatures are shown in this view, so pre-,\npost- and bodyconditions, as well as activities are omitted,\nwhich is re\ufb02ected in the last constraint.\ncontext\nOperation\n-- only\nthe\nsignature\nof the\nOperation\nis shown , not\nits\nbehavior (role\nname \"method\" refers to the\nActivities\nof the\noperation), or\ndependencies\ninv: method ->union( precondition )->union(body)->union(\npostcondition )->isEmpty ()\n4.\nTRANSFORMATIONS PACKAGE\nThe package AllViews provides the foundation for speci-\nfying the transformations between the SUM and the views\nin both directions. Part of the package\u2019s contents are shown\nin Figure 7.\nThe Abstraction concept (which is in fact a\nKobrA2::Transformation::Common::AllViews\nAbstraction\nTransformationExpression\nViewElement\nSumElement\nView\nKobrA2::SUM::Structure::Elements::Element\nKobrA2::Views::ConcreteSyntax::Element\nKobrA2::SUM::Constraint::Behavioral::Exp\nressionInOcl\nKobrA2::Views::Subject::View\n{subsets mapping}\n0..1\n0..1\n{subsets clientDependency}\n+abstraction 1\n{subsets client}\n+ve 1\n1..*\n1\n{subsets supplier}\n+se 1\n{subsets supplierDependency}\n+abstraction 1..*\nFigure 7: Transformation abstractions.\ndependency reused from the UML but with additional con-\nstraints) plays the key role in relating elements from the\nSUM to elements of a view. Abstraction is actually mapped\nto ExpressionInOcl.\nWhen appearing in transformations,\nthe equals sign links elements in the SUM to the respective\nelements in the view, and vice versa. For instance, equal-\nity of the general meta-association of a Generalization in\na transformation invariant means that, when following gen-\neral, there must be an element in the SUM and in the view\nfor which similar transformation expressions are speci\ufb01ed.\nIn the case of KobrA 2.0, which has many projections that\njust select a subset of elements using one-to-one abstrac-\ntions, this allows concise declarative TransformationExpres-\nsions. Together with the view constraints, a CASE tool can\nbe implemented which uses a transformation language of the\nimplementor\u2019s choice, for instance the Atlas Transformation\nLanguage (ATL) [11] or QVT [9]. The role names se and ve\nare short for SumElement and ViewElement, respectively.\nThese roles subset the client and supplier roles from the\nUML.\nSUM elements are translated into UML elements with\nstereotypes, so that the views are easy to manage for de-\nvelopers familiar with the UML. The bidirectional mappings\nbetween stereotyped view elements and non-stereotyped SUM\nelements are expressed in the constraints of the Association-\nAbstraction, a subclass of the Abstraction from the AllViews\npackage. This is also an example of a transformation which\nis reused in other views.\ncontext\nAssociationAbstraction\ninv: ve.memberEnd = se.memberEnd\ninv: ve.ownedEnd = se.ownedEnd\nivn: ve. navigableOwnedEnd = se. navigableOwnedEnd\ninv: se. oclIsKindOf(Acquires) implies ve.\nhasStereotype (\u2019acquires \u2019)\ninv: ve. hasStereotype (\u2019acquires \u2019)\nimplies\nse.\noclIsKindOf (Aquires)\ninv: se. oclIsKindOf(Nests) implies\nve. hasStereotype (\u2019\nnests \u2019)\ninv: ve. hasStereotype (\u2019nests \u2019)\nimplies se. oclIsKindOf\n(Nests)\ninv: se. oclIsKindOf (Creates) implies\nve. hasStereotype\n(\u2019creates \u2019)\ninv: ve. hasStereotype (\u2019creates \u2019)\nimplies se.\noclIsKindOf (Creates)\nFigure 8 shows the main elements involved in the trans-\nformation of the black box structural view for Component-\nClasses. The \ufb01rst transformation constraint is on the view\nand declares the starting point for the transformation. It\nstates that the subject ComponentClass and its generaliza-\ntions (using a SUM utility function, superClosure) are in the\nview.\nThe following transformation rules illustrate how to create\nthe output (i.e. view) elements from the input (i.e. SUM) el-\nements, such as the publicly visible attributes and operations\nof the ComponentClass and the acquired ComponentClasses.\nThe \ufb01rst constraint for ComponentClassAbstraction states\nthat references to potential general classes (and Component-\nClasses) of ComponentClasses are mirrored in the view. In\naddition, ComponentClasses will be shown with the corre-\nsponding stereotypes.\nThe ComponentClass owns various\ntypes of associations, so in this view only the acquires asso-\nciations are selected (whose transformation rules are cov-\nered in the common transformation packages).For classes\nand ComponentClasses, only publicly visible attributes and\noperations appear in the view.\nClass invariants are also\ncopied. Classes that may appear in this view (e.g. as gener-\nalizations of ComponentClasses) may have a powertype (role\nname powertypeExtent) which will be displayed.\nThe last transformation statement copies the class refer-\nences of operations. As with all views, the transformation\nrules, the common transformation statements (which also\ncover operations) and the view constraints serve as a speci-\n\ufb01cation for the implementation of a view. Individual CASE\ntools can use di\ufb00erent implementation techniques as long as\nthey conform to the semantics of these rules and constraints.\nKobrA2::Transformation::Specification::Structural::Class::Service\nComponentClassAbstraction\nKobrA2::Transformation::Common::Feature::OperationAbstraction\nKobrA2::Transformation::Common::AllViews::Abstraction\nKobrA2::SUM::Structure::Classes::ComponentClass\nKobrA2::SUM::Structure::Classes::Operation\nKobrA2::SUM::Structure::Classes::Class\nOperationAbstraction\nClassAbstraction\n+se\n1\n1..*\n+se\n1\n1..*\n+se\n1\n1..*\nFigure 8: Transformation to the Speci\ufb01cation Structural Service View.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassService\ninv: ownedMember ->select( oclIsKindOf(Class)) =\nsubject.superClosure ->union(subject.acquires.\nsuperClosure )\ncontext\nComponentClassAbstraction\ninv: ve.superClass = se. superClass\ninv: ve. hasStereotype (\u2019ComponentClass \u2019)\ninv: se.isSubject\nimplies (ve. hasStereotype (\u2019subject\n\u2019) and ve.ownedMember ->select( oclIsKindOf (\nAssociation )) = se.ownedMember ->select(\noclIsKindOf (Acquires)))\ncontext\nClassAbstraction\ninv: ve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\ninv: ve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public)\ninv: ve.\u2018inv \u2019 = se.\u2018inv \u2019\n-- copy\npowertypeExtent\nthat is only\nallowed\nfor\nclass\ninv: ve. powertypeExtent = se. powertypeExtent\ncontext\nOperationAbstraction\ninv: ve.class = se.class\nFor the black box type view, only publicly visible at-\ntributes and operations of classes (as opposed to Compo-\nnentClasses) used by the subject can be seen. This is spec-\ni\ufb01ed in the \ufb01rst rule which de\ufb01nes owned members of the\nview and thus serves as the starting point of the transfor-\nmation. cbbTypes is a utility function de\ufb01ned in the SUM\nwhich computes the black box types by selecting the types\nof the subject\u2019s public attributes and parameter types of its\npublic operations.\nClass invariants and potential powertypes and connections\nto the classes in this view are shown as well. There may\nalso be Enumerations, for which the EnumerationLiterals\nare displayed.\nThe transformation rules for this view are almost the same\nas the realization transformation constraints from the pack-\nage Transformation::Realization::Structural::Class::Type. The\ndi\ufb00erences are the select(visibility=#public) statements for\noperations and attributes.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassType\ninv: ownedMember ->select( oclIsKindOf(Class) or\noclIsKindOf(\u2018Enumeration \u2019) or\noclIsKindOf (\nAssociation)) = subject ->union(subject.cbbTypes)\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nClassAbstraction\ninv: not se.oclIsKindOf ( ComponentClass ) implies (\nve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\nve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public))\ninv: ve. powertypeExtent = se. powertypeExtent\ninv: ve. superClass = se.superClass\ninv: \u2018ve.inv \u2019 = \u2018se.inv \u2019\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nEnumerationAbstraction\ninv: ve. ownedLiteral = se. ownedLiteral\ncontext\nEnumerationLiteralAbstraction\ninv: ve. specification = se. specification .\nstringInSignature\n5.\nNAVIGATION\nMost of today\u2019s tools use some combination of trees to\norganize the content of models as well as the views used to\nvisualize a software system or component. In an any envi-\nronment incorporating a number of di\ufb00erent tools there is\ninvariably a large number of di\ufb00erent trees storing a het-\nerogeneous mix of artifacts including model elements (e.g.\nclasses, instances, associations), diagrams (e.g.\nclass dia-\ngrams, state diagrams) and other artifact types (source code,\nXML \ufb01les, con\ufb01guration \ufb01les ). To work with all the views in\na traditional development environment, therefore, engineers\ntypically have to learn about the organization structures of\nall the incorporated tools.\nIn contrast to conventional paradigms for organizing and\nnavigating the many views used to visualize a system, OSM\nemploys the metaphor of a multi-dimensional cube. More\nspeci\ufb01cally, as illustrated in Figure 9, OSM regards dimen-\nsion of the underlying methodology as representing a di\ufb00er-\nent dimension of the cube, and each independently variable\naspect of that dimension is a selectable dimension element.\nSelecting a view thus simply corresponds to selecting a single\ncell within the cube. In general, three types of dimensions\nare supported: static dimensions in which the number of\nFigure 9: Dimension-based navigation.\nselectable elements (i.e. coordinates) is \ufb01xed, dynamic di-\nmensions in which the number of elements is dynamic (i.e.\nderived from the SUM), and mixed dimensions which have\nboth static and dynamic elements.\nTo support the OSM dimension based navigation metaphor\nfor KobrA, we de\ufb01ned the seven dimensions indicated on the\nleft hand side of Figure 10 which is a sceenshot of nAOMI.\nThe Abstraction dimension (not expanded here), which has\nthree static dimension elements, PIM (platform independent\nmodel), PSM (platform speci\ufb01c model) and Code, captures\nthe model-driven development concern of KobrA. The ver-\nsion dimension captures the state of the modeled system at\nspeci\ufb01c points in time. The Component dimension, which\nhas dynamic dimension elements de\ufb01ned by instances of the\nclass ComponentClass in the SUM, captures the component-\nbased development concern of KobrA.\nThe Encapsulation dimension, which has two \ufb01xed ele-\nments, supports the distinction between Speci\ufb01cation (black\nbox) and Realization (white box) views of components, while\nthe Projection dimension with the \ufb01xed elements Structural,\nOperational and Behavioral covers the di\ufb00erent information\ntypes. The Granularity dimension provides a \ufb01ner grained\ndistinction between views describing the types used by com-\nponents (Type granularity) and views describing the required\nand provided interfaces (Service granularity). The Opera-\ntion dimension allows a selection of individual operations.\nIn the ideal case, when all views are truly orthogonal, the\nchoices that can be made in each dimensions are completely\nindependent.\nHowever, this is very di\ufb03cult to achieve in\nsoftware engineering. The approach still works if the views\nare not completely orthogonal, but dependencies then occur\nbetween di\ufb00erent choices in di\ufb00erent dimensions, so that the\ndecisions made in one dimensions may a\ufb00ect choices possi-\nble in another dimension. This is best handled by giving\ndimensions a precedence ranking determined by the order\nin which they appear (the top being the highest). When an\nelement in a dimension is selected, the tool automatically\nmakes default selections for dimensions of lower precedence\n(i.e.\ndimensions lower down) and disables selections that\nwould navigate to cells (i.e. views) which are not (yet) de-\n\ufb01ned by the method at hand.\n6.\nSHOPPING CART EXAMPLE\nTo show how a software system can be speci\ufb01ed using\nnAOMi, this section presents a case study based on a shop-\nping cart system. A ShoppingCart component collects and\nFigure 10: Speci\ufb01cation Structural View.\nmanages the products selected by users and supports pay-\nment via a credit card.\nFigure 10 illustrates a structural\nview of the component.\nIn the dimension navigator on the left hand side, PIM\nwas chosen for the \u201cAbstraction Level\u201d (not expanded in the\nscreenshot). The second dimension is the state of the soft-\nware system at a certain point in time. The picture shows\nthat the latest available version was chosen. As with every\nchoice in a dimension, it may in\ufb02uence the options in lower\nranked dimensions. The component under consideration is\nthe ShoppingCart, for which a black box view is selected\nin the next dimension. After the user selects the structural\nprojection option and the service level granularity, the tool\nautomatically chooses the option for all operations in the\nlast dimension, as there is no editor registered for the other\noptions.\nThe component under development is presented with the\nstereotype subject and its relationship to other components\nand classes is shown in the view, which corresponds to a cell\nof the multi-dimensional navigation cube, and is generated\non-the-\ufb02y from the SUM when it is selected. The classes\nProduct and CreditCard can be used as data types in the\noperations of the component.\nFigure 11 illustrates the operational view in which an\noperation can be formalized using pre- and postconditions.\nThe precondition corresponds to the assumes clause in and\nthe postcondition corresponds to the result clause. As in the\nUML, the precondition of an operation must be true when\nthe operation is invoked and the postcondition must be true\nwhen the operation is \ufb01nished. The operation addProduct\nin Figure 11 must be in state CollectingProducts or Empty\nwhen invoked. This is also visible in the behavioral view,\nFigure 11: addProduct() Operation Speci\ufb01cation.\nsince there are only two transitions with the operation ad-\ndProduct. Both leads to the state CollectingProducts which\nis also a postcondition of the operation. The second post-\ncondition is that the cost attribute of the component must\nbe increased by the price of the added product. The pre- and\npostcondition can be expressed using the OCL. The proper-\nties of the component, states and operation parameters can\nbe used to formalise the constraints like as in this example.\nFigure 12 shows the publicly visible behaviour of the Shop-\npingCart component with states and transitions. The condi-\ntional transitions map to operations of the component. Like\nevery view, this view is also synchronized with the SUM so\nthat it is guaranteed that its operations, states and proper-\nties are consistent with those in the structural view.\nFigure 12: Speci\ufb01cation Behavioral Model.\nAlthough the operational view seems to be similar to the\nbehavioral view because of the overlapping information within\nthem, there are signi\ufb01cant di\ufb00erences. The focus of the op-\nerational view is on a precise formal de\ufb01nition of an opera-\ntion of a component. The operations can be enriched by pre-\nand postconditions which can be de\ufb01ned using complex OCL\nstatements, that formalize the complete behavior of an op-\neration. The additional information in the OCL statements\ncan be used for code generation and documentation.\n7.\nCONCLUSION\nAt the beginning of the paper we identi\ufb01ed three funda-\nmental hypothesis upon which the notion of OSM is based\n\u2014 (a) that it is feasible to integrate the many di\ufb00erent kinds\nof artifacts used in contemporary software engineering meth-\nods within a single coherent methodology in which they are\ntreated as views, (b) that it is feasible to create an e\ufb03-\ncient and scalable way of supporting these views by gener-\nating them dynamically, on-the-\ufb02y, from a Single Underly-\ning Model (SUM) using model-based transformations and\n(c) that it is feasible to provide an intuitive metaphor for\nnavigating around these many views by adapting the ortho-\ngraphic projection technique underpinning the CAD tools\nused in other engineering disciplines.\nThe prototype tool, nAOMi, described in this paper rep-\nresents the \ufb01rst step towards demonstrating the validity of\nthese hypotheses and showing that OSM is a viable approach\nto software engineering. Of the three hypotheses, (a) and (c)\nare most convincingly demonstrated by the prototype, since\nit shows that it is indeed possible to support all the views\nof the KobrA method within a single navigation metaphor.\nThe prototype tool does not demonstrate the validity of hy-\npothesis (b) to the same extent as the others due to its\nsmall size. Although it demonstrates the feasibility of gen-\nerating views from the SUM and vice-versa, the question of\nwhether such an approach scales up to large environments\nis still open.\nAlthough nOAMi is the only tool developed with the spe-\nci\ufb01c aim of supporting KobrA-based OSM, several other\ntools and methods have similar properties or aims.\nFor\nexample, Glinz et al.\n[10] describe a tool with a \ufb01sheye\nzooming algorithm which lets the user view a model with\nvarying amounts of detail depending on the context. It has\nto be investigated whether it is possible to combine the \ufb01sh-\neye zooming concept with the dimension-based navigation\nparadigm. While the KobrA 2.0 implementation of nAOMi\nheavily uses UML diagrams for developers, Glinz et al. use\ncustom diagram types, e.g.\nfor structural and behavioral\nviews.\nAn approach which also emphasizes the description of for-\nmal consistency rules (correspondences) between views is\nRM-ODP [5][6].\nHowever, this approach does not explic-\nitly mention the notion of a SUM and thus implies that\nconsistency rules should be de\ufb01ned in a pairwise fashion be-\ntween individual pairs of views. ArchiMate [7], which com-\nplements TOGAF [12], is an enterprise architecture mod-\neling language which o\ufb00ers two orthogonal \u201ddimensions\u201d for\nmodeling, (business, architecture, and technology) layers and\n(informational, behavioral and structural) aspects and also\nsuggests two more dimensions, purpose and abstraction level.\nHowever, as many of these views span multiple choices of a\nsingle\u201cdimension\u201d, the intuitive dimension-based navigation\nmetaphor of OSM can not be easily applied. There are also\nmore general approaches for view-based modeling but they\nare less speci\ufb01c in terms of consistency rules between views\nand provide little guidance on how to manage and navigate\nviews, for example the Zachman Framework [14].\nRegarding the practical use of OSM environments in the\nfuture, the biggest challenge is developing appropriate SUM\nmetamodels which can accommodate all the types of views\nand services that software engineers are accustomed to to-\nday. For this \ufb01rst prototypical SUM-based environment sup-\nporting the OSM approach we had a method at our disposal\n(KobrA) that already de\ufb01ned a full set of orthogonal UML-\nbased views. This allowed us to model the required SUM\nand view metamodels by simply adapting the UML meta-\nmodels, removing and adding model elements as needed.\nIn doing so we were able to manually ensure that the meta-\nmodels ful\ufb01lled the two core requirements of SUM-based en-\nvironments \u2014 (1) being minimalistic and (2) redundancy\nfree. If SUM-based software engineering environments are\nto take o\ufb00, and to be introduced into existing, heteroge-\nneous environments, more sophisticated ways of integrating\nexisting metamodels into a single uni\ufb01ed metamodel will be\nrequired.\n8.\nREFERENCES\n[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,\nO. Laitenberger, R. Laqua, D. Muthig, B. Paech,\nJ. W\u00a8ust, and J. Zettel. Component-Based Product Line\nEngineering with UML. Addison Wesley, Reading,\nMassachusetts, USA, 1st edition, November 2001.\n[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic\nSoftware Modeling: A Practical Approach to\nView-Based Development. In Evaluation of Novel\nApproaches to Software Engineering, volume 69 of\nCommunications in Computer and Information\nScience, pages 206\u2013219. Springer Berlin Heidelberg,\n2010.\n[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic\nService Modeling. In Proceedings of 15th IEEE EDOC\nConference Workshops (EDOCW), Helsinki, Finland,\n2011.\n[4] Eclipse Foundation. UML2Tools.\nhttp://wiki.eclipse.org/MDT-UML2Tools, 2013.\n[5] ISO/IEC and ITU-T. The Reference Model of Open\nDistributed Processing. RM-ODP, ITU-T Rec.\nX.901-X.904 / ISO/IEC 10746.\nhttp://standards.iso.org/\nittf/PubliclyAvailableStandards/index.html,\n1998.\n[6] J. I. J. Jose Raul Romero and A. Vallecillo. Realizing\nCorrespondences in MultiViewpoint Speci\ufb01cations. In\nProceedings of the Thirteenth IEEE International\nEDOC Conference, 1 - 4 September 2009, Auckland,\nNew Zealand, September 2009.\n[7] M. Lankhorst. Enterprise Architecture at Work.\nSpringer Berlin Heidelberg, 2009.\n[8] Object Management Group (OMG). OMG Uni\ufb01ed\nModeling Language (OMG UML), Superstructure,\nV2.1.2.\nhttp://www.omg.org/cgi-bin/doc?formal/07-11-02,\nNovember 2007.\n[9] Object Management Group (OMG). Meta Object\nFacility (MOF) 2.0 Query/View/Transformation, v1.0.\nhttp://www.omg.org/spec/QVT/1.0/PDF/, April 2008.\n[10] C. Seybold, M. Glinz, S. Meier, and N. Merlo-Schett.\nAn e\ufb00ective layout adaptation technique for a\ngraphical modeling tool. In Proceedings of the 2003\nInternational Conference on Software Engineering,\nPortland, 2003.\n[11] The Atlas Transformation Language (ATL). O\ufb03cial\nWebsite. http://www.eclipse.org/atl/, 2013.\n[12] The Open Group. TOGAF Version 9 - The Open\nGroup Architecture Framework.\nhttp://www.opengroup.org/architecture/\ntogaf9-doc/arch/index.html, Feb 2009.\n[13] University of Mannheim - Software Engineering\nGroup. nAOMi - opeN, Adaptable, Orthographic\nModeling EnvIronment.\nhttp://eclipselabs.org/p/naomi.\n[14] J. A. Zachman. The Zachman Framework: A Primer\nfor Enterprise Engineering and Manufacturing.\nhttp://www.zachmaninternational.com, 2009.\n",
    "pdf_url": "",
    "references": [
      "[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,",
      "O. Laitenberger, R. Laqua, D. Muthig, B. Paech,",
      "J. W\u00a8ust, and J. Zettel. Component-Based Product Line",
      "Engineering with UML. Addison Wesley, Reading,",
      "Massachusetts, USA, 1st edition, November 2001.",
      "[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic",
      "Software Modeling: A Practical Approach to",
      "View-Based Development. In Evaluation of Novel",
      "Approaches to Software Engineering, volume 69 of",
      "Communications in Computer and Information",
      "Science, pages 206\u2013219. Springer Berlin Heidelberg,",
      "2010.",
      "[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "How to Teach Software Modeling",
    "resume": "To enhance motivation of students to study software engineering,some way of nding balance between the scientic aspect and thepractical aspect of software engineering is required. In this paper,we claim that teaching multiple software modeling techniques froma unied viewpoint is a good way of obtaining the balance andattracting the students interest as well.",
    "auteurs": [
      "Tetsuo Tamai",
      "Meguro-ku"
    ],
    "institutions": [
      "Tetsuo Tamai Graduate School of Arts and SciencesThe University of Tokyo3-8-1 Komaba, Meguro-kuTokyo 153-8902, "
    ],
    "mots_cles": [
      " software modeling",
      " software engineering education",
      " UML "
    ],
    "texte_integral": "How to Teach Software Modeling\nTetsuo Tamai\nGraduate School of Arts and Sciences\nThe University of Tokyo\n3-8-1 Komaba, Meguro-ku\nTokyo 153-8902, Japan\ntamai@acm.org\nABSTRACT\nTo enhance motivation of students to study software engineering,\nsome way of \ufb01nding balance between the scienti\ufb01c aspect and the\npractical aspect of software engineering is required. In this paper,\nwe claim that teaching multiple software modeling techniques from\na uni\ufb01ed viewpoint is a good way of obtaining the balance and\nattracting the students\u2019 interest as well.\nCategories and Subject Descriptors\nK.3.2 [Computers and Education]: Computer and Information\nScience Education\u2014computer science education; D.2.1 [Software\nEngineering]: Requirements/Speci\ufb01cation\u2014modeling\nGeneral Terms\nDesign\nKeywords\nsoftware modeling, software engineering education, UML\n1.\nINTRODUCTION\nSoftware engineering education at universities faces a common\nproblem; that is regular students do not usually have experience of\ndeveloping software for practical use and thus are not motivated for\nsoftware engineering aiming at high quality software production\nby a project team or a persistent organization. Software projects\nconducted by students simulating real scale software development\nmay help enhance students\u2019 motivation, although it requires a lot of\nefforts to prepare such projects and manage them.\nAnother way of solving this problem is to teach those who al-\nready have real experience in industry. In our case, there are cur-\nrently \ufb01ve Ph. D. students under the author\u2019s supervision who are\nworking at companies as well as doing research in our lab. As\na by-product, interactions between the part-time students and the\nother regular students stimulate each other, particularly enlighten-\ning the regular students to practical software issues. However, too\nmuch emphasis on practicality may bring negligence to scienceand\nCopyright is held by the author/owner.\nICSE\u201905, May 15\u201321, 2005, St. Louis, Missouri, USA.\nACM 1-58113-963-2/05/0005.\ntechnology and may generate anti-intellectualism. A good balance\nbetween the scienti\ufb01c aspect and the practical aspect of software\nengineering should always be pursued.\nIn our view, teaching various software modeling techniques is a\ngood way to achieve balanced software engineering education. It\nis needless to say that model is a key concept and modeling is an\nessential skill in software engineering. There are a variety of mod-\neling techniques; some are intuitive and quite accessibleto novices,\nwhile some are highly sophisticated and attract theory oriented stu-\ndents and researchers.\nIn this paper, we would like to show that it is effective to teach\nmultiple modeling techniques from a uni\ufb01ed viewpoint. It is based\non our experience of teaching software engineering courses at sev-\neral universities in Japan. Recently, the author published a textbook\non software engineering, speci\ufb01cally focused on software model-\ning (unfortunately, it is written in Japanese)[1]. The book covers\nthe whole area of software engineering, including design, testing\nand evolution but the modeling part has a role of attracting inter-\nests of intelligent students, who may not have much experience in\ndeveloping real scale software systems. It also gives a consistent\nviewpoint penetrating through various techniques employed in dif-\nferent stages of software engineering.\n2.\nMODELING TECHNIQUES\nIn software engineering, models are used for various purposes,\ne.g. life cycle model, process model, project model, product model,\nquality model, domain model, requirements model, design model,\nobject model, data model, etc. In the following, we basically focus\non requirements and design models but most of the discussionswill\nhold for other kinds of models.\nTeaching modeling is almost equal to teaching abstraction. Mod-\nels are constructed through capturing the crucial properties and\nstructure of the target, abstracting away irrelevant details. Thus,\nlearning how to model is a good training for mastering abstraction.\n2.1\nGraph Representation of Models\nMany software models are represented with diagrams. Wide ac-\nceptance of UML symbolizes the trend that diagrams are often pre-\nferred to textual languages. Among many types of diagrams, graph\nstructured diagrams are by far the most widely used. The reasons\nmay be as follows.\n1. A most fundamental way for human mind to understand the\nworld is by regarding it as consisting of a set of conceptual\nunits and a set of relations between them. Conceptual units\ncan be naturally illustrated with boxes or circles or whatever\nclosed \ufb01gures and relations can be illustrated with lines or ar-\nrows connecting such \ufb01gures, corresponding to vertices and\nedges of graphs, respectively.\n609\n2. It is easy to draw graph structured diagrams by hand or with\ndrawing tools.\n3. Concepts and algorithms of the graph theory are available\nand often useful in analyzing models represented by graphs.\nA typical example is reasoning on transitive relations by trac-\ning along paths of graphs. Also, the concept of subgraph is\nhighly useful in decomposinghigher-level models or cluster-\ning lower-level models.\nAccordingly, a number of models share the same structure of\ngraphs. Table 1 shows graph structures of some typical models.\nTable 1: Graph structures of typical models\nmodel\nvertex\nedge\nData \ufb02ow\nprocess\ndata \ufb02ow\nER\nentity\nrelationship\nState transition\nstate\ntransition\nJSD\nprocess\ndata stream connection\nstate vector connection\nActivity\nactivity\ncontrol \ufb02ow\nPetri net\nplace, transition\n\ufb01re and token \ufb02ow\n2.2\nCommonality and Difference between\nModels\nIt is pedagogical to let students notice the common structure\nshared by a number of models. However, the apparent resemblance\noften causes confusion. Such confusion can be observed not only\nin software modeling graphs but in many diagrams found in daily\nnewspapers, magazines, reports, proposals and other documents. It\nis often the case that one vertex denotes a type of things and an-\nother denotes quite a different type on the same diagram or one\ntype of edges co-exist with edges with different meaning. Thus,\nit is important to make students consciously aware the differences\nbetween different models. We often experience that when we let\nstudents draw data \ufb02ow diagrams who appear to have understood\nthe data \ufb02ow model perfectly, the diagrams turn out to be some-\nthing like control \ufb02ow graphs.\nTo show the difference, it is instructive to categorize models rep-\nresented by graphs. Basically, there are two categories.\n1. Static models:\nAn edge connecting vertex A and vertex B represents a rela-\ntion between A and B. When the edge is undirected, it means\n\u201cA and B are in some relation\u201d and when directed, it means\n\u201cA has a relation with B\u201d. Typical examples include entity\nrelationship model, class diagram and semantic network.\n2. Dynamic models:\nAn edge from vertex A to B denotes a move from A to B.\nThe edge in this case is always directed. There are two sub-\ncategories:\n(a) The case where a view of control moves from A to B.\nExamples are control \ufb02ow model and state transition\nmodel.\n(b) The case where data or objects \ufb02ow from A to B. Exam-\nples are data \ufb02ow model, work \ufb02ow model, and trans-\nportation \ufb02ow model.\nStatic models and dynamic models may not be easily confused\nbut confusion betweendifferent dynamic models are often observed,\ne.g. data \ufb02ow and control \ufb02ow or state transition and activity tran-\nsition. Since graphs are intuitively understandable, their semantics\nare apt to be understood ambiguously or misunderstood.\n3.\nUML\nUML diagrams can also be viewed in terms of graph structures.\nTable 2 shows graph structures of \ufb01ve UML diagrams.\nTable 2: Graph structures of UML diagrams\ndiagram\nvertex\nedge\nclass diagram\nclass\ngeneralization,\ncomposition,\nassociation\nstate machine\nstate\ntransition\nactivity diagram\nactivity\ncontrol \ufb02ow\ncollaboration diagram\nobject\nmessage \ufb02ow\nsequence diagram\nmessage\nmessage \ufb02ow\nanchor point\nIt is usually not desirable to teach UML per se. UML is a col-\nlection of miscellaneous diagrams and its speci\ufb01cation is continu-\nously changing. For the pedagogical purpose, UML had better be\nregarded as a catalogue of analysis and design know-how collected\naround diagrammatic representations. Diagrams should be selected\naccording to the policy of how to teach modeling methods.\nEach UML diagram contains overly rich constructs, which some-\ntimes blur the essential property of the model. For example, the\nactivity diagram is essentially a control \ufb02ow diagram but it also in-\ncludes a notation for data \ufb02ow description. From the stance of em-\nphasizing differences between various models, it is not appropriate\nto include such ad hoc constructs. By the same token, the collab-\noration diagram (, renamed to \u201ccommunication diagram\u201d in UML\n2) is explained to have the equivalent semantics as the sequence\ndiagram. But if that is the case, signi\ufb01cance of the collaboration\ndiagram is considerably limited. The author prefers to regard it as\nshowing collaboration relations between objects, integrating a set\nof different sequence diagrams.\n4.\nCONCLUSION\nSoftware modeling is important by itself but teaching modeling\nin the software engineering course has at least two additional mean-\nings. One is to give a bird\u2019s-eye view to the whole software engi-\nneering through the standpoint of modeling technology. The other\nis to attract interest of good students who may not have much expe-\nrience in developing a real-scale software but possess intelligence\nand will to attack complexity of modern software construction.\n5.\nREFERENCES\n[1] T. Tamai. Foundations of Software Engineering. Iwanami\nShoten, Tokyo, Japan, 2004. in Japanese.\n610\n",
    "pdf_url": "",
    "references": [
      "[1] T. Tamai. Foundations of Software Engineering. Iwanami"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "How to Teach Software Modeling",
    "resume": "To enhance motivation of students to study software engineering,some way of nding balance between the scientic aspect and thepractical aspect of software engineering is required. In this paper,we claim that teaching multiple software modeling techniques froma unied viewpoint is a good way of obtaining the balance andattracting the students interest as well.",
    "auteurs": [
      "Tetsuo Tamai",
      "Meguro-ku"
    ],
    "institutions": [
      "Tetsuo Tamai Graduate School of Arts and SciencesThe University of Tokyo3-8-1 Komaba, Meguro-kuTokyo 153-8902, "
    ],
    "mots_cles": [
      " software modeling",
      " software engineering education",
      " UML "
    ],
    "texte_integral": "How to Teach Software Modeling\nTetsuo Tamai\nGraduate School of Arts and Sciences\nThe University of Tokyo\n3-8-1 Komaba, Meguro-ku\nTokyo 153-8902, Japan\ntamai@acm.org\nABSTRACT\nTo enhance motivation of students to study software engineering,\nsome way of \ufb01nding balance between the scienti\ufb01c aspect and the\npractical aspect of software engineering is required. In this paper,\nwe claim that teaching multiple software modeling techniques from\na uni\ufb01ed viewpoint is a good way of obtaining the balance and\nattracting the students\u2019 interest as well.\nCategories and Subject Descriptors\nK.3.2 [Computers and Education]: Computer and Information\nScience Education\u2014computer science education; D.2.1 [Software\nEngineering]: Requirements/Speci\ufb01cation\u2014modeling\nGeneral Terms\nDesign\nKeywords\nsoftware modeling, software engineering education, UML\n1.\nINTRODUCTION\nSoftware engineering education at universities faces a common\nproblem; that is regular students do not usually have experience of\ndeveloping software for practical use and thus are not motivated for\nsoftware engineering aiming at high quality software production\nby a project team or a persistent organization. Software projects\nconducted by students simulating real scale software development\nmay help enhance students\u2019 motivation, although it requires a lot of\nefforts to prepare such projects and manage them.\nAnother way of solving this problem is to teach those who al-\nready have real experience in industry. In our case, there are cur-\nrently \ufb01ve Ph. D. students under the author\u2019s supervision who are\nworking at companies as well as doing research in our lab. As\na by-product, interactions between the part-time students and the\nother regular students stimulate each other, particularly enlighten-\ning the regular students to practical software issues. However, too\nmuch emphasis on practicality may bring negligence to scienceand\nCopyright is held by the author/owner.\nICSE\u201905, May 15\u201321, 2005, St. Louis, Missouri, USA.\nACM 1-58113-963-2/05/0005.\ntechnology and may generate anti-intellectualism. A good balance\nbetween the scienti\ufb01c aspect and the practical aspect of software\nengineering should always be pursued.\nIn our view, teaching various software modeling techniques is a\ngood way to achieve balanced software engineering education. It\nis needless to say that model is a key concept and modeling is an\nessential skill in software engineering. There are a variety of mod-\neling techniques; some are intuitive and quite accessibleto novices,\nwhile some are highly sophisticated and attract theory oriented stu-\ndents and researchers.\nIn this paper, we would like to show that it is effective to teach\nmultiple modeling techniques from a uni\ufb01ed viewpoint. It is based\non our experience of teaching software engineering courses at sev-\neral universities in Japan. Recently, the author published a textbook\non software engineering, speci\ufb01cally focused on software model-\ning (unfortunately, it is written in Japanese)[1]. The book covers\nthe whole area of software engineering, including design, testing\nand evolution but the modeling part has a role of attracting inter-\nests of intelligent students, who may not have much experience in\ndeveloping real scale software systems. It also gives a consistent\nviewpoint penetrating through various techniques employed in dif-\nferent stages of software engineering.\n2.\nMODELING TECHNIQUES\nIn software engineering, models are used for various purposes,\ne.g. life cycle model, process model, project model, product model,\nquality model, domain model, requirements model, design model,\nobject model, data model, etc. In the following, we basically focus\non requirements and design models but most of the discussionswill\nhold for other kinds of models.\nTeaching modeling is almost equal to teaching abstraction. Mod-\nels are constructed through capturing the crucial properties and\nstructure of the target, abstracting away irrelevant details. Thus,\nlearning how to model is a good training for mastering abstraction.\n2.1\nGraph Representation of Models\nMany software models are represented with diagrams. Wide ac-\nceptance of UML symbolizes the trend that diagrams are often pre-\nferred to textual languages. Among many types of diagrams, graph\nstructured diagrams are by far the most widely used. The reasons\nmay be as follows.\n1. A most fundamental way for human mind to understand the\nworld is by regarding it as consisting of a set of conceptual\nunits and a set of relations between them. Conceptual units\ncan be naturally illustrated with boxes or circles or whatever\nclosed \ufb01gures and relations can be illustrated with lines or ar-\nrows connecting such \ufb01gures, corresponding to vertices and\nedges of graphs, respectively.\n609\n2. It is easy to draw graph structured diagrams by hand or with\ndrawing tools.\n3. Concepts and algorithms of the graph theory are available\nand often useful in analyzing models represented by graphs.\nA typical example is reasoning on transitive relations by trac-\ning along paths of graphs. Also, the concept of subgraph is\nhighly useful in decomposinghigher-level models or cluster-\ning lower-level models.\nAccordingly, a number of models share the same structure of\ngraphs. Table 1 shows graph structures of some typical models.\nTable 1: Graph structures of typical models\nmodel\nvertex\nedge\nData \ufb02ow\nprocess\ndata \ufb02ow\nER\nentity\nrelationship\nState transition\nstate\ntransition\nJSD\nprocess\ndata stream connection\nstate vector connection\nActivity\nactivity\ncontrol \ufb02ow\nPetri net\nplace, transition\n\ufb01re and token \ufb02ow\n2.2\nCommonality and Difference between\nModels\nIt is pedagogical to let students notice the common structure\nshared by a number of models. However, the apparent resemblance\noften causes confusion. Such confusion can be observed not only\nin software modeling graphs but in many diagrams found in daily\nnewspapers, magazines, reports, proposals and other documents. It\nis often the case that one vertex denotes a type of things and an-\nother denotes quite a different type on the same diagram or one\ntype of edges co-exist with edges with different meaning. Thus,\nit is important to make students consciously aware the differences\nbetween different models. We often experience that when we let\nstudents draw data \ufb02ow diagrams who appear to have understood\nthe data \ufb02ow model perfectly, the diagrams turn out to be some-\nthing like control \ufb02ow graphs.\nTo show the difference, it is instructive to categorize models rep-\nresented by graphs. Basically, there are two categories.\n1. Static models:\nAn edge connecting vertex A and vertex B represents a rela-\ntion between A and B. When the edge is undirected, it means\n\u201cA and B are in some relation\u201d and when directed, it means\n\u201cA has a relation with B\u201d. Typical examples include entity\nrelationship model, class diagram and semantic network.\n2. Dynamic models:\nAn edge from vertex A to B denotes a move from A to B.\nThe edge in this case is always directed. There are two sub-\ncategories:\n(a) The case where a view of control moves from A to B.\nExamples are control \ufb02ow model and state transition\nmodel.\n(b) The case where data or objects \ufb02ow from A to B. Exam-\nples are data \ufb02ow model, work \ufb02ow model, and trans-\nportation \ufb02ow model.\nStatic models and dynamic models may not be easily confused\nbut confusion betweendifferent dynamic models are often observed,\ne.g. data \ufb02ow and control \ufb02ow or state transition and activity tran-\nsition. Since graphs are intuitively understandable, their semantics\nare apt to be understood ambiguously or misunderstood.\n3.\nUML\nUML diagrams can also be viewed in terms of graph structures.\nTable 2 shows graph structures of \ufb01ve UML diagrams.\nTable 2: Graph structures of UML diagrams\ndiagram\nvertex\nedge\nclass diagram\nclass\ngeneralization,\ncomposition,\nassociation\nstate machine\nstate\ntransition\nactivity diagram\nactivity\ncontrol \ufb02ow\ncollaboration diagram\nobject\nmessage \ufb02ow\nsequence diagram\nmessage\nmessage \ufb02ow\nanchor point\nIt is usually not desirable to teach UML per se. UML is a col-\nlection of miscellaneous diagrams and its speci\ufb01cation is continu-\nously changing. For the pedagogical purpose, UML had better be\nregarded as a catalogue of analysis and design know-how collected\naround diagrammatic representations. Diagrams should be selected\naccording to the policy of how to teach modeling methods.\nEach UML diagram contains overly rich constructs, which some-\ntimes blur the essential property of the model. For example, the\nactivity diagram is essentially a control \ufb02ow diagram but it also in-\ncludes a notation for data \ufb02ow description. From the stance of em-\nphasizing differences between various models, it is not appropriate\nto include such ad hoc constructs. By the same token, the collab-\noration diagram (, renamed to \u201ccommunication diagram\u201d in UML\n2) is explained to have the equivalent semantics as the sequence\ndiagram. But if that is the case, signi\ufb01cance of the collaboration\ndiagram is considerably limited. The author prefers to regard it as\nshowing collaboration relations between objects, integrating a set\nof different sequence diagrams.\n4.\nCONCLUSION\nSoftware modeling is important by itself but teaching modeling\nin the software engineering course has at least two additional mean-\nings. One is to give a bird\u2019s-eye view to the whole software engi-\nneering through the standpoint of modeling technology. The other\nis to attract interest of good students who may not have much expe-\nrience in developing a real-scale software but possess intelligence\nand will to attack complexity of modern software construction.\n5.\nREFERENCES\n[1] T. Tamai. Foundations of Software Engineering. Iwanami\nShoten, Tokyo, Japan, 2004. in Japanese.\n610\n",
    "pdf_url": "",
    "references": [
      "[1] T. Tamai. Foundations of Software Engineering. Iwanami"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "How to Teach Software Modeling",
    "resume": "To enhance motivation of students to study software engineering,some way of nding balance between the scientic aspect and thepractical aspect of software engineering is required. In this paper,we claim that teaching multiple software modeling techniques froma unied viewpoint is a good way of obtaining the balance andattracting the students interest as well.",
    "auteurs": [
      "Tetsuo Tamai",
      "Meguro-ku"
    ],
    "institutions": [
      "Tetsuo Tamai Graduate School of Arts and SciencesThe University of Tokyo3-8-1 Komaba, Meguro-kuTokyo 153-8902, "
    ],
    "mots_cles": [
      " software modeling",
      " software engineering education",
      " UML "
    ],
    "texte_integral": "How to Teach Software Modeling\nTetsuo Tamai\nGraduate School of Arts and Sciences\nThe University of Tokyo\n3-8-1 Komaba, Meguro-ku\nTokyo 153-8902, Japan\ntamai@acm.org\nABSTRACT\nTo enhance motivation of students to study software engineering,\nsome way of \ufb01nding balance between the scienti\ufb01c aspect and the\npractical aspect of software engineering is required. In this paper,\nwe claim that teaching multiple software modeling techniques from\na uni\ufb01ed viewpoint is a good way of obtaining the balance and\nattracting the students\u2019 interest as well.\nCategories and Subject Descriptors\nK.3.2 [Computers and Education]: Computer and Information\nScience Education\u2014computer science education; D.2.1 [Software\nEngineering]: Requirements/Speci\ufb01cation\u2014modeling\nGeneral Terms\nDesign\nKeywords\nsoftware modeling, software engineering education, UML\n1.\nINTRODUCTION\nSoftware engineering education at universities faces a common\nproblem; that is regular students do not usually have experience of\ndeveloping software for practical use and thus are not motivated for\nsoftware engineering aiming at high quality software production\nby a project team or a persistent organization. Software projects\nconducted by students simulating real scale software development\nmay help enhance students\u2019 motivation, although it requires a lot of\nefforts to prepare such projects and manage them.\nAnother way of solving this problem is to teach those who al-\nready have real experience in industry. In our case, there are cur-\nrently \ufb01ve Ph. D. students under the author\u2019s supervision who are\nworking at companies as well as doing research in our lab. As\na by-product, interactions between the part-time students and the\nother regular students stimulate each other, particularly enlighten-\ning the regular students to practical software issues. However, too\nmuch emphasis on practicality may bring negligence to scienceand\nCopyright is held by the author/owner.\nICSE\u201905, May 15\u201321, 2005, St. Louis, Missouri, USA.\nACM 1-58113-963-2/05/0005.\ntechnology and may generate anti-intellectualism. A good balance\nbetween the scienti\ufb01c aspect and the practical aspect of software\nengineering should always be pursued.\nIn our view, teaching various software modeling techniques is a\ngood way to achieve balanced software engineering education. It\nis needless to say that model is a key concept and modeling is an\nessential skill in software engineering. There are a variety of mod-\neling techniques; some are intuitive and quite accessibleto novices,\nwhile some are highly sophisticated and attract theory oriented stu-\ndents and researchers.\nIn this paper, we would like to show that it is effective to teach\nmultiple modeling techniques from a uni\ufb01ed viewpoint. It is based\non our experience of teaching software engineering courses at sev-\neral universities in Japan. Recently, the author published a textbook\non software engineering, speci\ufb01cally focused on software model-\ning (unfortunately, it is written in Japanese)[1]. The book covers\nthe whole area of software engineering, including design, testing\nand evolution but the modeling part has a role of attracting inter-\nests of intelligent students, who may not have much experience in\ndeveloping real scale software systems. It also gives a consistent\nviewpoint penetrating through various techniques employed in dif-\nferent stages of software engineering.\n2.\nMODELING TECHNIQUES\nIn software engineering, models are used for various purposes,\ne.g. life cycle model, process model, project model, product model,\nquality model, domain model, requirements model, design model,\nobject model, data model, etc. In the following, we basically focus\non requirements and design models but most of the discussionswill\nhold for other kinds of models.\nTeaching modeling is almost equal to teaching abstraction. Mod-\nels are constructed through capturing the crucial properties and\nstructure of the target, abstracting away irrelevant details. Thus,\nlearning how to model is a good training for mastering abstraction.\n2.1\nGraph Representation of Models\nMany software models are represented with diagrams. Wide ac-\nceptance of UML symbolizes the trend that diagrams are often pre-\nferred to textual languages. Among many types of diagrams, graph\nstructured diagrams are by far the most widely used. The reasons\nmay be as follows.\n1. A most fundamental way for human mind to understand the\nworld is by regarding it as consisting of a set of conceptual\nunits and a set of relations between them. Conceptual units\ncan be naturally illustrated with boxes or circles or whatever\nclosed \ufb01gures and relations can be illustrated with lines or ar-\nrows connecting such \ufb01gures, corresponding to vertices and\nedges of graphs, respectively.\n609\n2. It is easy to draw graph structured diagrams by hand or with\ndrawing tools.\n3. Concepts and algorithms of the graph theory are available\nand often useful in analyzing models represented by graphs.\nA typical example is reasoning on transitive relations by trac-\ning along paths of graphs. Also, the concept of subgraph is\nhighly useful in decomposinghigher-level models or cluster-\ning lower-level models.\nAccordingly, a number of models share the same structure of\ngraphs. Table 1 shows graph structures of some typical models.\nTable 1: Graph structures of typical models\nmodel\nvertex\nedge\nData \ufb02ow\nprocess\ndata \ufb02ow\nER\nentity\nrelationship\nState transition\nstate\ntransition\nJSD\nprocess\ndata stream connection\nstate vector connection\nActivity\nactivity\ncontrol \ufb02ow\nPetri net\nplace, transition\n\ufb01re and token \ufb02ow\n2.2\nCommonality and Difference between\nModels\nIt is pedagogical to let students notice the common structure\nshared by a number of models. However, the apparent resemblance\noften causes confusion. Such confusion can be observed not only\nin software modeling graphs but in many diagrams found in daily\nnewspapers, magazines, reports, proposals and other documents. It\nis often the case that one vertex denotes a type of things and an-\nother denotes quite a different type on the same diagram or one\ntype of edges co-exist with edges with different meaning. Thus,\nit is important to make students consciously aware the differences\nbetween different models. We often experience that when we let\nstudents draw data \ufb02ow diagrams who appear to have understood\nthe data \ufb02ow model perfectly, the diagrams turn out to be some-\nthing like control \ufb02ow graphs.\nTo show the difference, it is instructive to categorize models rep-\nresented by graphs. Basically, there are two categories.\n1. Static models:\nAn edge connecting vertex A and vertex B represents a rela-\ntion between A and B. When the edge is undirected, it means\n\u201cA and B are in some relation\u201d and when directed, it means\n\u201cA has a relation with B\u201d. Typical examples include entity\nrelationship model, class diagram and semantic network.\n2. Dynamic models:\nAn edge from vertex A to B denotes a move from A to B.\nThe edge in this case is always directed. There are two sub-\ncategories:\n(a) The case where a view of control moves from A to B.\nExamples are control \ufb02ow model and state transition\nmodel.\n(b) The case where data or objects \ufb02ow from A to B. Exam-\nples are data \ufb02ow model, work \ufb02ow model, and trans-\nportation \ufb02ow model.\nStatic models and dynamic models may not be easily confused\nbut confusion betweendifferent dynamic models are often observed,\ne.g. data \ufb02ow and control \ufb02ow or state transition and activity tran-\nsition. Since graphs are intuitively understandable, their semantics\nare apt to be understood ambiguously or misunderstood.\n3.\nUML\nUML diagrams can also be viewed in terms of graph structures.\nTable 2 shows graph structures of \ufb01ve UML diagrams.\nTable 2: Graph structures of UML diagrams\ndiagram\nvertex\nedge\nclass diagram\nclass\ngeneralization,\ncomposition,\nassociation\nstate machine\nstate\ntransition\nactivity diagram\nactivity\ncontrol \ufb02ow\ncollaboration diagram\nobject\nmessage \ufb02ow\nsequence diagram\nmessage\nmessage \ufb02ow\nanchor point\nIt is usually not desirable to teach UML per se. UML is a col-\nlection of miscellaneous diagrams and its speci\ufb01cation is continu-\nously changing. For the pedagogical purpose, UML had better be\nregarded as a catalogue of analysis and design know-how collected\naround diagrammatic representations. Diagrams should be selected\naccording to the policy of how to teach modeling methods.\nEach UML diagram contains overly rich constructs, which some-\ntimes blur the essential property of the model. For example, the\nactivity diagram is essentially a control \ufb02ow diagram but it also in-\ncludes a notation for data \ufb02ow description. From the stance of em-\nphasizing differences between various models, it is not appropriate\nto include such ad hoc constructs. By the same token, the collab-\noration diagram (, renamed to \u201ccommunication diagram\u201d in UML\n2) is explained to have the equivalent semantics as the sequence\ndiagram. But if that is the case, signi\ufb01cance of the collaboration\ndiagram is considerably limited. The author prefers to regard it as\nshowing collaboration relations between objects, integrating a set\nof different sequence diagrams.\n4.\nCONCLUSION\nSoftware modeling is important by itself but teaching modeling\nin the software engineering course has at least two additional mean-\nings. One is to give a bird\u2019s-eye view to the whole software engi-\nneering through the standpoint of modeling technology. The other\nis to attract interest of good students who may not have much expe-\nrience in developing a real-scale software but possess intelligence\nand will to attack complexity of modern software construction.\n5.\nREFERENCES\n[1] T. Tamai. Foundations of Software Engineering. Iwanami\nShoten, Tokyo, Japan, 2004. in Japanese.\n610\n",
    "pdf_url": "",
    "references": [
      "[1] T. Tamai. Foundations of Software Engineering. Iwanami"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "How to Teach Software Modeling",
    "resume": "To enhance motivation of students to study software engineering,some way of nding balance between the scientic aspect and thepractical aspect of software engineering is required. In this paper,we claim that teaching multiple software modeling techniques froma unied viewpoint is a good way of obtaining the balance andattracting the students interest as well.",
    "auteurs": [
      "Tetsuo Tamai",
      "Meguro-ku"
    ],
    "institutions": [
      "Tetsuo Tamai Graduate School of Arts and SciencesThe University of Tokyo3-8-1 Komaba, Meguro-kuTokyo 153-8902, "
    ],
    "mots_cles": [
      " software modeling",
      " software engineering education",
      " UML "
    ],
    "texte_integral": "How to Teach Software Modeling\nTetsuo Tamai\nGraduate School of Arts and Sciences\nThe University of Tokyo\n3-8-1 Komaba, Meguro-ku\nTokyo 153-8902, Japan\ntamai@acm.org\nABSTRACT\nTo enhance motivation of students to study software engineering,\nsome way of \ufb01nding balance between the scienti\ufb01c aspect and the\npractical aspect of software engineering is required. In this paper,\nwe claim that teaching multiple software modeling techniques from\na uni\ufb01ed viewpoint is a good way of obtaining the balance and\nattracting the students\u2019 interest as well.\nCategories and Subject Descriptors\nK.3.2 [Computers and Education]: Computer and Information\nScience Education\u2014computer science education; D.2.1 [Software\nEngineering]: Requirements/Speci\ufb01cation\u2014modeling\nGeneral Terms\nDesign\nKeywords\nsoftware modeling, software engineering education, UML\n1.\nINTRODUCTION\nSoftware engineering education at universities faces a common\nproblem; that is regular students do not usually have experience of\ndeveloping software for practical use and thus are not motivated for\nsoftware engineering aiming at high quality software production\nby a project team or a persistent organization. Software projects\nconducted by students simulating real scale software development\nmay help enhance students\u2019 motivation, although it requires a lot of\nefforts to prepare such projects and manage them.\nAnother way of solving this problem is to teach those who al-\nready have real experience in industry. In our case, there are cur-\nrently \ufb01ve Ph. D. students under the author\u2019s supervision who are\nworking at companies as well as doing research in our lab. As\na by-product, interactions between the part-time students and the\nother regular students stimulate each other, particularly enlighten-\ning the regular students to practical software issues. However, too\nmuch emphasis on practicality may bring negligence to scienceand\nCopyright is held by the author/owner.\nICSE\u201905, May 15\u201321, 2005, St. Louis, Missouri, USA.\nACM 1-58113-963-2/05/0005.\ntechnology and may generate anti-intellectualism. A good balance\nbetween the scienti\ufb01c aspect and the practical aspect of software\nengineering should always be pursued.\nIn our view, teaching various software modeling techniques is a\ngood way to achieve balanced software engineering education. It\nis needless to say that model is a key concept and modeling is an\nessential skill in software engineering. There are a variety of mod-\neling techniques; some are intuitive and quite accessibleto novices,\nwhile some are highly sophisticated and attract theory oriented stu-\ndents and researchers.\nIn this paper, we would like to show that it is effective to teach\nmultiple modeling techniques from a uni\ufb01ed viewpoint. It is based\non our experience of teaching software engineering courses at sev-\neral universities in Japan. Recently, the author published a textbook\non software engineering, speci\ufb01cally focused on software model-\ning (unfortunately, it is written in Japanese)[1]. The book covers\nthe whole area of software engineering, including design, testing\nand evolution but the modeling part has a role of attracting inter-\nests of intelligent students, who may not have much experience in\ndeveloping real scale software systems. It also gives a consistent\nviewpoint penetrating through various techniques employed in dif-\nferent stages of software engineering.\n2.\nMODELING TECHNIQUES\nIn software engineering, models are used for various purposes,\ne.g. life cycle model, process model, project model, product model,\nquality model, domain model, requirements model, design model,\nobject model, data model, etc. In the following, we basically focus\non requirements and design models but most of the discussionswill\nhold for other kinds of models.\nTeaching modeling is almost equal to teaching abstraction. Mod-\nels are constructed through capturing the crucial properties and\nstructure of the target, abstracting away irrelevant details. Thus,\nlearning how to model is a good training for mastering abstraction.\n2.1\nGraph Representation of Models\nMany software models are represented with diagrams. Wide ac-\nceptance of UML symbolizes the trend that diagrams are often pre-\nferred to textual languages. Among many types of diagrams, graph\nstructured diagrams are by far the most widely used. The reasons\nmay be as follows.\n1. A most fundamental way for human mind to understand the\nworld is by regarding it as consisting of a set of conceptual\nunits and a set of relations between them. Conceptual units\ncan be naturally illustrated with boxes or circles or whatever\nclosed \ufb01gures and relations can be illustrated with lines or ar-\nrows connecting such \ufb01gures, corresponding to vertices and\nedges of graphs, respectively.\n609\n2. It is easy to draw graph structured diagrams by hand or with\ndrawing tools.\n3. Concepts and algorithms of the graph theory are available\nand often useful in analyzing models represented by graphs.\nA typical example is reasoning on transitive relations by trac-\ning along paths of graphs. Also, the concept of subgraph is\nhighly useful in decomposinghigher-level models or cluster-\ning lower-level models.\nAccordingly, a number of models share the same structure of\ngraphs. Table 1 shows graph structures of some typical models.\nTable 1: Graph structures of typical models\nmodel\nvertex\nedge\nData \ufb02ow\nprocess\ndata \ufb02ow\nER\nentity\nrelationship\nState transition\nstate\ntransition\nJSD\nprocess\ndata stream connection\nstate vector connection\nActivity\nactivity\ncontrol \ufb02ow\nPetri net\nplace, transition\n\ufb01re and token \ufb02ow\n2.2\nCommonality and Difference between\nModels\nIt is pedagogical to let students notice the common structure\nshared by a number of models. However, the apparent resemblance\noften causes confusion. Such confusion can be observed not only\nin software modeling graphs but in many diagrams found in daily\nnewspapers, magazines, reports, proposals and other documents. It\nis often the case that one vertex denotes a type of things and an-\nother denotes quite a different type on the same diagram or one\ntype of edges co-exist with edges with different meaning. Thus,\nit is important to make students consciously aware the differences\nbetween different models. We often experience that when we let\nstudents draw data \ufb02ow diagrams who appear to have understood\nthe data \ufb02ow model perfectly, the diagrams turn out to be some-\nthing like control \ufb02ow graphs.\nTo show the difference, it is instructive to categorize models rep-\nresented by graphs. Basically, there are two categories.\n1. Static models:\nAn edge connecting vertex A and vertex B represents a rela-\ntion between A and B. When the edge is undirected, it means\n\u201cA and B are in some relation\u201d and when directed, it means\n\u201cA has a relation with B\u201d. Typical examples include entity\nrelationship model, class diagram and semantic network.\n2. Dynamic models:\nAn edge from vertex A to B denotes a move from A to B.\nThe edge in this case is always directed. There are two sub-\ncategories:\n(a) The case where a view of control moves from A to B.\nExamples are control \ufb02ow model and state transition\nmodel.\n(b) The case where data or objects \ufb02ow from A to B. Exam-\nples are data \ufb02ow model, work \ufb02ow model, and trans-\nportation \ufb02ow model.\nStatic models and dynamic models may not be easily confused\nbut confusion betweendifferent dynamic models are often observed,\ne.g. data \ufb02ow and control \ufb02ow or state transition and activity tran-\nsition. Since graphs are intuitively understandable, their semantics\nare apt to be understood ambiguously or misunderstood.\n3.\nUML\nUML diagrams can also be viewed in terms of graph structures.\nTable 2 shows graph structures of \ufb01ve UML diagrams.\nTable 2: Graph structures of UML diagrams\ndiagram\nvertex\nedge\nclass diagram\nclass\ngeneralization,\ncomposition,\nassociation\nstate machine\nstate\ntransition\nactivity diagram\nactivity\ncontrol \ufb02ow\ncollaboration diagram\nobject\nmessage \ufb02ow\nsequence diagram\nmessage\nmessage \ufb02ow\nanchor point\nIt is usually not desirable to teach UML per se. UML is a col-\nlection of miscellaneous diagrams and its speci\ufb01cation is continu-\nously changing. For the pedagogical purpose, UML had better be\nregarded as a catalogue of analysis and design know-how collected\naround diagrammatic representations. Diagrams should be selected\naccording to the policy of how to teach modeling methods.\nEach UML diagram contains overly rich constructs, which some-\ntimes blur the essential property of the model. For example, the\nactivity diagram is essentially a control \ufb02ow diagram but it also in-\ncludes a notation for data \ufb02ow description. From the stance of em-\nphasizing differences between various models, it is not appropriate\nto include such ad hoc constructs. By the same token, the collab-\noration diagram (, renamed to \u201ccommunication diagram\u201d in UML\n2) is explained to have the equivalent semantics as the sequence\ndiagram. But if that is the case, signi\ufb01cance of the collaboration\ndiagram is considerably limited. The author prefers to regard it as\nshowing collaboration relations between objects, integrating a set\nof different sequence diagrams.\n4.\nCONCLUSION\nSoftware modeling is important by itself but teaching modeling\nin the software engineering course has at least two additional mean-\nings. One is to give a bird\u2019s-eye view to the whole software engi-\nneering through the standpoint of modeling technology. The other\nis to attract interest of good students who may not have much expe-\nrience in developing a real-scale software but possess intelligence\nand will to attack complexity of modern software construction.\n5.\nREFERENCES\n[1] T. Tamai. Foundations of Software Engineering. Iwanami\nShoten, Tokyo, Japan, 2004. in Japanese.\n610\n",
    "pdf_url": "",
    "references": [
      "[1] T. Tamai. Foundations of Software Engineering. Iwanami"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "University of Kent"
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "A Prototype Implementation of an Orthographic Software Modeling Environment",
    "resume": "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
    "auteurs": [
      "Colin Atkinson",
      "Dietmar Stoll",
      "Jacques Robin",
      "Recife",
      "Brasil",
      "D.2.2"
    ],
    "institutions": [
      "Dietmar Stoll University of Mannheim, TunjicUniversity of Mannheim,",
      "Orthographic Software Modeling (OSM) is a view-centricsoftware engineering approach that aims to leverage the or-thographic projection metaphor used in the visualization ofphysical objects to visualize software systems. Although thegeneral concept of OSM does not prescribe specic sets ofviews, a concrete OSM environment has to be specic aboutthe particular views to be used in a particular project. Atthe University of Mannheim we are developing a prototype OSM environment, nAOMi, that supports the views denedby the KobrA 2.0 method, a version of KobrA adapted forOSM. In this paper we provide an overview of the KobrA 2.0metamodel underpinning nAOMi and give a small exampleof its use to model a software system.",
      "Colin Atkinson University of Mannheim,"
    ],
    "mots_cles": [
      " Orthographic Software Modeling",
      " View-based Modeling "
    ],
    "texte_integral": "A Prototype Implementation of an Orthographic Software\nModeling Environment\nColin Atkinson\nUniversity of Mannheim,\nGermany\natkinson@informatik.uni-\nmannheim.de\nDietmar Stoll\nUniversity of Mannheim,\nGermany\nstoll@informatik.uni-\nmannheim.de\nChristian Tunjic\nUniversity of Mannheim,\nGermany\ntunjic@informatik.uni-\nmannheim.de\nJacques Robin\nUniversidade Federal de\nPernambuco, Recife, Brasil\njr@cin.ufpe.br\nABSTRACT\nOrthographic Software Modeling (OSM) is a view-centric\nsoftware engineering approach that aims to leverage the or-\nthographic projection metaphor used in the visualization of\nphysical objects to visualize software systems. Although the\ngeneral concept of OSM does not prescribe speci\ufb01c sets of\nviews, a concrete OSM environment has to be speci\ufb01c about\nthe particular views to be used in a particular project. At\nthe University of Mannheim we are developing a prototype\nOSM environment, nAOMi, that supports the views de\ufb01ned\nby the KobrA 2.0 method, a version of KobrA adapted for\nOSM. In this paper we provide an overview of the KobrA 2.0\nmetamodel underpinning nAOMi and give a small example\nof its use to model a software system.\nCategories and Subject Descriptors\nD.1.7 [Programming Techniques]: Visual Programming;\nD.2.2 [Design Tools and Techniques]: Computer-aided\nsoftware engineering (CASE); D.2.6 [Software Engineer-\ning]: Programming Environments\u2014Graphical environments\nKeywords\nOrthographic Software Modeling, View-based Modeling\n1.\nINTRODUCTION\nOrthographic Software Modeling (OSM) is based on three\nfundamental hypotheses \u2014 (a) that it is feasible to inte-\ngrate the many di\ufb00erent kinds of artifacts used in contempo-\nrary software engineering methods within a single coherent\nmethodology in which they are treated as views, (b) that it\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are\nnot made or distributed for pro\ufb01t or commercial advantage and that copies\nbear this notice and the full citation on the \ufb01rst page. To copy otherwise, to\nrepublish, to post on servers or to redistribute to lists, requires prior speci\ufb01c\npermission and/or a fee.\nVAO \u201913, July 2, 2013, Montpellier, France\nCopyright 2013 ACM 978-1-4503-2041-2 ...$15.00.\nis feasible to create an e\ufb03cient and scalable way of support-\ning these views by generating them dynamically, on-the-\ufb02y,\nfrom a Single Underlying Model (SUM) using model-based\ntransformations and (c) that it is feasible to provide an in-\ntuitive metaphor for navigating around these many views\nby adapting the orthographic projection technique under-\npinning the CAD tools used in other engineering disciplines.\nFigure 1: Orthographic Projection.\nAs shown in Figure 1, the main advantages of using the\nidea of orthographic projection to de\ufb01ne the views used\nto visualize and described a system are that they (a) can\nbe organized according to a simple and easy-to-understand\nmetaphor and (b) collectively represent all the properties of\na system with minimal overlap and redundancy. In practice\nthis translates into a set of \u201cdimensions\u201d, each containing\nwell de\ufb01ned choices (or so called \u201cdimension elements\u201d) that\ncan be used to select individuals views.\nAs shown in Figure 2, the main advantage of making the\nartifacts used to describe a software system views of a SUM\nis that the number of pairwise coherence relationships that\nhave to be maintained is reduced and new views can be in-\ntroduced by simply de\ufb01ning their relationship to the SUM.\nMoreover, the importance of this advantage grows quickly\nas the size of the system and the complexity of the deployed\ndevelopment methodology increase. Another important ad-\nvantage is that the dominance of one particular kind of view\nover the development process (e.g. code) at the expense of\nother kinds of views (e.g. graphical models) is reduced so\nthat any appropriate type of views can be used to enrich\nthe underlying description of the system, depending on the\nneeds and skills of the stakeholder involved. This makes it\npossible to subsume all view types under the same, overarch-\nSUM\nSUM / View Centric Environment\nArtifact / Tools Centric Environment\nFigure 2: Consistency Dependencies in Artifact-oriented versus View-oriented Environments.\ning development process and methodology (e.g. agile-driven,\nfocusing on small development cycles, or model-driven de-\nvelopment, based on transformations between abstraction\nlevels). Although the details of how the views are created\nfrom the SUM and how the SUM is updated from the views\nare not central to the approach, a natural implementation\nis to use the visualization and transformation technologies\no\ufb00ered by model driven software engineering (MDSE).\nTo explore the validity of these hypotheses at the Uni-\nversity of Mannheim we have been developing a prototype\nOSM modeling environment based on an enhanced version\nof the KobrA method for model-driven, component-oriented\ndevelopment, KobrA 2.0 [1]. This was chosen as a basis for\nthe prototype, known as the Open, Adaptable, Orthographic\nModeling Environment (nAOMi) [13] because its views were\ndesigned with the precise goals of being (a) genuine pro-\njections of a subject containing carefully selected subsets\nof information about that subject, (b) minimalistic in the\nsense that they should overlap to the smallest extent possible\nand contain the minimum necessary models elements, and\n(c) selectable via a set of independent \u201cdimensions\u201d which\nre\ufb02ect di\ufb00erent fundamental concerns of development (i.e.\nabstraction levels, composition or variants). In other words,\nKobrA already provided one of the \u201cmost orthogonal\u201d sets\nof views for visualizing software systems of any contempo-\nrary method. More details about the actual views and di-\nmensions de\ufb01ned in KobrA are presented in the following\nsections. More information on OSM can be found in [2] and\n[3].\nnAOMi is implemented as an Eclipse plugin using the\nEclipse Modeling Framework (EMF) as the underlying mod-\neling platform and UML 2.0 tools [4] to generate and edit\nviews.\nThe KobrA 2.0 metamodel on which the current\nversion of nAOMi is based is a specialization of the UML\nmetamodel composed of three separate packages \u2014 one for\nthe SUM, one for the views and one for the transformations\n(Figure 3). The UML was chosen as the base language be-\ncause of its maturity and widespread acceptance, making the\nenvironment usable to the largest possible body of develop-\ners. UML elements not needed in KobrA 2.0 are excluded\nusing OCL constraints while new elements or properties are\nKobrA2\nTransformation\nSUM\nViews\nFigure 3: KobrA 2.0 Top Level Packages.\nintroduced by specializing existing elements.\nThe unique contribution of this paper is to elaborate on\nthe structure of the KobrA 2.0 metamodel and how it is used\nto drive nAOMi. The three following sections each focus on\none of the three main components of the metamodel \u2014 the\nSUM, the views and the transformations . This is followed\nby a brief overview of the OSM navigation paradigm in Sec-\ntion 5 before a small example of the approach is presented in\nSection 6. Section 7 then concludes the paper with related\nand future work.\n2.\nSUM PACKAGE\nFigure 4 depicts the internal structure of the SUM pack-\nage which is based on the UML metamodel. There are three\nmain subpackages, two containing the structural and behav-\nioral constructs respectively, and one containing the con-\nstraints that ensure that the metaclasses are used according\nto the KobrA conventions and rules.\nThe Classes subpackage of the Structure package contains\nsome of the most fundamental elements of the KobrA meta-\nmodel, such as Class and ComponentClass.\nThe internal\nstructure of this package is illustrated in Figure 5. Com-\nponentClass represents objects with complex and reusable\nbehaviors, while Class captures simple \u201cdata type\u201d objects\nthat have only very simple or non-reusable behaviors. The\nmodeler has to decide whether it is necessary to model a\nspeci\ufb01c part of the system as a ComponentClass and include\nstate charts and activity diagrams, or whether it is su\ufb03cient\nto use a Class (which is limited to using OCL constraints).\nComponentClass inherits (indirectly via Class) from Com-\nmunications so it also has the isActive attribute. This makes\nKobrA2::SUM::Constraint::Behavioral\nKobrA2::SUM::Constraint::Structural\nKobrA2::SUM::Constraint\nKobrA2::SUM::Constraint::Common\nKobrA2::SUM::Behavior::ProtocolStateMachines\nKobrA2::SUM::Behavior::Common\nKobrA2::SUM::Behavior::Activities\nKobrA2::SUM::Behavior::Actions\nKobrA2::SUM::Behavior\nKobrA2::SUM::Structure::Classes\nKobrA2::SUM::Structure::Types\nKobrA2::SUM::Structure::Instances\nKobrA2::SUM::Structure::Elements\nKobrA2::SUM::Structure\nKobrA2::SUM::Constraint::OclExpressions\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\n<<merge>>\nFigure 4: KobrA 2.0 SUM Package.\nit possible to model whether its instances are active or pas-\nsive. Active objects, which can be used to model threads and\nprocesses ([8] p. 438), start to execute their behavior as soon\nas they are created and perform operations spontaneously.\nA ComponentClass may exhibit complex behavior. In Ko-\nbrA, this behavior may be speci\ufb01ed in the form of\nUML\nState Diagrams (de\ufb01ning acceptable operation invocation\nsequences), and in the form of Activities (de\ufb01ning algorithms\nof operations). UML Interaction elements (in sequence dia-\ngrams) can be derived from the activity elements and thus\nare not included in the SUM. As KobrA aims to facilitate\nautomatic checking of allowed sequences of operation calls,\nProtocol State Machines are supported instead of general\nstate machines. Since the latter include a large variety of\nelements not needed for specifying acceptable operation se-\nquences or automatic checking, OCL constraints are used to\nprohibit the use of unwanted features.\ncontext\nComponentClass\n-- only\nallow\nActivity\nelements\nor\nProtocolStateMachines\ninv: ownedBehavior ->forAll( oclIsKindOf( Actitivity) or\noclIsKindOf ( ProtocolStateMachine ))\nFor example, since KobrA has no concept of roles for com-\nponents, the use of role also needs to be prohibited. The part\nassociation refers to owned properties of components whose\nattribute isComposite is true. As KobrA uses associations\nlike nests and creates for components, part, required and\nprovided are not needed. Connectors (i.e. delegation and\nassembly) are not used in KobrA either so ownedConnector\nis excluded.\nClass\nKobrA2::SUM::Structure::Classes\nGeneralizationSet\nAssociationClass\nComponentClass\nProperty\nUsage\nAssociation\nOperation\nPackageable\nElement\nParameter\nAcquires\nCreates\nNests\nUML::Component::PackagingComponents::Component\nUML::CommonBehaviors::Communications::Class\n+ownedOperation\n*\n+class\n0..1\n+supplier\n1..*\n{subsets supplierDependency}\n+supplierUsage\n*\n+client\n1..*\n{subsets clientDependency}\n+clientUsage\n*\n+ownedAttribute\n*\n+class\n0..1\n+powertype\n0..1\n+powertypeExtent\n*\n+packagedElement\n*\n{subsets component}\n+componentClass\n0..1\n+/superClass\nFigure 5: KobrA 2.0 Classes Package.\ncontext\nComponentClass\ninv: role ->union(part)->union( ownedConnector )\n->union( collaborationUse )-> union( representation )\n->union( realization)->union(required)\n->union(provided)->isEmpty ()\n3.\nVIEWS PACKAGE\nThe structure of the Views package is illustrated in Figure\n6. Again, since most of the views de\ufb01ned in KobrA 2.0 are\nbased on UML diagrams, the view metamodels have similar\nelements to the SUM metamodel. The big di\ufb00erence to the\nSUM is that there are no restrictions on the use of the view\nmetamodel elements.\nFor instance, views for a particular\npurpose such as supporting model checkers can be supported\nby adding elements unrelated to the UML.\nThe substructure of the Views package re\ufb02ects the types\nand organization of the KobrA views according to the view\n\u201cdimensions\u201d supported in nAOMi (cf. example in Section\n6). At the top level, the Views package is thus decomposed\ninto the Speci\ufb01cation and Realization options of the encap-\nsulation dimension.\nThese, in turn are both decomposed\ninto the Structural, Behavioral and Operational options of\nthe Projection dimension.\nFinally, with the exception of\nthe behavioral option, these are also all subdivided into the\nService and Type options of the granularity dimension. This\ndimension, with its two options, is an addition to the original\nversion of KobrA.\nThe Service view shows the direct, publicly visible rela-\ntionships of the subject ComponentClass to other Compo-\nnentClasses, while the Type view shows the publicly visi-\nble relationships of the subject to simple Classes. As with\nthe SUM, constraints have been de\ufb01ned to control what can\ngo into each view and when they are well formed. For ev-\nery view, a constraint enumerates all allowed elements (not\nshown in this paper).\nIn the following, some of the other constraints for the\nService view are elaborated. Since this view is a black-box\nview, the internals of ComponentClasses (nestedClassi\ufb01er)\nare not shown.\ncontext\nComponentClass\n-- no nested\nclassifiers , no\nprotocol\ninv: nestedClassifier ->union(protocol)->isEmpty ()\nClasses are only allowed if they are generalizations of Com-\nponentClasses, (or any of its superclasses, since a Compo-\nnentClass may inherit from a class as shown in the con-\nstraints with context Class. The following invariants ensure\nthat only publicly visible attributes and operations are in\nthis view, for both classes and ComponentClasses (which\ninherit from Class).\nClass\nService\nType\nInstance\nService\nType\nStructural\nSpecification\nOperational\nService\nType\nProtocol\nBehavioral\nKobrA2::Views::Derived\nComponentClassDependencies\nOperationDependencies\nInstance\nService\nType\nClass\nService\nType\nStructural\nRealization\nOperational\nService\nType\nBehavioral\nAlgorithm\nViews\nConcreteSyntax\nSubject\n<<import>>\n<<merge>>\n<<merge>>\n<<import>>\n<<merge>>\n<<import>>\nFigure 6: KobrA 2.0 Views package nesting.\ncontext\nClass\n-- only\nallow\nclasses\nthat\nare\ndirect or\nindirect\ngeneralizations\nof\nComponentClasses\nin this\nview\ndef: ccGeneralization : generalization .specific ->\nexists( oclIsKindOf ( ComponentClass ))\ninv:\ngeneralization .specific ->select( oclIsTypeOf (\nClass))->exists(s|s. ccGeneralization )\nor\nccGeneralization\n-- only\npublic\nattributes\nin this\nview\ninv: ownedAttribute ->forAll(visibility =# public)\n-- only\npublic\nOperations\nare\nallowed\nin the\nspecification\ninv: ownedOperation ->forAll(visibility =# public)\nOnly operation signatures are shown in this view, so pre-,\npost- and bodyconditions, as well as activities are omitted,\nwhich is re\ufb02ected in the last constraint.\ncontext\nOperation\n-- only\nthe\nsignature\nof the\nOperation\nis shown , not\nits\nbehavior (role\nname \"method\" refers to the\nActivities\nof the\noperation), or\ndependencies\ninv: method ->union( precondition )->union(body)->union(\npostcondition )->isEmpty ()\n4.\nTRANSFORMATIONS PACKAGE\nThe package AllViews provides the foundation for speci-\nfying the transformations between the SUM and the views\nin both directions. Part of the package\u2019s contents are shown\nin Figure 7.\nThe Abstraction concept (which is in fact a\nKobrA2::Transformation::Common::AllViews\nAbstraction\nTransformationExpression\nViewElement\nSumElement\nView\nKobrA2::SUM::Structure::Elements::Element\nKobrA2::Views::ConcreteSyntax::Element\nKobrA2::SUM::Constraint::Behavioral::Exp\nressionInOcl\nKobrA2::Views::Subject::View\n{subsets mapping}\n0..1\n0..1\n{subsets clientDependency}\n+abstraction 1\n{subsets client}\n+ve 1\n1..*\n1\n{subsets supplier}\n+se 1\n{subsets supplierDependency}\n+abstraction 1..*\nFigure 7: Transformation abstractions.\ndependency reused from the UML but with additional con-\nstraints) plays the key role in relating elements from the\nSUM to elements of a view. Abstraction is actually mapped\nto ExpressionInOcl.\nWhen appearing in transformations,\nthe equals sign links elements in the SUM to the respective\nelements in the view, and vice versa. For instance, equal-\nity of the general meta-association of a Generalization in\na transformation invariant means that, when following gen-\neral, there must be an element in the SUM and in the view\nfor which similar transformation expressions are speci\ufb01ed.\nIn the case of KobrA 2.0, which has many projections that\njust select a subset of elements using one-to-one abstrac-\ntions, this allows concise declarative TransformationExpres-\nsions. Together with the view constraints, a CASE tool can\nbe implemented which uses a transformation language of the\nimplementor\u2019s choice, for instance the Atlas Transformation\nLanguage (ATL) [11] or QVT [9]. The role names se and ve\nare short for SumElement and ViewElement, respectively.\nThese roles subset the client and supplier roles from the\nUML.\nSUM elements are translated into UML elements with\nstereotypes, so that the views are easy to manage for de-\nvelopers familiar with the UML. The bidirectional mappings\nbetween stereotyped view elements and non-stereotyped SUM\nelements are expressed in the constraints of the Association-\nAbstraction, a subclass of the Abstraction from the AllViews\npackage. This is also an example of a transformation which\nis reused in other views.\ncontext\nAssociationAbstraction\ninv: ve.memberEnd = se.memberEnd\ninv: ve.ownedEnd = se.ownedEnd\nivn: ve. navigableOwnedEnd = se. navigableOwnedEnd\ninv: se. oclIsKindOf(Acquires) implies ve.\nhasStereotype (\u2019acquires \u2019)\ninv: ve. hasStereotype (\u2019acquires \u2019)\nimplies\nse.\noclIsKindOf (Aquires)\ninv: se. oclIsKindOf(Nests) implies\nve. hasStereotype (\u2019\nnests \u2019)\ninv: ve. hasStereotype (\u2019nests \u2019)\nimplies se. oclIsKindOf\n(Nests)\ninv: se. oclIsKindOf (Creates) implies\nve. hasStereotype\n(\u2019creates \u2019)\ninv: ve. hasStereotype (\u2019creates \u2019)\nimplies se.\noclIsKindOf (Creates)\nFigure 8 shows the main elements involved in the trans-\nformation of the black box structural view for Component-\nClasses. The \ufb01rst transformation constraint is on the view\nand declares the starting point for the transformation. It\nstates that the subject ComponentClass and its generaliza-\ntions (using a SUM utility function, superClosure) are in the\nview.\nThe following transformation rules illustrate how to create\nthe output (i.e. view) elements from the input (i.e. SUM) el-\nements, such as the publicly visible attributes and operations\nof the ComponentClass and the acquired ComponentClasses.\nThe \ufb01rst constraint for ComponentClassAbstraction states\nthat references to potential general classes (and Component-\nClasses) of ComponentClasses are mirrored in the view. In\naddition, ComponentClasses will be shown with the corre-\nsponding stereotypes.\nThe ComponentClass owns various\ntypes of associations, so in this view only the acquires asso-\nciations are selected (whose transformation rules are cov-\nered in the common transformation packages).For classes\nand ComponentClasses, only publicly visible attributes and\noperations appear in the view.\nClass invariants are also\ncopied. Classes that may appear in this view (e.g. as gener-\nalizations of ComponentClasses) may have a powertype (role\nname powertypeExtent) which will be displayed.\nThe last transformation statement copies the class refer-\nences of operations. As with all views, the transformation\nrules, the common transformation statements (which also\ncover operations) and the view constraints serve as a speci-\n\ufb01cation for the implementation of a view. Individual CASE\ntools can use di\ufb00erent implementation techniques as long as\nthey conform to the semantics of these rules and constraints.\nKobrA2::Transformation::Specification::Structural::Class::Service\nComponentClassAbstraction\nKobrA2::Transformation::Common::Feature::OperationAbstraction\nKobrA2::Transformation::Common::AllViews::Abstraction\nKobrA2::SUM::Structure::Classes::ComponentClass\nKobrA2::SUM::Structure::Classes::Operation\nKobrA2::SUM::Structure::Classes::Class\nOperationAbstraction\nClassAbstraction\n+se\n1\n1..*\n+se\n1\n1..*\n+se\n1\n1..*\nFigure 8: Transformation to the Speci\ufb01cation Structural Service View.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassService\ninv: ownedMember ->select( oclIsKindOf(Class)) =\nsubject.superClosure ->union(subject.acquires.\nsuperClosure )\ncontext\nComponentClassAbstraction\ninv: ve.superClass = se. superClass\ninv: ve. hasStereotype (\u2019ComponentClass \u2019)\ninv: se.isSubject\nimplies (ve. hasStereotype (\u2019subject\n\u2019) and ve.ownedMember ->select( oclIsKindOf (\nAssociation )) = se.ownedMember ->select(\noclIsKindOf (Acquires)))\ncontext\nClassAbstraction\ninv: ve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\ninv: ve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public)\ninv: ve.\u2018inv \u2019 = se.\u2018inv \u2019\n-- copy\npowertypeExtent\nthat is only\nallowed\nfor\nclass\ninv: ve. powertypeExtent = se. powertypeExtent\ncontext\nOperationAbstraction\ninv: ve.class = se.class\nFor the black box type view, only publicly visible at-\ntributes and operations of classes (as opposed to Compo-\nnentClasses) used by the subject can be seen. This is spec-\ni\ufb01ed in the \ufb01rst rule which de\ufb01nes owned members of the\nview and thus serves as the starting point of the transfor-\nmation. cbbTypes is a utility function de\ufb01ned in the SUM\nwhich computes the black box types by selecting the types\nof the subject\u2019s public attributes and parameter types of its\npublic operations.\nClass invariants and potential powertypes and connections\nto the classes in this view are shown as well. There may\nalso be Enumerations, for which the EnumerationLiterals\nare displayed.\nThe transformation rules for this view are almost the same\nas the realization transformation constraints from the pack-\nage Transformation::Realization::Structural::Class::Type. The\ndi\ufb00erences are the select(visibility=#public) statements for\noperations and attributes.\ncontext\nKobrA2 :: Views :: Subject ::\nSpecificationStructuralClassType\ninv: ownedMember ->select( oclIsKindOf(Class) or\noclIsKindOf(\u2018Enumeration \u2019) or\noclIsKindOf (\nAssociation)) = subject ->union(subject.cbbTypes)\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nClassAbstraction\ninv: not se.oclIsKindOf ( ComponentClass ) implies (\nve. ownedAttribute = se.ownedAttribute ->select(\nvisibility =# public)\nve. ownedOperation = se.ownedOperation ->select(\nvisibility =# public))\ninv: ve. powertypeExtent = se. powertypeExtent\ninv: ve. superClass = se.superClass\ninv: \u2018ve.inv \u2019 = \u2018se.inv \u2019\ncontext\nComponentClassAbstraction\ninv: se.isSubject\nimplies\nve. hasStereotype (\u2019subject \u2019)\ncontext\nEnumerationAbstraction\ninv: ve. ownedLiteral = se. ownedLiteral\ncontext\nEnumerationLiteralAbstraction\ninv: ve. specification = se. specification .\nstringInSignature\n5.\nNAVIGATION\nMost of today\u2019s tools use some combination of trees to\norganize the content of models as well as the views used to\nvisualize a software system or component. In an any envi-\nronment incorporating a number of di\ufb00erent tools there is\ninvariably a large number of di\ufb00erent trees storing a het-\nerogeneous mix of artifacts including model elements (e.g.\nclasses, instances, associations), diagrams (e.g.\nclass dia-\ngrams, state diagrams) and other artifact types (source code,\nXML \ufb01les, con\ufb01guration \ufb01les ). To work with all the views in\na traditional development environment, therefore, engineers\ntypically have to learn about the organization structures of\nall the incorporated tools.\nIn contrast to conventional paradigms for organizing and\nnavigating the many views used to visualize a system, OSM\nemploys the metaphor of a multi-dimensional cube. More\nspeci\ufb01cally, as illustrated in Figure 9, OSM regards dimen-\nsion of the underlying methodology as representing a di\ufb00er-\nent dimension of the cube, and each independently variable\naspect of that dimension is a selectable dimension element.\nSelecting a view thus simply corresponds to selecting a single\ncell within the cube. In general, three types of dimensions\nare supported: static dimensions in which the number of\nFigure 9: Dimension-based navigation.\nselectable elements (i.e. coordinates) is \ufb01xed, dynamic di-\nmensions in which the number of elements is dynamic (i.e.\nderived from the SUM), and mixed dimensions which have\nboth static and dynamic elements.\nTo support the OSM dimension based navigation metaphor\nfor KobrA, we de\ufb01ned the seven dimensions indicated on the\nleft hand side of Figure 10 which is a sceenshot of nAOMI.\nThe Abstraction dimension (not expanded here), which has\nthree static dimension elements, PIM (platform independent\nmodel), PSM (platform speci\ufb01c model) and Code, captures\nthe model-driven development concern of KobrA. The ver-\nsion dimension captures the state of the modeled system at\nspeci\ufb01c points in time. The Component dimension, which\nhas dynamic dimension elements de\ufb01ned by instances of the\nclass ComponentClass in the SUM, captures the component-\nbased development concern of KobrA.\nThe Encapsulation dimension, which has two \ufb01xed ele-\nments, supports the distinction between Speci\ufb01cation (black\nbox) and Realization (white box) views of components, while\nthe Projection dimension with the \ufb01xed elements Structural,\nOperational and Behavioral covers the di\ufb00erent information\ntypes. The Granularity dimension provides a \ufb01ner grained\ndistinction between views describing the types used by com-\nponents (Type granularity) and views describing the required\nand provided interfaces (Service granularity). The Opera-\ntion dimension allows a selection of individual operations.\nIn the ideal case, when all views are truly orthogonal, the\nchoices that can be made in each dimensions are completely\nindependent.\nHowever, this is very di\ufb03cult to achieve in\nsoftware engineering. The approach still works if the views\nare not completely orthogonal, but dependencies then occur\nbetween di\ufb00erent choices in di\ufb00erent dimensions, so that the\ndecisions made in one dimensions may a\ufb00ect choices possi-\nble in another dimension. This is best handled by giving\ndimensions a precedence ranking determined by the order\nin which they appear (the top being the highest). When an\nelement in a dimension is selected, the tool automatically\nmakes default selections for dimensions of lower precedence\n(i.e.\ndimensions lower down) and disables selections that\nwould navigate to cells (i.e. views) which are not (yet) de-\n\ufb01ned by the method at hand.\n6.\nSHOPPING CART EXAMPLE\nTo show how a software system can be speci\ufb01ed using\nnAOMi, this section presents a case study based on a shop-\nping cart system. A ShoppingCart component collects and\nFigure 10: Speci\ufb01cation Structural View.\nmanages the products selected by users and supports pay-\nment via a credit card.\nFigure 10 illustrates a structural\nview of the component.\nIn the dimension navigator on the left hand side, PIM\nwas chosen for the \u201cAbstraction Level\u201d (not expanded in the\nscreenshot). The second dimension is the state of the soft-\nware system at a certain point in time. The picture shows\nthat the latest available version was chosen. As with every\nchoice in a dimension, it may in\ufb02uence the options in lower\nranked dimensions. The component under consideration is\nthe ShoppingCart, for which a black box view is selected\nin the next dimension. After the user selects the structural\nprojection option and the service level granularity, the tool\nautomatically chooses the option for all operations in the\nlast dimension, as there is no editor registered for the other\noptions.\nThe component under development is presented with the\nstereotype subject and its relationship to other components\nand classes is shown in the view, which corresponds to a cell\nof the multi-dimensional navigation cube, and is generated\non-the-\ufb02y from the SUM when it is selected. The classes\nProduct and CreditCard can be used as data types in the\noperations of the component.\nFigure 11 illustrates the operational view in which an\noperation can be formalized using pre- and postconditions.\nThe precondition corresponds to the assumes clause in and\nthe postcondition corresponds to the result clause. As in the\nUML, the precondition of an operation must be true when\nthe operation is invoked and the postcondition must be true\nwhen the operation is \ufb01nished. The operation addProduct\nin Figure 11 must be in state CollectingProducts or Empty\nwhen invoked. This is also visible in the behavioral view,\nFigure 11: addProduct() Operation Speci\ufb01cation.\nsince there are only two transitions with the operation ad-\ndProduct. Both leads to the state CollectingProducts which\nis also a postcondition of the operation. The second post-\ncondition is that the cost attribute of the component must\nbe increased by the price of the added product. The pre- and\npostcondition can be expressed using the OCL. The proper-\nties of the component, states and operation parameters can\nbe used to formalise the constraints like as in this example.\nFigure 12 shows the publicly visible behaviour of the Shop-\npingCart component with states and transitions. The condi-\ntional transitions map to operations of the component. Like\nevery view, this view is also synchronized with the SUM so\nthat it is guaranteed that its operations, states and proper-\nties are consistent with those in the structural view.\nFigure 12: Speci\ufb01cation Behavioral Model.\nAlthough the operational view seems to be similar to the\nbehavioral view because of the overlapping information within\nthem, there are signi\ufb01cant di\ufb00erences. The focus of the op-\nerational view is on a precise formal de\ufb01nition of an opera-\ntion of a component. The operations can be enriched by pre-\nand postconditions which can be de\ufb01ned using complex OCL\nstatements, that formalize the complete behavior of an op-\neration. The additional information in the OCL statements\ncan be used for code generation and documentation.\n7.\nCONCLUSION\nAt the beginning of the paper we identi\ufb01ed three funda-\nmental hypothesis upon which the notion of OSM is based\n\u2014 (a) that it is feasible to integrate the many di\ufb00erent kinds\nof artifacts used in contemporary software engineering meth-\nods within a single coherent methodology in which they are\ntreated as views, (b) that it is feasible to create an e\ufb03-\ncient and scalable way of supporting these views by gener-\nating them dynamically, on-the-\ufb02y, from a Single Underly-\ning Model (SUM) using model-based transformations and\n(c) that it is feasible to provide an intuitive metaphor for\nnavigating around these many views by adapting the ortho-\ngraphic projection technique underpinning the CAD tools\nused in other engineering disciplines.\nThe prototype tool, nAOMi, described in this paper rep-\nresents the \ufb01rst step towards demonstrating the validity of\nthese hypotheses and showing that OSM is a viable approach\nto software engineering. Of the three hypotheses, (a) and (c)\nare most convincingly demonstrated by the prototype, since\nit shows that it is indeed possible to support all the views\nof the KobrA method within a single navigation metaphor.\nThe prototype tool does not demonstrate the validity of hy-\npothesis (b) to the same extent as the others due to its\nsmall size. Although it demonstrates the feasibility of gen-\nerating views from the SUM and vice-versa, the question of\nwhether such an approach scales up to large environments\nis still open.\nAlthough nOAMi is the only tool developed with the spe-\nci\ufb01c aim of supporting KobrA-based OSM, several other\ntools and methods have similar properties or aims.\nFor\nexample, Glinz et al.\n[10] describe a tool with a \ufb01sheye\nzooming algorithm which lets the user view a model with\nvarying amounts of detail depending on the context. It has\nto be investigated whether it is possible to combine the \ufb01sh-\neye zooming concept with the dimension-based navigation\nparadigm. While the KobrA 2.0 implementation of nAOMi\nheavily uses UML diagrams for developers, Glinz et al. use\ncustom diagram types, e.g.\nfor structural and behavioral\nviews.\nAn approach which also emphasizes the description of for-\nmal consistency rules (correspondences) between views is\nRM-ODP [5][6].\nHowever, this approach does not explic-\nitly mention the notion of a SUM and thus implies that\nconsistency rules should be de\ufb01ned in a pairwise fashion be-\ntween individual pairs of views. ArchiMate [7], which com-\nplements TOGAF [12], is an enterprise architecture mod-\neling language which o\ufb00ers two orthogonal \u201ddimensions\u201d for\nmodeling, (business, architecture, and technology) layers and\n(informational, behavioral and structural) aspects and also\nsuggests two more dimensions, purpose and abstraction level.\nHowever, as many of these views span multiple choices of a\nsingle\u201cdimension\u201d, the intuitive dimension-based navigation\nmetaphor of OSM can not be easily applied. There are also\nmore general approaches for view-based modeling but they\nare less speci\ufb01c in terms of consistency rules between views\nand provide little guidance on how to manage and navigate\nviews, for example the Zachman Framework [14].\nRegarding the practical use of OSM environments in the\nfuture, the biggest challenge is developing appropriate SUM\nmetamodels which can accommodate all the types of views\nand services that software engineers are accustomed to to-\nday. For this \ufb01rst prototypical SUM-based environment sup-\nporting the OSM approach we had a method at our disposal\n(KobrA) that already de\ufb01ned a full set of orthogonal UML-\nbased views. This allowed us to model the required SUM\nand view metamodels by simply adapting the UML meta-\nmodels, removing and adding model elements as needed.\nIn doing so we were able to manually ensure that the meta-\nmodels ful\ufb01lled the two core requirements of SUM-based en-\nvironments \u2014 (1) being minimalistic and (2) redundancy\nfree. If SUM-based software engineering environments are\nto take o\ufb00, and to be introduced into existing, heteroge-\nneous environments, more sophisticated ways of integrating\nexisting metamodels into a single uni\ufb01ed metamodel will be\nrequired.\n8.\nREFERENCES\n[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,\nO. Laitenberger, R. Laqua, D. Muthig, B. Paech,\nJ. W\u00a8ust, and J. Zettel. Component-Based Product Line\nEngineering with UML. Addison Wesley, Reading,\nMassachusetts, USA, 1st edition, November 2001.\n[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic\nSoftware Modeling: A Practical Approach to\nView-Based Development. In Evaluation of Novel\nApproaches to Software Engineering, volume 69 of\nCommunications in Computer and Information\nScience, pages 206\u2013219. Springer Berlin Heidelberg,\n2010.\n[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic\nService Modeling. In Proceedings of 15th IEEE EDOC\nConference Workshops (EDOCW), Helsinki, Finland,\n2011.\n[4] Eclipse Foundation. UML2Tools.\nhttp://wiki.eclipse.org/MDT-UML2Tools, 2013.\n[5] ISO/IEC and ITU-T. The Reference Model of Open\nDistributed Processing. RM-ODP, ITU-T Rec.\nX.901-X.904 / ISO/IEC 10746.\nhttp://standards.iso.org/\nittf/PubliclyAvailableStandards/index.html,\n1998.\n[6] J. I. J. Jose Raul Romero and A. Vallecillo. Realizing\nCorrespondences in MultiViewpoint Speci\ufb01cations. In\nProceedings of the Thirteenth IEEE International\nEDOC Conference, 1 - 4 September 2009, Auckland,\nNew Zealand, September 2009.\n[7] M. Lankhorst. Enterprise Architecture at Work.\nSpringer Berlin Heidelberg, 2009.\n[8] Object Management Group (OMG). OMG Uni\ufb01ed\nModeling Language (OMG UML), Superstructure,\nV2.1.2.\nhttp://www.omg.org/cgi-bin/doc?formal/07-11-02,\nNovember 2007.\n[9] Object Management Group (OMG). Meta Object\nFacility (MOF) 2.0 Query/View/Transformation, v1.0.\nhttp://www.omg.org/spec/QVT/1.0/PDF/, April 2008.\n[10] C. Seybold, M. Glinz, S. Meier, and N. Merlo-Schett.\nAn e\ufb00ective layout adaptation technique for a\ngraphical modeling tool. In Proceedings of the 2003\nInternational Conference on Software Engineering,\nPortland, 2003.\n[11] The Atlas Transformation Language (ATL). O\ufb03cial\nWebsite. http://www.eclipse.org/atl/, 2013.\n[12] The Open Group. TOGAF Version 9 - The Open\nGroup Architecture Framework.\nhttp://www.opengroup.org/architecture/\ntogaf9-doc/arch/index.html, Feb 2009.\n[13] University of Mannheim - Software Engineering\nGroup. nAOMi - opeN, Adaptable, Orthographic\nModeling EnvIronment.\nhttp://eclipselabs.org/p/naomi.\n[14] J. A. Zachman. The Zachman Framework: A Primer\nfor Enterprise Engineering and Manufacturing.\nhttp://www.zachmaninternational.com, 2009.\n",
    "pdf_url": "/media/Article_06.pdf",
    "references": [
      "[1] C. Atkinson, J. Bayer, C. Bunse, E. Kamsties,",
      "O. Laitenberger, R. Laqua, D. Muthig, B. Paech,",
      "J. W\u00a8ust, and J. Zettel. Component-Based Product Line",
      "Engineering with UML. Addison Wesley, Reading,",
      "Massachusetts, USA, 1st edition, November 2001.",
      "[2] C. Atkinson, D. Stoll, and P. Bostan. Orthographic",
      "Software Modeling: A Practical Approach to",
      "View-Based Development. In Evaluation of Novel",
      "Approaches to Software Engineering, volume 69 of",
      "Communications in Computer and Information",
      "Science, pages 206\u2013219. Springer Berlin Heidelberg,",
      "2010.",
      "[3] C. Atkinson, D. Stoll, and C. Tunjic. Orthographic"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "How to Teach Software Modeling",
    "resume": "To enhance motivation of students to study software engineering,some way of nding balance between the scientic aspect and thepractical aspect of software engineering is required. In this paper,we claim that teaching multiple software modeling techniques froma unied viewpoint is a good way of obtaining the balance andattracting the students interest as well.",
    "auteurs": [
      "Tetsuo Tamai",
      "Meguro-ku"
    ],
    "institutions": [
      "Tetsuo Tamai Graduate School of Arts and SciencesThe University of Tokyo3-8-1 Komaba, Meguro-kuTokyo 153-8902, "
    ],
    "mots_cles": [
      " software modeling",
      " software engineering education",
      " UML "
    ],
    "texte_integral": "How to Teach Software Modeling\nTetsuo Tamai\nGraduate School of Arts and Sciences\nThe University of Tokyo\n3-8-1 Komaba, Meguro-ku\nTokyo 153-8902, Japan\ntamai@acm.org\nABSTRACT\nTo enhance motivation of students to study software engineering,\nsome way of \ufb01nding balance between the scienti\ufb01c aspect and the\npractical aspect of software engineering is required. In this paper,\nwe claim that teaching multiple software modeling techniques from\na uni\ufb01ed viewpoint is a good way of obtaining the balance and\nattracting the students\u2019 interest as well.\nCategories and Subject Descriptors\nK.3.2 [Computers and Education]: Computer and Information\nScience Education\u2014computer science education; D.2.1 [Software\nEngineering]: Requirements/Speci\ufb01cation\u2014modeling\nGeneral Terms\nDesign\nKeywords\nsoftware modeling, software engineering education, UML\n1.\nINTRODUCTION\nSoftware engineering education at universities faces a common\nproblem; that is regular students do not usually have experience of\ndeveloping software for practical use and thus are not motivated for\nsoftware engineering aiming at high quality software production\nby a project team or a persistent organization. Software projects\nconducted by students simulating real scale software development\nmay help enhance students\u2019 motivation, although it requires a lot of\nefforts to prepare such projects and manage them.\nAnother way of solving this problem is to teach those who al-\nready have real experience in industry. In our case, there are cur-\nrently \ufb01ve Ph. D. students under the author\u2019s supervision who are\nworking at companies as well as doing research in our lab. As\na by-product, interactions between the part-time students and the\nother regular students stimulate each other, particularly enlighten-\ning the regular students to practical software issues. However, too\nmuch emphasis on practicality may bring negligence to scienceand\nCopyright is held by the author/owner.\nICSE\u201905, May 15\u201321, 2005, St. Louis, Missouri, USA.\nACM 1-58113-963-2/05/0005.\ntechnology and may generate anti-intellectualism. A good balance\nbetween the scienti\ufb01c aspect and the practical aspect of software\nengineering should always be pursued.\nIn our view, teaching various software modeling techniques is a\ngood way to achieve balanced software engineering education. It\nis needless to say that model is a key concept and modeling is an\nessential skill in software engineering. There are a variety of mod-\neling techniques; some are intuitive and quite accessibleto novices,\nwhile some are highly sophisticated and attract theory oriented stu-\ndents and researchers.\nIn this paper, we would like to show that it is effective to teach\nmultiple modeling techniques from a uni\ufb01ed viewpoint. It is based\non our experience of teaching software engineering courses at sev-\neral universities in Japan. Recently, the author published a textbook\non software engineering, speci\ufb01cally focused on software model-\ning (unfortunately, it is written in Japanese)[1]. The book covers\nthe whole area of software engineering, including design, testing\nand evolution but the modeling part has a role of attracting inter-\nests of intelligent students, who may not have much experience in\ndeveloping real scale software systems. It also gives a consistent\nviewpoint penetrating through various techniques employed in dif-\nferent stages of software engineering.\n2.\nMODELING TECHNIQUES\nIn software engineering, models are used for various purposes,\ne.g. life cycle model, process model, project model, product model,\nquality model, domain model, requirements model, design model,\nobject model, data model, etc. In the following, we basically focus\non requirements and design models but most of the discussionswill\nhold for other kinds of models.\nTeaching modeling is almost equal to teaching abstraction. Mod-\nels are constructed through capturing the crucial properties and\nstructure of the target, abstracting away irrelevant details. Thus,\nlearning how to model is a good training for mastering abstraction.\n2.1\nGraph Representation of Models\nMany software models are represented with diagrams. Wide ac-\nceptance of UML symbolizes the trend that diagrams are often pre-\nferred to textual languages. Among many types of diagrams, graph\nstructured diagrams are by far the most widely used. The reasons\nmay be as follows.\n1. A most fundamental way for human mind to understand the\nworld is by regarding it as consisting of a set of conceptual\nunits and a set of relations between them. Conceptual units\ncan be naturally illustrated with boxes or circles or whatever\nclosed \ufb01gures and relations can be illustrated with lines or ar-\nrows connecting such \ufb01gures, corresponding to vertices and\nedges of graphs, respectively.\n609\n2. It is easy to draw graph structured diagrams by hand or with\ndrawing tools.\n3. Concepts and algorithms of the graph theory are available\nand often useful in analyzing models represented by graphs.\nA typical example is reasoning on transitive relations by trac-\ning along paths of graphs. Also, the concept of subgraph is\nhighly useful in decomposinghigher-level models or cluster-\ning lower-level models.\nAccordingly, a number of models share the same structure of\ngraphs. Table 1 shows graph structures of some typical models.\nTable 1: Graph structures of typical models\nmodel\nvertex\nedge\nData \ufb02ow\nprocess\ndata \ufb02ow\nER\nentity\nrelationship\nState transition\nstate\ntransition\nJSD\nprocess\ndata stream connection\nstate vector connection\nActivity\nactivity\ncontrol \ufb02ow\nPetri net\nplace, transition\n\ufb01re and token \ufb02ow\n2.2\nCommonality and Difference between\nModels\nIt is pedagogical to let students notice the common structure\nshared by a number of models. However, the apparent resemblance\noften causes confusion. Such confusion can be observed not only\nin software modeling graphs but in many diagrams found in daily\nnewspapers, magazines, reports, proposals and other documents. It\nis often the case that one vertex denotes a type of things and an-\nother denotes quite a different type on the same diagram or one\ntype of edges co-exist with edges with different meaning. Thus,\nit is important to make students consciously aware the differences\nbetween different models. We often experience that when we let\nstudents draw data \ufb02ow diagrams who appear to have understood\nthe data \ufb02ow model perfectly, the diagrams turn out to be some-\nthing like control \ufb02ow graphs.\nTo show the difference, it is instructive to categorize models rep-\nresented by graphs. Basically, there are two categories.\n1. Static models:\nAn edge connecting vertex A and vertex B represents a rela-\ntion between A and B. When the edge is undirected, it means\n\u201cA and B are in some relation\u201d and when directed, it means\n\u201cA has a relation with B\u201d. Typical examples include entity\nrelationship model, class diagram and semantic network.\n2. Dynamic models:\nAn edge from vertex A to B denotes a move from A to B.\nThe edge in this case is always directed. There are two sub-\ncategories:\n(a) The case where a view of control moves from A to B.\nExamples are control \ufb02ow model and state transition\nmodel.\n(b) The case where data or objects \ufb02ow from A to B. Exam-\nples are data \ufb02ow model, work \ufb02ow model, and trans-\nportation \ufb02ow model.\nStatic models and dynamic models may not be easily confused\nbut confusion betweendifferent dynamic models are often observed,\ne.g. data \ufb02ow and control \ufb02ow or state transition and activity tran-\nsition. Since graphs are intuitively understandable, their semantics\nare apt to be understood ambiguously or misunderstood.\n3.\nUML\nUML diagrams can also be viewed in terms of graph structures.\nTable 2 shows graph structures of \ufb01ve UML diagrams.\nTable 2: Graph structures of UML diagrams\ndiagram\nvertex\nedge\nclass diagram\nclass\ngeneralization,\ncomposition,\nassociation\nstate machine\nstate\ntransition\nactivity diagram\nactivity\ncontrol \ufb02ow\ncollaboration diagram\nobject\nmessage \ufb02ow\nsequence diagram\nmessage\nmessage \ufb02ow\nanchor point\nIt is usually not desirable to teach UML per se. UML is a col-\nlection of miscellaneous diagrams and its speci\ufb01cation is continu-\nously changing. For the pedagogical purpose, UML had better be\nregarded as a catalogue of analysis and design know-how collected\naround diagrammatic representations. Diagrams should be selected\naccording to the policy of how to teach modeling methods.\nEach UML diagram contains overly rich constructs, which some-\ntimes blur the essential property of the model. For example, the\nactivity diagram is essentially a control \ufb02ow diagram but it also in-\ncludes a notation for data \ufb02ow description. From the stance of em-\nphasizing differences between various models, it is not appropriate\nto include such ad hoc constructs. By the same token, the collab-\noration diagram (, renamed to \u201ccommunication diagram\u201d in UML\n2) is explained to have the equivalent semantics as the sequence\ndiagram. But if that is the case, signi\ufb01cance of the collaboration\ndiagram is considerably limited. The author prefers to regard it as\nshowing collaboration relations between objects, integrating a set\nof different sequence diagrams.\n4.\nCONCLUSION\nSoftware modeling is important by itself but teaching modeling\nin the software engineering course has at least two additional mean-\nings. One is to give a bird\u2019s-eye view to the whole software engi-\nneering through the standpoint of modeling technology. The other\nis to attract interest of good students who may not have much expe-\nrience in developing a real-scale software but possess intelligence\nand will to attack complexity of modern software construction.\n5.\nREFERENCES\n[1] T. Tamai. Foundations of Software Engineering. Iwanami\nShoten, Tokyo, Japan, 2004. in Japanese.\n610\n",
    "pdf_url": "/media/Article_04.pdf",
    "references": [
      "[1] T. Tamai. Foundations of Software Engineering. Iwanami"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "Towards a Quantum Software Modeling Language",
    "resume": "We set down the principles behind a modeling language for quan-tum software. We present a minimal set of extensions to the well-known Unified Modeling Language (UML) that allows it to effec-tively model quantum software. These extensions are separate andindependent of UML as a whole. As such they can be used to ex-tend any other software modeling language, or as a basis for acompletely new language. We argue that these extensions are bothnecessary and sufficient to model, abstractly, any piece of quantumsoftware. Finally, we provide a small set of examples that showcasethe effectiveness of the extension set.",
    "auteurs": [
      "Carlos A. P\u00e9rez-Delgado\u2217",
      "G. Perez-Gonzalez",
      "Luis Potos\u00ed",
      "Modeling Language",
      "Carlos A. P\u00e9rez-Delgado",
      "G. Perez-Gonzalez"
    ],
    "institutions": [
      "University of Kent"
    ],
    "mots_cles": [
      " quantum computing",
      " software engineering",
      " UML "
    ],
    "texte_integral": "Towards a Quantum Software Modeling Language\nCarlos A. P\u00e9rez-Delgado\u2217\nUniversity of Kent\nCanterbury, Kent, United Kingdom\nc.perez@kent.ac.uk\nHector G. Perez-Gonzalez\nUniversidad Aut\u00f3noma de San Luis Potos\u00ed\nSan Luis Potos\u00ed, SLP, M\u00e9xico\nhectorgerardo@uaslp.mx\nABSTRACT\nWe set down the principles behind a modeling language for quan-\ntum software. We present a minimal set of extensions to the well-\nknown Unified Modeling Language (UML) that allows it to effec-\ntively model quantum software. These extensions are separate and\nindependent of UML as a whole. As such they can be used to ex-\ntend any other software modeling language, or as a basis for a\ncompletely new language. We argue that these extensions are both\nnecessary and sufficient to model, abstractly, any piece of quantum\nsoftware. Finally, we provide a small set of examples that showcase\nthe effectiveness of the extension set.\nCCS CONCEPTS\n\u2022 General and reference \u2192 General conference proceedings;\nDesign; \u2022 Software and its engineering \u2192 System descrip-\ntion languages; Unified Modeling Language (UML); Software\ndesign engineering; \u2022 Theory of computation \u2192 Quantum\ncomputation theory; Quantum information theory.\nKEYWORDS\nquantum computing, software engineering, UML\nACM Reference Format:\nCarlos A. P\u00e9rez-Delgado and Hector G. Perez-Gonzalez. 2020. Towards a\nQuantum Software Modeling Language. In IEEE/ACM 42nd International\nConference on Software Engineering Workshops (ICSEW\u201920), May 23\u201329, 2020,\nSeoul, Republic of Korea. ACM, New York, NY, USA, 3 pages. https://doi.org/\n10.1145/3387940.3392183\n1\nINTRODUCTION\nQuantum computation rose to prominence after the discovery of\nquantum algorithms[5, 7] that can efficiently perform tasks that\nare intractable classically. These discoveries propelled research and\ninterest in quantum computation. Today, there exists prototype\nquantum hardware with computational capabilities beyond that of\nany classical machine[1]. Further applications of quantum theory\nto computation have also been made in several areas of theory of\ncomputing, such as models of computation[6], data structures[8],\nand cryptography[2].\n\u2217Both authors contributed equally to this research.\nPermission to make digital or hard copies of all or part of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for components of this work owned by others than the\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\nand/or a fee. Request permissions from permissions@acm.org.\nICSEW\u201920, May 23\u201329, 2020, Seoul, Republic of Korea\n\u00a9 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.\nACM ISBN 978-1-4503-7963-2/20/05...$15.00\nhttps://doi.org/10.1145/3387940.3392183\nQuantum computation has, until today, been studied almost\nexclusively \u2018in the small.\u2019 A general understanding of quantum\ncomputation, or, quantum programming \u2018in the large\u2019 is yet to be\ndeveloped. Here we aim to set the foundations of a general frame-\nwork for studying, developing, and conveying quantum programs.\nWe aim to do so by developing a universal modeling language\nfor quantum software. Rather than develop such a language from\nscratch, we have decided to start from the well-known Unified\nModeling Language (UML)[3], and introduce a minimum set of\nextensions that allow it to effectively model quantum software.\nAssuming UML to be a shared common-language upon which\nwe can build, allows us to convey our original extensions much\nmore succinctly. Our extension set can, however, be applied with\nlittle or no modification to any other modeling language.\n2\nQ-UML\nBefore discussing in depth the extensions we are introducing, we\nmake a few fundamental observations on which we base the guiding\nprinciples for our extension set.\nOur first observation is about the nature of quantum computa-\ntion. The central difference between quantum and classical com-\nputation is in how it achieves its goals. Quantum computers have\naccess to quantum algorithms[7], and quantum data-structures[8],\nthat are unavailable to classical computers\u2014hence their perfor-\nmance advantage. Algorithms and data-structures are, however,\nimplementation details. Algorithms are an essential design choice\nwhile programming in the small. However, they are more often\nthan not completely ignored in large-scale software architectural\ndesign. For instance, UML diagrams seldom portray algorithms and\ndata-structures beyond a very high-level design perspective.\nIt would seem then that quantum computation introduces noth-\ning to computation that needs to be captured in a software design\ndiagram. This is not the case, and the reason for this is our second\nobservation. Quantum computation changes the very nature of in-\nformation itself. Quantum information is much richer than classical\ninformation. It is also much more challenging to store, transmit,\nand receive. If a module (class, object, etc.) needs to store, transmit\nor receive quantum information, then this is an important design\nconsideration\u2014which needs to be included in any effective software\ndesign.\nA third observation here is that the classical vs. quantum nature\nof the information used by a module is an important consideration\nboth when discussing its internal implementation and its interface.\nFurthermore, these two are separate and independent considera-\ntions.\nA classical module, implementing some classical behavior, would\nhave no need, or capability, to communicate quantum data. A quan-\ntum module may or may not have to; i.e. a module\u2019s quantum\nbehavior may be completely part of its internal implementation\n442\n2020 IEEE/ACM 42nd International Conference on Software Engineering Workshops (ICSEW)\nand not appear as part of its interface. For instance, take a module\nimplementing Shor\u2019s algorithm. Shor\u2019s algorithm uses quantum\neffects to efficiently factor a large integer into its prime factors.\nThe implementation of this module must necessarily be quantum.\nBoth the input (the large integer) and the output (the prime factors),\nconsist of classical information. And hence, the interface of such a\nmodule can be strictly classical.\nMore generally, we can conceive of quantum software modules\nthat have all classical inputs and outputs (like the above example),\nall quantum inputs and outputs, or a mix of both. A quantum soft-\nware design must address, for each individual interface element,\nwhether it is classical input/output, or if it is quantum. In short,\nwhether a module communicates classically or via quantum infor-\nmation, and whether its internal implementation requires quantum\nhardware are important considerations that need to be captured in\na design document.\nThe importance of such labelling should be clear. Quantum data\ncan only be stored and transmitted with special hardware designed\nto do so. More importantly, from an abstract, device-independent,\nstrictly software perspective: quantum and classical information\nare not interchangeable. Classical information is clone-able and\nadmits fanout operations, while quantum information (in general)\ndoes not. On the other hand, quantum information has a much\nlarger state-space.\nFinally, it is true that quantum information is strictly a super-set\nof classical information\u2014and hence a quantum module can commu-\nnicate any classical information it desires using a quantum interface\nelement. We argue, however, that using a quantum interface ele-\nment and messaging when classical would suffice is bad quantum\nsoftware design, for the reasons stated above.\nIn summary, the guiding principles behind any quantum software\nmodeling language must include the following:\n(1) (Quantum Classes): Whenever a software module makes\nuse of quantum information, either as part of its internal\nstate/implementation, or as part of its interface, this must be\nclearly established in a design document.\n(2) (Quantum Elements): Each module interface element (e.g.\npublic functions/methods, public variables) and internal state\nvariables can be either classical or quantum, and must be\nlabelled accordingly.\n(a) (Quantum Variables): Each variable should be labelled\nas classical or quantum. If the model represents data types,\nthe variables should also specify the classical (e.g. integer,\nstring) or quantum (e.g. qubit, qubit array, quantum graph\nstate) data type,\n(b) (Quantum Operations): For each operation, both the in-\nput and output should be clearly labelled as either classical\nor quantum. Whether the operation internally operates\nquantumly should also be labelled.\n(3) (Quantum Supremacy): A module that has at least one\nquantum element is to be considered a quantum software\nmodule, otherwise it is a classical module. Quantum and\nclassical modules should be clearly labelled as such.\n(4) (Quantum Aggregation): Any module that is composed of\none or more quantum modules will itself be considered a\nquantum module, and must be labelled as such.\n(5) (Quantum Communication): Quantum and classical mod-\nules can communicate with each other as long as their inter-\nfaces are compatible, i.e. the quantum module has classical\ninputs and/or outputs that can interface with the classical\nmodule.\nWe will argue in Sec. 2.3 how these extensions are not only nec-\nessary, but also sufficient in order to design and represent quantum\nsoftware. First, in the following two sections we put these principles\ninto practice as a set of concrete extensions to UML.\n2.1\nClass Diagram Extensions\nUML is a very graphical language, meant to convey a lot of meaning\nin a very small amount of space. As such, it makes sense to use a\ngraphical way to represent quantum software elements. We chose to\ndo this by use of bold text to denote quantum elements, and double\nlines to denote a quantum relationship or quantum communication.\nFigure 1: Q-UML class diagram of Shor\u2019s Algorithm. Quan-\ntum classes and interface elements are presented in bold\ntext, and quantum relationships use double-lines.\nFor attributes, the name will be bold if it is represented using\nquantum information. For methods, we use the following conven-\ntion. If any of the inputs are quantum, these are bold. If the output\nor datatype of the method is quantum, then the datatype should also\nbe bold. For backwards compatibility with regular UML, whenever\nthe input or output datatypes of a method are omitted, these will be\nassumed to be classical in nature. If a class/object has any quantum\nattributes or methods then it itself is considered quantum, and its\nname shall also be bold.\nRelationships between classes will use double-lines whenever the\nrelationship is quantum in nature. For inheritance, if the superclass\nis quantum then the subclass, and the inheritance relationship, will\nalso be quantum. (the converse is not necessarily true however).\nIn the case of aggregation and composition, if a class/object being\naggregated/composed is quantum, then the class/object to which\nit is aggregated/composed into, as well as that relationship will\n443\nalso be quantum. Association relationships do not have any special\nrules, beyond the need of a quantum class/object to have a classical\ninterface if it is to associate with classical classes/objects.\nFig. 1 showcases a Q-UML diagram that exemplifies the above\nrules.\n2.2\nSequence Diagram Extensions\nSequence diagrams in UML allow us to portray the dynamic rela-\ntionship between modules in a software program. As we did before\nfor static relationships, we extend the existing language in order to\nallow us to differentiate between classical and quantum messages.\nAs previously discussed, this is essential information. Quantum\ninformation behaves differently from classical information; it can\nstore/portray different data; it admits different operations; and, it\nrequires different hardware to store, send, and receive.\nFigure 2: Q-UML sequence diagram of Shor\u2019s Algorithm.\nQuantum classes are presented in bold text, and quantum\nmessages use double-lines.\nLike before, we make use of bold text to markup quantum mod-\nules, and double lines to portray quantum messages. Fig. 2 shows a\nQ-UML sequence diagram. Note how even though the relationship\nbetween Shorfactor and ShorOrder is quantum, the messaging\nbetween them is not. This illustrates an important point. A module\nis marked as quantum if it uses quantum resources in any form,\neither directly as part of its internal implementation or as part of\nan aggregated module. If a sub-module (in UML a composed class\nor object) is quantum, then the encompassing module must also be\nmarked as quantum. In a static (e.g. class) diagram, the quantum\ncomposition relationships inform us\u2014especially in the case of a\nseemingly classical module that does not in itself use quantum\nresources\u2014which composed modules are using quantum resources.\nAlso, note the communication between the objects ShorOrder\nand QFT_n. The module QFT_n operates on a quantum state.\nHence, both \u2018set\u2019 messages are quantum. Likewise, the return mes-\nsages \u03c1 and \u03c1\u2032 are quantum states. However, the request to perform\na quantum Fourier transform (QFT) or a QFT inverse operation\ncan (and therefore should) be communicated classically. This dia-\ngram showcases the level of granularity available to us using these\ndiagrams with the proposed extensions.\n2.3\nDiscussion\nWe have proposed a minimal series of extensions to existing soft-\nware modeling languages. We exemplify our additions in UML,\nbut these extensions are easily applicable to any other modeling\nlanguage, or be used as the basis for a new modeling language.\nWe\u2019ve argued the necessity of each of the extensions in previous\nsections. We can argue as well, that these extensions are not only\nnecessary, but also sufficient to fully model quantum software.\nTo make this argument, we appeal to the fact that all quantum\ncomputation is simulable using classical computation albeit with\nan efficiency loss. Other than their use of quantum information and\nalgorithms, quantum computers are indistinct from classical ones.\nHence, from a high-level design perspective, the only information\nelement that needs to be considered when developing quantum\nsoftware is when quantum (rather than classical) information is\nbeing used.\nThe one remaining information element we have not discussed\nis algorithm efficiency. If quantum computation is to be used, it\nwill most likely be due to the efficient algorithms at its disposal.\nThat said, algorithm efficiency is not a solely quantum consider-\nation. UML itself does not inherently have language elements for\nalgorithm efficiency (beyond user-defined notes). It does, however,\nhave several extensions used and proposed for this purpose(see\ne.g.[4]). Other modeling languages may also have definite algorithm\nefficiency elements. We argue that it is best to use existing language\nelements when they are available.\nACKNOWLEDGMENTS\nCP-D would like to acknowledge funding through the EPSRC Quan-\ntum Communications Hub (EP/T001011/1). The authors would also\nlike to thank Joanna I. Ziembicka for useful comments during the\npreparation on this manuscript.\nREFERENCES\n[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-\nducting processor. Nature 574, 7779 (2019), 505\u2013510.\nhttps://doi.org/10.1038/\ns41586-019-1666-5\n[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key\ndistribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.\n[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-\nguage User Guide, The (2nd Edition) (Addison-Wesley Object Technology Series).\nAddison-Wesley Professional.\n[4] C. Canevet, S. Gilmore, J. Hillston, M. Prowse, and P. Stevens. 2003. Performance\nmodelling with the Unified Modelling Language and stochastic process algebras.\nIEE Proceedings - Computers and Digital Techniques 150, 2 (March 2003), 107\u2013120.\nhttps://doi.org/10.1049/ip-cdt:20030084\n[5] Lov K. Grover. 1996.\nA Fast Quantum Mechanical Algorithm for Database\nSearch. In Proceedings of the Twenty-eighth Annual ACM Symposium on The-\nory of Computing (STOC \u201996). ACM, New York, NY, USA, 212\u2013219.\nhttps:\n//doi.org/10.1145/237814.237866\n[6] Carlos A. P\u00e9rez-Delgado and Donny Cheung. 2007. Local unitary quantum cellular\nautomata. Phys. Rev. A 76 (Sep 2007), 032320. Issue 3. https://doi.org/10.1103/\nPhysRevA.76.032320\n[7] Peter W Shor. 1994. Algorithms for quantum computation: Discrete logarithms\nand factoring. In Proceedings 35th annual symposium on foundations of computer\nscience. Ieee, 124\u2013134.\n[8] Liming Zhao, Carlos A. P\u00e9rez-Delgado, and Joseph F. Fitzsimons. 2016. Fast graph\noperations in quantum computation. Phys. Rev. A 93 (Mar 2016), 032314. Issue 3.\nhttps://doi.org/10.1103/PhysRevA.93.032314\n444\n",
    "pdf_url": "/media/Article_05_6rTfqRJ.pdf",
    "references": [
      "[1] Frank Arute et. al. 2019. Quantum supremacy using a programmable supercon-",
      "ducting processor. Nature 574, 7779 (2019), 505\u2013510.",
      "https://doi.org/10.1038/",
      "s41586-019-1666-5",
      "[2] Charles H Bennett and Gilles Brassard. 2014. Quantum cryptography: public key",
      "distribution and coin tossing. Theor. Comput. Sci. 560, 12 (2014), 7\u201311.",
      "[3] Grady Booch, James Rumbaugh, and Ivar Jacobson. 2005. Unified Modeling Lan-"
    ],
    "publication_date": "07-11-2023"
  },
  {
    "titre": "How to Teach Software Modeling",
    "resume": "To enhance motivation of students to study software engineering,some way of nding balance between the scientic aspect and thepractical aspect of software engineering is required. In this paper,we claim that teaching multiple software modeling techniques froma unied viewpoint is a good way of obtaining the balance andattracting the students interest as well.",
    "auteurs": [
      "Tetsuo Tamai",
      "Meguro-ku"
    ],
    "institutions": [
      "Tetsuo Tamai Graduate School of Arts and SciencesThe University of Tokyo3-8-1 Komaba, Meguro-kuTokyo 153-8902, "
    ],
    "mots_cles": [
      " software modeling",
      " software engineering education",
      " UML "
    ],
    "texte_integral": "How to Teach Software Modeling\nTetsuo Tamai\nGraduate School of Arts and Sciences\nThe University of Tokyo\n3-8-1 Komaba, Meguro-ku\nTokyo 153-8902, Japan\ntamai@acm.org\nABSTRACT\nTo enhance motivation of students to study software engineering,\nsome way of \ufb01nding balance between the scienti\ufb01c aspect and the\npractical aspect of software engineering is required. In this paper,\nwe claim that teaching multiple software modeling techniques from\na uni\ufb01ed viewpoint is a good way of obtaining the balance and\nattracting the students\u2019 interest as well.\nCategories and Subject Descriptors\nK.3.2 [Computers and Education]: Computer and Information\nScience Education\u2014computer science education; D.2.1 [Software\nEngineering]: Requirements/Speci\ufb01cation\u2014modeling\nGeneral Terms\nDesign\nKeywords\nsoftware modeling, software engineering education, UML\n1.\nINTRODUCTION\nSoftware engineering education at universities faces a common\nproblem; that is regular students do not usually have experience of\ndeveloping software for practical use and thus are not motivated for\nsoftware engineering aiming at high quality software production\nby a project team or a persistent organization. Software projects\nconducted by students simulating real scale software development\nmay help enhance students\u2019 motivation, although it requires a lot of\nefforts to prepare such projects and manage them.\nAnother way of solving this problem is to teach those who al-\nready have real experience in industry. In our case, there are cur-\nrently \ufb01ve Ph. D. students under the author\u2019s supervision who are\nworking at companies as well as doing research in our lab. As\na by-product, interactions between the part-time students and the\nother regular students stimulate each other, particularly enlighten-\ning the regular students to practical software issues. However, too\nmuch emphasis on practicality may bring negligence to scienceand\nCopyright is held by the author/owner.\nICSE\u201905, May 15\u201321, 2005, St. Louis, Missouri, USA.\nACM 1-58113-963-2/05/0005.\ntechnology and may generate anti-intellectualism. A good balance\nbetween the scienti\ufb01c aspect and the practical aspect of software\nengineering should always be pursued.\nIn our view, teaching various software modeling techniques is a\ngood way to achieve balanced software engineering education. It\nis needless to say that model is a key concept and modeling is an\nessential skill in software engineering. There are a variety of mod-\neling techniques; some are intuitive and quite accessibleto novices,\nwhile some are highly sophisticated and attract theory oriented stu-\ndents and researchers.\nIn this paper, we would like to show that it is effective to teach\nmultiple modeling techniques from a uni\ufb01ed viewpoint. It is based\non our experience of teaching software engineering courses at sev-\neral universities in Japan. Recently, the author published a textbook\non software engineering, speci\ufb01cally focused on software model-\ning (unfortunately, it is written in Japanese)[1]. The book covers\nthe whole area of software engineering, including design, testing\nand evolution but the modeling part has a role of attracting inter-\nests of intelligent students, who may not have much experience in\ndeveloping real scale software systems. It also gives a consistent\nviewpoint penetrating through various techniques employed in dif-\nferent stages of software engineering.\n2.\nMODELING TECHNIQUES\nIn software engineering, models are used for various purposes,\ne.g. life cycle model, process model, project model, product model,\nquality model, domain model, requirements model, design model,\nobject model, data model, etc. In the following, we basically focus\non requirements and design models but most of the discussionswill\nhold for other kinds of models.\nTeaching modeling is almost equal to teaching abstraction. Mod-\nels are constructed through capturing the crucial properties and\nstructure of the target, abstracting away irrelevant details. Thus,\nlearning how to model is a good training for mastering abstraction.\n2.1\nGraph Representation of Models\nMany software models are represented with diagrams. Wide ac-\nceptance of UML symbolizes the trend that diagrams are often pre-\nferred to textual languages. Among many types of diagrams, graph\nstructured diagrams are by far the most widely used. The reasons\nmay be as follows.\n1. A most fundamental way for human mind to understand the\nworld is by regarding it as consisting of a set of conceptual\nunits and a set of relations between them. Conceptual units\ncan be naturally illustrated with boxes or circles or whatever\nclosed \ufb01gures and relations can be illustrated with lines or ar-\nrows connecting such \ufb01gures, corresponding to vertices and\nedges of graphs, respectively.\n609\n2. It is easy to draw graph structured diagrams by hand or with\ndrawing tools.\n3. Concepts and algorithms of the graph theory are available\nand often useful in analyzing models represented by graphs.\nA typical example is reasoning on transitive relations by trac-\ning along paths of graphs. Also, the concept of subgraph is\nhighly useful in decomposinghigher-level models or cluster-\ning lower-level models.\nAccordingly, a number of models share the same structure of\ngraphs. Table 1 shows graph structures of some typical models.\nTable 1: Graph structures of typical models\nmodel\nvertex\nedge\nData \ufb02ow\nprocess\ndata \ufb02ow\nER\nentity\nrelationship\nState transition\nstate\ntransition\nJSD\nprocess\ndata stream connection\nstate vector connection\nActivity\nactivity\ncontrol \ufb02ow\nPetri net\nplace, transition\n\ufb01re and token \ufb02ow\n2.2\nCommonality and Difference between\nModels\nIt is pedagogical to let students notice the common structure\nshared by a number of models. However, the apparent resemblance\noften causes confusion. Such confusion can be observed not only\nin software modeling graphs but in many diagrams found in daily\nnewspapers, magazines, reports, proposals and other documents. It\nis often the case that one vertex denotes a type of things and an-\nother denotes quite a different type on the same diagram or one\ntype of edges co-exist with edges with different meaning. Thus,\nit is important to make students consciously aware the differences\nbetween different models. We often experience that when we let\nstudents draw data \ufb02ow diagrams who appear to have understood\nthe data \ufb02ow model perfectly, the diagrams turn out to be some-\nthing like control \ufb02ow graphs.\nTo show the difference, it is instructive to categorize models rep-\nresented by graphs. Basically, there are two categories.\n1. Static models:\nAn edge connecting vertex A and vertex B represents a rela-\ntion between A and B. When the edge is undirected, it means\n\u201cA and B are in some relation\u201d and when directed, it means\n\u201cA has a relation with B\u201d. Typical examples include entity\nrelationship model, class diagram and semantic network.\n2. Dynamic models:\nAn edge from vertex A to B denotes a move from A to B.\nThe edge in this case is always directed. There are two sub-\ncategories:\n(a) The case where a view of control moves from A to B.\nExamples are control \ufb02ow model and state transition\nmodel.\n(b) The case where data or objects \ufb02ow from A to B. Exam-\nples are data \ufb02ow model, work \ufb02ow model, and trans-\nportation \ufb02ow model.\nStatic models and dynamic models may not be easily confused\nbut confusion betweendifferent dynamic models are often observed,\ne.g. data \ufb02ow and control \ufb02ow or state transition and activity tran-\nsition. Since graphs are intuitively understandable, their semantics\nare apt to be understood ambiguously or misunderstood.\n3.\nUML\nUML diagrams can also be viewed in terms of graph structures.\nTable 2 shows graph structures of \ufb01ve UML diagrams.\nTable 2: Graph structures of UML diagrams\ndiagram\nvertex\nedge\nclass diagram\nclass\ngeneralization,\ncomposition,\nassociation\nstate machine\nstate\ntransition\nactivity diagram\nactivity\ncontrol \ufb02ow\ncollaboration diagram\nobject\nmessage \ufb02ow\nsequence diagram\nmessage\nmessage \ufb02ow\nanchor point\nIt is usually not desirable to teach UML per se. UML is a col-\nlection of miscellaneous diagrams and its speci\ufb01cation is continu-\nously changing. For the pedagogical purpose, UML had better be\nregarded as a catalogue of analysis and design know-how collected\naround diagrammatic representations. Diagrams should be selected\naccording to the policy of how to teach modeling methods.\nEach UML diagram contains overly rich constructs, which some-\ntimes blur the essential property of the model. For example, the\nactivity diagram is essentially a control \ufb02ow diagram but it also in-\ncludes a notation for data \ufb02ow description. From the stance of em-\nphasizing differences between various models, it is not appropriate\nto include such ad hoc constructs. By the same token, the collab-\noration diagram (, renamed to \u201ccommunication diagram\u201d in UML\n2) is explained to have the equivalent semantics as the sequence\ndiagram. But if that is the case, signi\ufb01cance of the collaboration\ndiagram is considerably limited. The author prefers to regard it as\nshowing collaboration relations between objects, integrating a set\nof different sequence diagrams.\n4.\nCONCLUSION\nSoftware modeling is important by itself but teaching modeling\nin the software engineering course has at least two additional mean-\nings. One is to give a bird\u2019s-eye view to the whole software engi-\nneering through the standpoint of modeling technology. The other\nis to attract interest of good students who may not have much expe-\nrience in developing a real-scale software but possess intelligence\nand will to attack complexity of modern software construction.\n5.\nREFERENCES\n[1] T. Tamai. Foundations of Software Engineering. Iwanami\nShoten, Tokyo, Japan, 2004. in Japanese.\n610\n",
    "pdf_url": "http://127.0.0.1:8000/media/Article_04.pdf",
    "references": [
      "[1] T. Tamai. Foundations of Software Engineering. Iwanami"
    ],
    "publication_date": "D:20231107172327-08'00'"
  }
]